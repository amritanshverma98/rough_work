{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "### prepare data for finetuning"
      ],
      "metadata": {
        "id": "CDliL-zZCxWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# --- REQUIRED: your Google Drive links ---\n",
        "FOLDER_URL = \"https://drive.google.com/drive/folders/1YMrsbFZmzxUTPiJSD8ybIFiInRVta2Jn?usp=sharing\"\n",
        "PICKLE_URL = \"https://drive.google.com/file/d/1NmuZVnS54NEyHHoJqwvIH_RNcli2C7na/view?usp=sharing\"\n",
        "\n",
        "# --- chunk length in seconds (edit this) ---\n",
        "CHUNK_SECONDS = 30\n",
        "\n",
        "# --- local directories ---\n",
        "DOWNLOAD_DIR = Path(\"./downloads\")       # where MP3s and the pickle will be saved\n",
        "MP3_DIR = DOWNLOAD_DIR / \"mp3s\"          # gdown will place folder contents here\n",
        "PICKLE_PATH = DOWNLOAD_DIR / \"data.pkl\"  # local pickle destination\n",
        "CHUNKS_DIR = Path(\"./chunks\")            # where chunks will be written\n",
        "\n",
        "for p in [DOWNLOAD_DIR, MP3_DIR, CHUNKS_DIR]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "CHUNK_MS = int(CHUNK_SECONDS * 1000)\n",
        "assert CHUNK_MS > 0, \"CHUNK_SECONDS must be > 0.\"\n"
      ],
      "metadata": {
        "id": "w_rTDg5HEFmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "# --- Download all files in the Drive folder (MP3s) ---\n",
        "print(\"Downloading MP3 folder (this can take a while for large folders)...\")\n",
        "gdown.download_folder(\n",
        "    url=FOLDER_URL,\n",
        "    output=str(MP3_DIR),\n",
        "    quiet=False,            # show progress\n",
        "    use_cookies=False,\n",
        "    remaining_ok=True\n",
        ")\n",
        "\n",
        "# --- Download the pickle file ---\n",
        "print(\"\\nDownloading pickle file...\")\n",
        "# gdown can handle sharing links; fuzzy=True extracts the file id automatically\n",
        "gdown.download(PICKLE_URL, output=str(PICKLE_PATH), quiet=False, fuzzy=True)\n",
        "\n",
        "print(\"\\nDone downloading.\")\n",
        "print(f\"MP3s folder: {MP3_DIR.resolve()}\")\n",
        "print(f\"Pickle file: {PICKLE_PATH.resolve()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ofRtkXiJC0Oj",
        "outputId": "6b9ff58e-9d15-400a-f420-5dabda4b3de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading MP3 folder (this can take a while for large folders)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1d1RNS0Ll5zsZzrjnXFCCvGLrHY3GKqmd id_1.mp3\n",
            "Processing file 1I5v9HXPgLzsyVBkqLax8l34np_AKyvGU id_2.mp3\n",
            "Processing file 1u12Ey-XyeMVYChQsY4L9TEXCDb08qIVU id_3.mp3\n",
            "Processing file 1_3rT7rNzUOPufBmAiMlO_xz5OZVipzfk id_4.mp3\n",
            "Processing file 1KbxlICw9R0TOFkh5RNjcLRPRkboHu013 id_5.mp3\n",
            "Processing file 1-3raZGW5AdHSC0jb8sOSpGRgAN9pOLd2 id_6.mp3\n",
            "Processing file 1RWI_HeCrKRnL4hP_HyR0TyBzq4czgcC9 id_7.mp3\n",
            "Processing file 1FcOLE_Mti1GWLaM9tzjusvaWASUsoSGs id_8.mp3\n",
            "Processing file 1Ciyd0jnWe0hkN6MrK11ZVtGwJSsK5Y8w id_9.mp3\n",
            "Processing file 1O91AwyK4zOU3BbIkdAqSXxZPiY_hzP_d id_10.mp3\n",
            "Processing file 1NxssP2KcJKsRUQE5l-s8M8yvlmBalHtD id_11.mp3\n",
            "Processing file 1TOdNoegXG2VoMm025tvElxPEqYCx1G_G id_12.mp3\n",
            "Processing file 1kc4vOvdhnz5z4Mfo119LzoDpNCK3Sqs5 id_13.mp3\n",
            "Processing file 1L4ST65LuS8AJ-VUBmAQ2REgovMnOJC-q id_14.mp3\n",
            "Processing file 1re0cCWSLcLPCxHSQGXXkIe8-GEwEmP8h id_15.mp3\n",
            "Processing file 1IbatLcMU8-Apa4TqnvqJiwxgtZkHnY4c id_16.mp3\n",
            "Processing file 1hVs8ZAyqfOfyeSg2QhwTMqY2-zEPCVDI id_17.mp3\n",
            "Processing file 1DKXcEOjV5EFCclGV84RoxLSUrKvxU5Wo id_18.mp3\n",
            "Processing file 1LJqwtRAhWjA0Qiv-wqs55dsAgDn42bnQ id_19.mp3\n",
            "Processing file 1V-8fJ9-LDpaBVYJzmEF4S2gDN7cdXSzS id_20.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1d1RNS0Ll5zsZzrjnXFCCvGLrHY3GKqmd\n",
            "To: /content/downloads/mp3s/id_1.mp3\n",
            "100%|██████████| 903k/903k [00:00<00:00, 8.59MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1I5v9HXPgLzsyVBkqLax8l34np_AKyvGU\n",
            "To: /content/downloads/mp3s/id_2.mp3\n",
            "100%|██████████| 743k/743k [00:00<00:00, 6.11MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1u12Ey-XyeMVYChQsY4L9TEXCDb08qIVU\n",
            "To: /content/downloads/mp3s/id_3.mp3\n",
            "100%|██████████| 721k/721k [00:00<00:00, 2.83MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_3rT7rNzUOPufBmAiMlO_xz5OZVipzfk\n",
            "To: /content/downloads/mp3s/id_4.mp3\n",
            "100%|██████████| 710k/710k [00:00<00:00, 6.40MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KbxlICw9R0TOFkh5RNjcLRPRkboHu013\n",
            "To: /content/downloads/mp3s/id_5.mp3\n",
            "100%|██████████| 608k/608k [00:00<00:00, 5.98MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-3raZGW5AdHSC0jb8sOSpGRgAN9pOLd2\n",
            "To: /content/downloads/mp3s/id_6.mp3\n",
            "100%|██████████| 477k/477k [00:00<00:00, 2.33MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RWI_HeCrKRnL4hP_HyR0TyBzq4czgcC9\n",
            "To: /content/downloads/mp3s/id_7.mp3\n",
            "100%|██████████| 529k/529k [00:00<00:00, 2.36MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1FcOLE_Mti1GWLaM9tzjusvaWASUsoSGs\n",
            "To: /content/downloads/mp3s/id_8.mp3\n",
            "100%|██████████| 561k/561k [00:00<00:00, 5.16MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ciyd0jnWe0hkN6MrK11ZVtGwJSsK5Y8w\n",
            "To: /content/downloads/mp3s/id_9.mp3\n",
            "100%|██████████| 499k/499k [00:00<00:00, 5.29MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1O91AwyK4zOU3BbIkdAqSXxZPiY_hzP_d\n",
            "To: /content/downloads/mp3s/id_10.mp3\n",
            "100%|██████████| 617k/617k [00:00<00:00, 2.52MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NxssP2KcJKsRUQE5l-s8M8yvlmBalHtD\n",
            "To: /content/downloads/mp3s/id_11.mp3\n",
            "100%|██████████| 718k/718k [00:00<00:00, 3.44MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TOdNoegXG2VoMm025tvElxPEqYCx1G_G\n",
            "To: /content/downloads/mp3s/id_12.mp3\n",
            "100%|██████████| 669k/669k [00:00<00:00, 6.26MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kc4vOvdhnz5z4Mfo119LzoDpNCK3Sqs5\n",
            "To: /content/downloads/mp3s/id_13.mp3\n",
            "100%|██████████| 522k/522k [00:00<00:00, 3.00MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1L4ST65LuS8AJ-VUBmAQ2REgovMnOJC-q\n",
            "To: /content/downloads/mp3s/id_14.mp3\n",
            "100%|██████████| 443k/443k [00:00<00:00, 4.71MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1re0cCWSLcLPCxHSQGXXkIe8-GEwEmP8h\n",
            "To: /content/downloads/mp3s/id_15.mp3\n",
            "100%|██████████| 439k/439k [00:00<00:00, 4.44MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IbatLcMU8-Apa4TqnvqJiwxgtZkHnY4c\n",
            "To: /content/downloads/mp3s/id_16.mp3\n",
            "100%|██████████| 454k/454k [00:00<00:00, 4.54MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hVs8ZAyqfOfyeSg2QhwTMqY2-zEPCVDI\n",
            "To: /content/downloads/mp3s/id_17.mp3\n",
            "100%|██████████| 472k/472k [00:00<00:00, 2.67MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DKXcEOjV5EFCclGV84RoxLSUrKvxU5Wo\n",
            "To: /content/downloads/mp3s/id_18.mp3\n",
            "100%|██████████| 496k/496k [00:00<00:00, 5.29MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LJqwtRAhWjA0Qiv-wqs55dsAgDn42bnQ\n",
            "To: /content/downloads/mp3s/id_19.mp3\n",
            "100%|██████████| 535k/535k [00:00<00:00, 4.98MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1V-8fJ9-LDpaBVYJzmEF4S2gDN7cdXSzS\n",
            "To: /content/downloads/mp3s/id_20.mp3\n",
            "100%|██████████| 441k/441k [00:00<00:00, 2.83MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading pickle file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NmuZVnS54NEyHHoJqwvIH_RNcli2C7na\n",
            "To: /content/downloads/data.pkl\n",
            "100%|██████████| 63.0k/63.0k [00:00<00:00, 1.97MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done downloading.\n",
            "MP3s folder: /content/downloads/mp3s\n",
            "Pickle file: /content/downloads/data.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "restart_from_begin = 0\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "if restart_from_begin:\n",
        "  print(\"Reading pickle into a DataFrame...\")\n",
        "  all_data = pd.read_pickle(PICKLE_PATH)\n",
        "  all_data.head()\n"
      ],
      "metadata": {
        "id": "k2nghnLmC0RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import imageio_ffmpeg\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "# Point pydub to the bundled ffmpeg executable so it works in most environments\n",
        "AudioSegment.converter = imageio_ffmpeg.get_ffmpeg_exe()\n",
        "chunk_files_paths = []\n",
        "mp3_paths = sorted(MP3_DIR.rglob(\"*.mp3\"))\n",
        "print(f\"Found {len(mp3_paths)} MP3 file(s).\")\n",
        "\n",
        "total_chunks = 0\n",
        "\n",
        "for mp3_path in tqdm(mp3_paths, desc=\"Chunking MP3s\"):\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(mp3_path)\n",
        "\n",
        "        duration_ms = len(audio)\n",
        "        if duration_ms == 0:\n",
        "            print(f\"Warning: {mp3_path} appears to be empty; skipping.\")\n",
        "            continue\n",
        "\n",
        "        n_chunks = math.ceil(duration_ms / CHUNK_MS)\n",
        "        base = mp3_path.stem\n",
        "        file_chunk_dir = CHUNKS_DIR / base\n",
        "        file_chunk_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        for i in range(n_chunks):\n",
        "            start = i * CHUNK_MS\n",
        "            end = min((i + 1) * CHUNK_MS, duration_ms)\n",
        "            chunk = audio[start:end]\n",
        "\n",
        "            # Save each chunk as MP3\n",
        "            out_path = file_chunk_dir / f\"{base}_chunk_{i+1:04d}.mp3\"\n",
        "            chunk_files_paths.append(out_path)\n",
        "            chunk.export(out_path, format=\"mp3\")\n",
        "\n",
        "        total_chunks += n_chunks\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {mp3_path}: {e}\")\n",
        "\n",
        "print(f\"\\nFinished. Wrote ~{total_chunks} chunk(s) into: {CHUNKS_DIR.resolve()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LNhS1L6C0UM",
        "outputId": "976e3e05-e226-445e-a278-2d76e1bb4087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(flt)p?( \\(default\\))?$', token):\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(dbl)p?( \\(default\\))?$', token):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20 MP3 file(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Chunking MP3s: 100%|██████████| 20/20 [00:15<00:00,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Finished. Wrote ~67 chunk(s) into: /content/chunks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_files_paths = [\"/content/\"+str(cfp) for cfp in chunk_files_paths]"
      ],
      "metadata": {
        "id": "O4vZscwWFcYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "  chunk_df = pd.DataFrame(chunk_files_paths,columns=['file_path'])"
      ],
      "metadata": {
        "id": "1FRBLuirFvGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "  chunk_df['id'] = chunk_df.apply(lambda x : x['file_path'].split(\"/\")[3],axis=1)\n",
        "  chunk_df['chunk_id'] = chunk_df.apply(lambda x : \"chunk_\"+x['file_path'].split(\"/\")[4].split(\"_\")[-1],axis=1)\n",
        "  chunk_df"
      ],
      "metadata": {
        "id": "y8NKQ3F-FrwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "    chunk_level_data = pd.merge(all_data,chunk_df,on='id',how='inner')[['id','chunk_id','type','topic','signal','file_path']]"
      ],
      "metadata": {
        "id": "JGIy0Dr4GWU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "  print(chunk_level_data.shape, chunk_df.shape) #((67, 6), (67, 3))"
      ],
      "metadata": {
        "id": "hukYkmaCGimr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chunk_level_data.head(3)"
      ],
      "metadata": {
        "id": "6mu6I8ZqGlcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## transcribe all chunks"
      ],
      "metadata": {
        "id": "75GY8Q5fGz5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU openai-whisper openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XavLcH3G9Tk",
        "outputId": "a83fe69a-822b-4af8-b1bd-2a2cf9ce1638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import whisper\n",
        "def transcribe_audio_using_whisper(model, path):\n",
        "  #ops = []\n",
        "    #for path in paths:\n",
        "    print(\"path \",path)\n",
        "    # load audio and pad/trim it to fit 30 seconds\n",
        "    audio = whisper.load_audio(path)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "    # make log-Mel spectrogram and move to the same device as the model\n",
        "    mel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\n",
        "\n",
        "    # detect the spoken language\n",
        "    _, probs = model.detect_language(mel)\n",
        "    print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
        "\n",
        "    # decode the audio\n",
        "    options = whisper.DecodingOptions()\n",
        "    result = whisper.decode(model, mel, options)\n",
        "\n",
        "    op = result.text\n",
        "    print(\"op is \",op)\n",
        "    #ops.append(op)\n",
        "    return op\n",
        "\n",
        "\n",
        "def get_whisper_model():\n",
        "  model = whisper.load_model(\"turbo\")\n",
        "  return model\n",
        "\n",
        "\n",
        "if restart_from_begin:\n",
        "  whisper_model =  get_whisper_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVmKSgzVGz9D",
        "outputId": "479ddce5-68e8-4067-8261-9b50f065385e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 1.51G/1.51G [00:06<00:00, 260MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "  ops = {'model':[],'inference':[],'file_path':[]}\n",
        "  for i,r in chunk_level_data.iterrows():\n",
        "        print(\"i \",i+1)\n",
        "        file_path = r['file_path']\n",
        "        whisper_transcribed = transcribe_audio_using_whisper(whisper_model, file_path)\n",
        "        ops['model'].append('whisper')\n",
        "        ops['inference'].append(whisper_transcribed)\n",
        "        ops['file_path'].append(file_path)\n",
        "\n",
        "  ops_df = pd.DataFrame(ops)\n",
        "  ops_df_whisper = ops_df.copy()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "aMw2nKKPHMeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "  ops_df_whisper.to_excel(f\"ops_df_whisper_{ops_df_whisper.shape}.xlsx\",index=False)"
      ],
      "metadata": {
        "id": "9Lh78ZfeHA57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "  ops_df_whisper.rename(columns={'inference':'chunk_transcript'},inplace=True)"
      ],
      "metadata": {
        "id": "DeKa_Z2sIZO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "    print(ops_df_whisper.shape, chunk_level_data.shape)"
      ],
      "metadata": {
        "id": "g9764Lx8IlBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "  chunk_level_data =  pd.merge(chunk_level_data,ops_df_whisper[['file_path','chunk_transcript']],on=['file_path'])"
      ],
      "metadata": {
        "id": "HmuM-ShbHA8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "    print(chunk_level_data.shape) #(67, 7)"
      ],
      "metadata": {
        "id": "6WutwhdvIyYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "    segs = []\n",
        "    file_names = chunk_level_data['id'].unique()\n",
        "\n",
        "    from itertools import accumulate\n",
        "\n",
        "    for fn in file_names:\n",
        "      print(\"fn \",fn)\n",
        "      chunk_level_data_fil =  chunk_level_data[chunk_level_data['id']==fn]\n",
        "      s = chunk_level_data_fil['chunk_transcript'].fillna('').astype(str).str.strip()\n",
        "      chunk_level_data_fil['cum_chunk_transcript'] = list(\n",
        "          accumulate(s, lambda a, b: (a + ' ' + b) if a and b else (a or b)))\n",
        "      chunk_level_data_fil['cum_chunk_transcript_shifted'] = chunk_level_data_fil['cum_chunk_transcript'].shift(1)\n",
        "      segs.append(chunk_level_data_fil)\n",
        "\n",
        "    chunk_level_data = pd.concat(segs,axis=0)\n",
        "    print(chunk_level_data.shape)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1wKk1mvZJyv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "  chunk_level_data"
      ],
      "metadata": {
        "id": "DJ6nhSlxKWXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def thinking_prompt(r):\n",
        "   cif = r['cum_chunk_transcript_shifted']\n",
        "   if (cif ==\"\") or (cif==None):\n",
        "      past_conversation = \"\"\n",
        "      i1 = \"\"\n",
        "   else:\n",
        "      past_conversation = \"Past Conversation : \"+cif\n",
        "      i1 = \"and past conversation \"\n",
        "   op = f\"\"\"\n",
        "You are given an audio conversation {i1}happening between an american express customer care professional and a customer.\n",
        "This customer can be either a genuine customer or a fraudster.\n",
        "\n",
        "## Your Task\n",
        "Predict a probability that the customer is a fraudster\n",
        "\n",
        "In order to predict the probability of fraud you should think and analyze the situation and create a reasoning.\n",
        "Make sure you see each and every aspect of the case and create a case report while reasoning about the case.\n",
        "Note that the permissible values of probability are 0.0, 0.25, 0.5, 0.75, 1.0\n",
        "\n",
        "The reasoning process should be enclosed within <think> </think> tags\n",
        "While the final answer should be enclosed in <answer> </answer> tags\n",
        "\n",
        "Example Response :\n",
        "<think>This is my reasoning</think>\\n<answer>0.75</answer>\n",
        "\n",
        "\"\"\"+past_conversation\n",
        "   return op.strip()\n",
        "\n",
        "\n",
        "if restart_from_begin:\n",
        "    chunk_level_data['llm_prompt'] = chunk_level_data.apply(lambda x : thinking_prompt(x),axis=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3C7hR8RTJeDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "    chunk_level_data.to_excel(f\"chunk_level_data_{chunk_level_data.shape}.xlsx\",index=False)"
      ],
      "metadata": {
        "id": "hfJDO86kMToL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# Set random seed for reproducibility\n",
        "random_state = 1\n",
        "random.seed(random_state)\n",
        "\n"
      ],
      "metadata": {
        "id": "snLhWvWkUGNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "    train_ratio = 0.7\n",
        "    test_ratio = 1-train_ratio\n",
        "\n",
        "    all_ids = list(set(chunk_level_data['id']))\n",
        "    print(len(all_ids))\n",
        "\n",
        "    train_ids =  random.sample(all_ids, int(0.7 * len(all_ids)))\n",
        "    print(len(train_ids))\n",
        "    test_ids = list(set(all_ids).difference(set(train_ids)))\n",
        "    print(len(test_ids))\n"
      ],
      "metadata": {
        "id": "SDkEXQapTzvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "  chunk_level_data['data_split_v1'] = chunk_level_data.apply(lambda x : 'train' if x['id'] in train_ids else 'test',axis=1)"
      ],
      "metadata": {
        "id": "YrRgUhRWU3Sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "    chunk_level_data['data_split_v1'].value_counts()"
      ],
      "metadata": {
        "id": "bQy79q_OVLR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  import pandas as pd\n",
        "  import requests\n",
        "  from io import BytesIO"
      ],
      "metadata": {
        "id": "YAitamVEge9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_begin:\n",
        "    chunk_level_data.to_excel(f\"chunk_level_data_{chunk_level_data.shape}.xlsx\",index=False)\n",
        "else:\n",
        "    print(\"downloading\")\n",
        "    # Replace with your sheet ID\n",
        "    sheet_id = \"1IZp4xXpHrecOmjpdqMqPt5fNA1HEL3Bf\"\n",
        "\n",
        "    # Construct the export URL\n",
        "    url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=xlsx\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # if the download fails, raise an error\n",
        "\n",
        "    # Load into pandas\n",
        "    chunk_level_data = pd.read_excel(BytesIO(response.content))\n",
        "\n",
        "    print(chunk_level_data.shape)\n"
      ],
      "metadata": {
        "id": "niwaRVmoVcKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2ac7276-1229-4b1c-bb5a-b95ecc73e566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(67, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_level_data.shape"
      ],
      "metadata": {
        "id": "m6UkAc2DeqEY",
        "outputId": "148a8d98-e350-46fe-b0c0-9ded78ae3c78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(67, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_chunk_level_data = chunk_level_data[chunk_level_data['data_split_v1']=='train']\n",
        "test_chunk_level_data = chunk_level_data[chunk_level_data['data_split_v1']=='test']"
      ],
      "metadata": {
        "id": "O0EOezfzVlK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_level_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zmBrJ1vxJeGv",
        "outputId": "20141813-8d90-4369-8748-0134d2ddb681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id        chunk_id       type  \\\n",
              "0   id_19  chunk_0002.mp3      fraud   \n",
              "1    id_8  chunk_0002.mp3  non_fraud   \n",
              "2   id_16  chunk_0002.mp3      fraud   \n",
              "3    id_6  chunk_0002.mp3  non_fraud   \n",
              "4    id_8  chunk_0001.mp3  non_fraud   \n",
              "..    ...             ...        ...   \n",
              "62   id_2  chunk_0001.mp3  non_fraud   \n",
              "63   id_3  chunk_0003.mp3  non_fraud   \n",
              "64   id_3  chunk_0001.mp3  non_fraud   \n",
              "65   id_3  chunk_0004.mp3  non_fraud   \n",
              "66  id_11  chunk_0003.mp3      fraud   \n",
              "\n",
              "                                                topic  \\\n",
              "0   Refund/chargeback abuse — dispute legitimate p...   \n",
              "1   Travel & international use — travel prep, FX tips   \n",
              "2   Override blocks — whitelist merchant/lift frau...   \n",
              "3          Account maintenance — update address/email   \n",
              "4   Travel & international use — travel prep, FX tips   \n",
              "..                                                ...   \n",
              "62         Payments — set up AutoPay, confirm posting   \n",
              "63                       Card activation & onboarding   \n",
              "64                       Card activation & onboarding   \n",
              "65                       Card activation & onboarding   \n",
              "66        Account-takeover setup — change email/phone   \n",
              "\n",
              "                                               signal  \\\n",
              "0   Attempts to steer dispute reason; demands imme...   \n",
              "1   Genuine signals: Clear itinerary; seeks best-p...   \n",
              "2   Requests whitelist/bypass; pushes new phone nu...   \n",
              "3   Genuine signals: Offers multiple identifiers; ...   \n",
              "4   Genuine signals: Clear itinerary; seeks best-p...   \n",
              "..                                                ...   \n",
              "62  Genuine signals: Eager to verify; provides ful...   \n",
              "63  Genuine signals: Full verification; accepts on...   \n",
              "64  Genuine signals: Full verification; accepts on...   \n",
              "65  Genuine signals: Full verification; accepts on...   \n",
              "66  Refuses/avoids verification; urgent demand to ...   \n",
              "\n",
              "                                     file_path  \\\n",
              "0   /content/chunks/id_19/id_19_chunk_0002.mp3   \n",
              "1     /content/chunks/id_8/id_8_chunk_0002.mp3   \n",
              "2   /content/chunks/id_16/id_16_chunk_0002.mp3   \n",
              "3     /content/chunks/id_6/id_6_chunk_0002.mp3   \n",
              "4     /content/chunks/id_8/id_8_chunk_0001.mp3   \n",
              "..                                         ...   \n",
              "62    /content/chunks/id_2/id_2_chunk_0001.mp3   \n",
              "63    /content/chunks/id_3/id_3_chunk_0003.mp3   \n",
              "64    /content/chunks/id_3/id_3_chunk_0001.mp3   \n",
              "65    /content/chunks/id_3/id_3_chunk_0004.mp3   \n",
              "66  /content/chunks/id_11/id_11_chunk_0003.mp3   \n",
              "\n",
              "                                     chunk_transcript  \\\n",
              "0   We need accurate reasons. If the merchant show...   \n",
              "1   notices, but it helps to keep your contact inf...   \n",
              "2   The order is 3,900 ASL Mooks MacBooks. Make it...   \n",
              "3   WA 98109. Address updated. Would you like a re...   \n",
              "4   American Express Travel. This is Neha. Hi Neha...   \n",
              "..                                                ...   \n",
              "62  American Express Payments. This is Jordan. How...   \n",
              "63  elsewhere. You've got trip delay insurance and...   \n",
              "64  You've reached American Express. This is Elena...   \n",
              "65  614? Yes, shipping to your on-file address is ...   \n",
              "66  I can't change contact points without authenti...   \n",
              "\n",
              "                                 cum_chunk_transcript  \\\n",
              "0   And next dispute, Sophia speaking. Fire the ch...   \n",
              "1   American Express Travel. This is Neha. Hi Neha...   \n",
              "2   Ah, fraud prevention at American Express. This...   \n",
              "3   American Express, Alicia speaking. Hi, Alicia....   \n",
              "4   American Express Travel. This is Neha. Hi Neha...   \n",
              "..                                                ...   \n",
              "62  American Express Payments. This is Jordan. How...   \n",
              "63  You've reached American Express. This is Elena...   \n",
              "64  You've reached American Express. This is Elena...   \n",
              "65  You've reached American Express. This is Elena...   \n",
              "66  American Express, this is Noah. How may I help...   \n",
              "\n",
              "                         cum_chunk_transcript_shifted  \\\n",
              "0   And next dispute, Sophia speaking. Fire the ch...   \n",
              "1   American Express Travel. This is Neha. Hi Neha...   \n",
              "2   Ah, fraud prevention at American Express. This...   \n",
              "3   American Express, Alicia speaking. Hi, Alicia....   \n",
              "4                                                 NaN   \n",
              "..                                                ...   \n",
              "62                                                NaN   \n",
              "63  You've reached American Express. This is Elena...   \n",
              "64                                                NaN   \n",
              "65  You've reached American Express. This is Elena...   \n",
              "66  American Express, this is Noah. How may I help...   \n",
              "\n",
              "                                           llm_prompt data_split_v1  \n",
              "0   You are given an audio conversation and past c...         train  \n",
              "1   You are given an audio conversation and past c...         train  \n",
              "2   You are given an audio conversation and past c...          test  \n",
              "3   You are given an audio conversation and past c...         train  \n",
              "4   You are given an audio conversation happening ...         train  \n",
              "..                                                ...           ...  \n",
              "62  You are given an audio conversation happening ...         train  \n",
              "63  You are given an audio conversation and past c...         train  \n",
              "64  You are given an audio conversation happening ...         train  \n",
              "65  You are given an audio conversation and past c...         train  \n",
              "66  You are given an audio conversation and past c...         train  \n",
              "\n",
              "[67 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-251e2a84-b34b-4e4d-93f0-681c67f4004a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>chunk_id</th>\n",
              "      <th>type</th>\n",
              "      <th>topic</th>\n",
              "      <th>signal</th>\n",
              "      <th>file_path</th>\n",
              "      <th>chunk_transcript</th>\n",
              "      <th>cum_chunk_transcript</th>\n",
              "      <th>cum_chunk_transcript_shifted</th>\n",
              "      <th>llm_prompt</th>\n",
              "      <th>data_split_v1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_19</td>\n",
              "      <td>chunk_0002.mp3</td>\n",
              "      <td>fraud</td>\n",
              "      <td>Refund/chargeback abuse — dispute legitimate p...</td>\n",
              "      <td>Attempts to steer dispute reason; demands imme...</td>\n",
              "      <td>/content/chunks/id_19/id_19_chunk_0002.mp3</td>\n",
              "      <td>We need accurate reasons. If the merchant show...</td>\n",
              "      <td>And next dispute, Sophia speaking. Fire the ch...</td>\n",
              "      <td>And next dispute, Sophia speaking. Fire the ch...</td>\n",
              "      <td>You are given an audio conversation and past c...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_8</td>\n",
              "      <td>chunk_0002.mp3</td>\n",
              "      <td>non_fraud</td>\n",
              "      <td>Travel &amp; international use — travel prep, FX tips</td>\n",
              "      <td>Genuine signals: Clear itinerary; seeks best-p...</td>\n",
              "      <td>/content/chunks/id_8/id_8_chunk_0002.mp3</td>\n",
              "      <td>notices, but it helps to keep your contact inf...</td>\n",
              "      <td>American Express Travel. This is Neha. Hi Neha...</td>\n",
              "      <td>American Express Travel. This is Neha. Hi Neha...</td>\n",
              "      <td>You are given an audio conversation and past c...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_16</td>\n",
              "      <td>chunk_0002.mp3</td>\n",
              "      <td>fraud</td>\n",
              "      <td>Override blocks — whitelist merchant/lift frau...</td>\n",
              "      <td>Requests whitelist/bypass; pushes new phone nu...</td>\n",
              "      <td>/content/chunks/id_16/id_16_chunk_0002.mp3</td>\n",
              "      <td>The order is 3,900 ASL Mooks MacBooks. Make it...</td>\n",
              "      <td>Ah, fraud prevention at American Express. This...</td>\n",
              "      <td>Ah, fraud prevention at American Express. This...</td>\n",
              "      <td>You are given an audio conversation and past c...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_6</td>\n",
              "      <td>chunk_0002.mp3</td>\n",
              "      <td>non_fraud</td>\n",
              "      <td>Account maintenance — update address/email</td>\n",
              "      <td>Genuine signals: Offers multiple identifiers; ...</td>\n",
              "      <td>/content/chunks/id_6/id_6_chunk_0002.mp3</td>\n",
              "      <td>WA 98109. Address updated. Would you like a re...</td>\n",
              "      <td>American Express, Alicia speaking. Hi, Alicia....</td>\n",
              "      <td>American Express, Alicia speaking. Hi, Alicia....</td>\n",
              "      <td>You are given an audio conversation and past c...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_8</td>\n",
              "      <td>chunk_0001.mp3</td>\n",
              "      <td>non_fraud</td>\n",
              "      <td>Travel &amp; international use — travel prep, FX tips</td>\n",
              "      <td>Genuine signals: Clear itinerary; seeks best-p...</td>\n",
              "      <td>/content/chunks/id_8/id_8_chunk_0001.mp3</td>\n",
              "      <td>American Express Travel. This is Neha. Hi Neha...</td>\n",
              "      <td>American Express Travel. This is Neha. Hi Neha...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>You are given an audio conversation happening ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>id_2</td>\n",
              "      <td>chunk_0001.mp3</td>\n",
              "      <td>non_fraud</td>\n",
              "      <td>Payments — set up AutoPay, confirm posting</td>\n",
              "      <td>Genuine signals: Eager to verify; provides ful...</td>\n",
              "      <td>/content/chunks/id_2/id_2_chunk_0001.mp3</td>\n",
              "      <td>American Express Payments. This is Jordan. How...</td>\n",
              "      <td>American Express Payments. This is Jordan. How...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>You are given an audio conversation happening ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>id_3</td>\n",
              "      <td>chunk_0003.mp3</td>\n",
              "      <td>non_fraud</td>\n",
              "      <td>Card activation &amp; onboarding</td>\n",
              "      <td>Genuine signals: Full verification; accepts on...</td>\n",
              "      <td>/content/chunks/id_3/id_3_chunk_0003.mp3</td>\n",
              "      <td>elsewhere. You've got trip delay insurance and...</td>\n",
              "      <td>You've reached American Express. This is Elena...</td>\n",
              "      <td>You've reached American Express. This is Elena...</td>\n",
              "      <td>You are given an audio conversation and past c...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>id_3</td>\n",
              "      <td>chunk_0001.mp3</td>\n",
              "      <td>non_fraud</td>\n",
              "      <td>Card activation &amp; onboarding</td>\n",
              "      <td>Genuine signals: Full verification; accepts on...</td>\n",
              "      <td>/content/chunks/id_3/id_3_chunk_0001.mp3</td>\n",
              "      <td>You've reached American Express. This is Elena...</td>\n",
              "      <td>You've reached American Express. This is Elena...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>You are given an audio conversation happening ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>id_3</td>\n",
              "      <td>chunk_0004.mp3</td>\n",
              "      <td>non_fraud</td>\n",
              "      <td>Card activation &amp; onboarding</td>\n",
              "      <td>Genuine signals: Full verification; accepts on...</td>\n",
              "      <td>/content/chunks/id_3/id_3_chunk_0004.mp3</td>\n",
              "      <td>614? Yes, shipping to your on-file address is ...</td>\n",
              "      <td>You've reached American Express. This is Elena...</td>\n",
              "      <td>You've reached American Express. This is Elena...</td>\n",
              "      <td>You are given an audio conversation and past c...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>id_11</td>\n",
              "      <td>chunk_0003.mp3</td>\n",
              "      <td>fraud</td>\n",
              "      <td>Account-takeover setup — change email/phone</td>\n",
              "      <td>Refuses/avoids verification; urgent demand to ...</td>\n",
              "      <td>/content/chunks/id_11/id_11_chunk_0003.mp3</td>\n",
              "      <td>I can't change contact points without authenti...</td>\n",
              "      <td>American Express, this is Noah. How may I help...</td>\n",
              "      <td>American Express, this is Noah. How may I help...</td>\n",
              "      <td>You are given an audio conversation and past c...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67 rows × 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-251e2a84-b34b-4e4d-93f0-681c67f4004a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-251e2a84-b34b-4e4d-93f0-681c67f4004a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-251e2a84-b34b-4e4d-93f0-681c67f4004a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-104e8e99-e36a-436b-9b4c-610596399c0e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-104e8e99-e36a-436b-9b4c-610596399c0e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-104e8e99-e36a-436b-9b4c-610596399c0e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_39dd7e15-6fa0-4db0-afe2-4d5fb2c605ac\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('chunk_level_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_39dd7e15-6fa0-4db0-afe2-4d5fb2c605ac button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('chunk_level_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "chunk_level_data",
              "summary": "{\n  \"name\": \"chunk_level_data\",\n  \"rows\": 67,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"id_19\",\n          \"id_2\",\n          \"id_5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"chunk_0001.mp3\",\n          \"chunk_0005.mp3\",\n          \"chunk_0003.mp3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"non_fraud\",\n          \"fraud\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Refund/chargeback abuse \\u2014 dispute legitimate purchase\",\n          \"Payments \\u2014 set up AutoPay, confirm posting\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"signal\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Attempts to steer dispute reason; demands immediate refund; refuses verification and documentation; tries multiple inaccurate reasons; urgency and manipulation.\",\n          \"Genuine signals: Eager to verify; provides full, consistent contact info; asks practical posting and notification questions; requests conservative AutoPay; accepts standard timelines.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 67,\n        \"samples\": [\n          \"/content/chunks/id_4/id_4_chunk_0001.mp3\",\n          \"/content/chunks/id_14/id_14_chunk_0001.mp3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 67,\n        \"samples\": [\n          \"American Express Membership Rewards, this is Sam. Hi Sam, Rochelle Kim here. I'm planning a Boston trip and want to transfer points to an airline. Happy to help, Rochelle. Let me verify last four digits, billing, zip, and email. Free fine, one zip, one sold, and I'm just three. Email rochelle.kimeastmail.com. Thanks, verified.\",\n          \"American Express Security, this is Dana. Your two-factor keeps blocking me at checkout. Turn off MFA for the day. Just flip the switch. I can review settings after we verify. May I have your name, last four digits, billing zip, and an in-app approval? I don't have access to any of that right now. Just disable it temporarily. I'll re-enable later.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cum_chunk_transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 67,\n        \"samples\": [\n          \"American Express Membership Rewards, this is Sam. Hi Sam, Rochelle Kim here. I'm planning a Boston trip and want to transfer points to an airline. Happy to help, Rochelle. Let me verify last four digits, billing, zip, and email. Free fine, one zip, one sold, and I'm just three. Email rochelle.kimeastmail.com. Thanks, verified.\",\n          \"American Express Security, this is Dana. Your two-factor keeps blocking me at checkout. Turn off MFA for the day. Just flip the switch. I can review settings after we verify. May I have your name, last four digits, billing zip, and an in-app approval? I don't have access to any of that right now. Just disable it temporarily. I'll re-enable later.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cum_chunk_transcript_shifted\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          \"Thank you for calling American Express. You're speaking with Maya. How can I help today? Hi, Maya. This is Alex Bennett. I'm calling about my September statement. The interest looks a lot higher than usual, and I'd like to understand why. I'm happy to explain, Alex. I'll just verify your account. Could you confirm your full name, last four digits on the card, billing ZSB, and email on file? is alex.bennettbaymail.com. 90 days. Thank you. Verified. Looking at August, I see you carried a balance of $1,920. Your payment posted on September 18, two days after the due date, which triggered a $29 late fee and interest on the average daily balance. That's why September's finance charge is higher. Okay, that tracks. I usually pay on the due date, so I must have years. You do have a strong history. I can submit a one-time courtesy waiver right now. It'll post within 2448 hours and reflect on your next statement. I'd appreciate that. Also, the due date is the 16th. Can I move it closer to my paycheck on the 25th? Absolutely. We can shift your statement cycle so the payment due date lands around the 25th. It will take one cycle to To help avoid this again, I recommend auto-pay for statement balance and push reminders. Would you like me to enroll you now? Yes. Use my Chase checking ending FK 187. Auto-pay set. You'll receive confirmation at alex.bennettbaymail.com. Anything else on the statement? There's a $3.50 from CloudStore. I forgot. That's my storage subscription.\",\n          \"American Express Payments. This is Jordan. How may I assist? Hi Jordan, Priya Meta here. I made a payment from my Wells Fargo account this morning and it hasn't shown up yet. Just checking if that's normal. I'll take a look. May I verify your full name, last four digits, billing ZIPA and E... Priya Meta, 7732, zip 95014. Email priya.meta.df. payment initiated at 8.42am today, reference 7c1-0 to N42. For $600, external bank transfers can take 2448 hours to fully post. Great. And once it posts, my available credit increases right away? Yes, your available credit and fraud thresholds will adjust as soon as it posts. You'll also get a push in email confirmation. Perfect. Can we set auto pay to minimum due\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llm_prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 48,\n        \"samples\": [\n          \"You are given an audio conversation and past conversation happening between an american express customer care professional and a customer.\\nThis customer can be either a genuine customer or a fraudster.\\n\\n## Your Task \\nPredict a probability that the customer is a fraudster\\n\\nIn order to predict the probability of fraud you should think and analyze the situation and create a reasoning.\\nMake sure you see each and every aspect of the case and create a case report while reasoning about the case.\\nNote that the permissible values of probability are 0.0, 0.25, 0.5, 0.75, 1.0\\n\\nThe reasoning process should be enclosed within <think> </think> tags\\nWhile the final answer should be enclosed in <answer> </answer> tags\\n\\nExample Response : \\n<think>This is my reasoning</think>\\n<answer>0.75</answer>\\n\\nPast Conversation : You've reached American Express. Chloe speaking. My new card never arrived. Reship it today to 44 Harbor Industrial RD, Unit C, Albany, NY122, Swell, TQ. Use overnight. I'm sorry to hear that. I'll help after verification. May I have your full name, last four digits, Billings up, and the email we have on file? Jonathan Reed, four-stage stone. I don't have time for the rest. I'm moving warehouses and need the card at Harbor Industrial. For security, I'll send a confirmation to your current email and phone on file. Please approve the request there, then we can discuss delivery options. No, don't contact those. I won't see it. Just ship to the new address. This is urgent. I can only ship to the address on file or a verified alternate after authentication. If the address is changing, we'll need to confirm through a registered channel first. Fine, then call me back on 518-550174 and I'll say approve.\",\n          \"You are given an audio conversation and past conversation happening between an american express customer care professional and a customer.\\nThis customer can be either a genuine customer or a fraudster.\\n\\n## Your Task \\nPredict a probability that the customer is a fraudster\\n\\nIn order to predict the probability of fraud you should think and analyze the situation and create a reasoning.\\nMake sure you see each and every aspect of the case and create a case report while reasoning about the case.\\nNote that the permissible values of probability are 0.0, 0.25, 0.5, 0.75, 1.0\\n\\nThe reasoning process should be enclosed within <think> </think> tags\\nWhile the final answer should be enclosed in <answer> </answer> tags\\n\\nExample Response : \\n<think>This is my reasoning</think>\\n<answer>0.75</answer>\\n\\nPast Conversation : American Express Payments. This is Jordan. How may I assist? Hi Jordan, Priya Meta here. I made a payment from my Wells Fargo account this morning and it hasn't shown up yet. Just checking if that's normal. I'll take a look. May I verify your full name, last four digits, billing ZIPA and E... Priya Meta, 7732, zip 95014. Email priya.meta.df. payment initiated at 8.42am today, reference 7c1-0 to N42. For $600, external bank transfers can take 2448 hours to fully post. Great. And once it posts, my available credit increases right away? Yes, your available credit and fraud thresholds will adjust as soon as it posts. You'll also get a push in email confirmation. Perfect. Can we set auto pay to minimum due\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_split_v1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"test\",\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_chunk_level_data = train_chunk_level_data.sample(frac=1,random_state=1)\n",
        "\n",
        "def get_audio_prompt(user_prompt, audio_path):\n",
        "\n",
        "  messages = [\n",
        "              {\n",
        "                  \"role\": \"user\",\n",
        "                  \"content\": [\n",
        "\n",
        "\n",
        "                      {\"type\": \"audio\", \"path\": audio_path},\n",
        "                       {\"type\": \"text\", \"text\": user_prompt},\n",
        "                  ]\n",
        "              }\n",
        "          ]\n",
        "  return messages\n",
        "\n",
        "daudio_new = {'answer':[],'prompt':[]}\n",
        "\n",
        "for i,r in train_chunk_level_data.iterrows():\n",
        "\n",
        "#  daudio_new_dic = {}\n",
        "  message = get_audio_prompt(r['llm_prompt'],r['file_path'])\n",
        "  typ = r['type']\n",
        "  if typ=='non_fraud':\n",
        "    answer = '0.0'\n",
        "  else:\n",
        "    answer = '1.0'\n",
        "\n",
        "  daudio_new['answer'].append(answer)\n",
        "  daudio_new['prompt'].append(message)\n"
      ],
      "metadata": {
        "id": "mwiTaq4dQbwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(daudio_new['prompt'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OP15OVDVyM0",
        "outputId": "0bd12c2b-1189-4438-dfcd-90e6505bcbe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(daudio_new['prompt'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3tIKk8ZHBCP",
        "outputId": "a407c356-c95f-4bfc-f5ef-83be149f0c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'user',\n",
              "  'content': [{'type': 'audio',\n",
              "    'path': '/content/chunks/id_1/id_1_chunk_0005.mp3'},\n",
              "   {'type': 'text',\n",
              "    'text': \"You are given an audio conversation and past conversation happening between an american express customer care professional and a customer.\\nThis customer can be either a genuine customer or a fraudster.\\n\\n## Your Task \\nPredict a probability that the customer is a fraudster\\n\\nIn order to predict the probability of fraud you should think and analyze the situation and create a reasoning.\\nMake sure you see each and every aspect of the case and create a case report while reasoning about the case.\\nNote that the permissible values of probability are 0.0, 0.25, 0.5, 0.75, 1.0\\n\\nThe reasoning process should be enclosed within <think> </think> tags\\nWhile the final answer should be enclosed in <answer> </answer> tags\\n\\nExample Response : \\n<think>This is my reasoning</think>\\n<answer>0.75</answer>\\n\\nPast Conversation : Thank you for calling American Express. You're speaking with Maya. How can I help today? Hi, Maya. This is Alex Bennett. I'm calling about my September statement. The interest looks a lot higher than usual, and I'd like to understand why. I'm happy to explain, Alex. I'll just verify your account. Could you confirm your full name, last four digits on the card, billing ZSB, and email on file? is alex.bennettbaymail.com. 90 days. Thank you. Verified. Looking at August, I see you carried a balance of $1,920. Your payment posted on September 18, two days after the due date, which triggered a $29 late fee and interest on the average daily balance. That's why September's finance charge is higher. Okay, that tracks. I usually pay on the due date, so I must have years. You do have a strong history. I can submit a one-time courtesy waiver right now. It'll post within 2448 hours and reflect on your next statement. I'd appreciate that. Also, the due date is the 16th. Can I move it closer to my paycheck on the 25th? Absolutely. We can shift your statement cycle so the payment due date lands around the 25th. It will take one cycle to To help avoid this again, I recommend auto-pay for statement balance and push reminders. Would you like me to enroll you now? Yes. Use my Chase checking ending FK 187. Auto-pay set. You'll receive confirmation at alex.bennettbaymail.com. Anything else on the statement? There's a $3.50 from CloudStore. I forgot. That's my storage subscription.\"}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPzGPhf_8htf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c79d1a42-5d28-4fb9-c9f9-2e9eb47c9559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'trl'...\n",
            "remote: Enumerating objects: 16996, done.\u001b[K\n",
            "remote: Counting objects: 100% (474/474), done.\u001b[K\n",
            "remote: Compressing objects: 100% (334/334), done.\u001b[K\n",
            "remote: Total 16996 (delta 376), reused 140 (delta 140), pack-reused 16522 (from 5)\u001b[K\n",
            "Receiving objects: 100% (16996/16996), 13.36 MiB | 21.55 MiB/s, done.\n",
            "Resolving deltas: 100% (12685/12685), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/letsinnovatedotai/trl.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q trackio mistral-common"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpjQV1w2Bbwi",
        "outputId": "a05dc308-6cbd-4a33-a5c2-97a1423904f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/872.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m870.4/872.5 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m872.5/872.5 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m140.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m165.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m158.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SokWfyBB3_dA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eea86406-4bec-4601-fe53-295189d5fe4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r chunks.zip chunks"
      ],
      "metadata": {
        "id": "vpQsp8aXg1Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r save_model_dir.zip save_model_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2KrRU28hJw1",
        "outputId": "3092ce38-283e-48d2-b5e3-17e04f15a469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: save_model_dir/ (stored 0%)\n",
            "  adding: save_model_dir/config.json (deflated 64%)\n",
            "  adding: save_model_dir/model-00002-of-00002.safetensors (deflated 21%)\n",
            "  adding: save_model_dir/model-00001-of-00002.safetensors (deflated 21%)\n",
            "  adding: save_model_dir/preprocessor_config.json (deflated 42%)\n",
            "  adding: save_model_dir/model.safetensors.index.json (deflated 96%)\n",
            "  adding: save_model_dir/generation_config.json (deflated 33%)\n",
            "  adding: save_model_dir/tekken.json (deflated 82%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tOq_3Go8zAv"
      },
      "outputs": [],
      "source": [
        "#cd trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wo8XTr38jcJR"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/trl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9zjXZQDn80li",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0824bd4-a784-48de-f13a-42a9a8d0ffa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./trl\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from trl==0.25.0.dev0) (1.11.0)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from trl==0.25.0.dev0) (4.0.0)\n",
            "Requirement already satisfied: transformers>=4.56.1 in /usr/local/lib/python3.12/dist-packages (from trl==0.25.0.dev0) (4.57.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl==0.25.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl==0.25.0.dev0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl==0.25.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl==0.25.0.dev0) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl==0.25.0.dev0) (2.8.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl==0.25.0.dev0) (0.35.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl==0.25.0.dev0) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.25.0.dev0) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.25.0.dev0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.25.0.dev0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.25.0.dev0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.25.0.dev0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.25.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.25.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.25.0.dev0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.25.0.dev0) (2025.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl==0.25.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl==0.25.0.dev0) (0.22.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.25.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl==0.25.0.dev0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl==0.25.0.dev0) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.25.0.dev0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.25.0.dev0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.25.0.dev0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.25.0.dev0) (2025.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl==0.25.0.dev0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl==0.25.0.dev0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl==0.25.0.dev0) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.25.0.dev0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.25.0.dev0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.25.0.dev0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.25.0.dev0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.25.0.dev0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.25.0.dev0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.25.0.dev0) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl==0.25.0.dev0) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl==0.25.0.dev0) (3.0.3)\n",
            "Building wheels for collected packages: trl\n",
            "  Building wheel for trl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trl: filename=trl-0.25.0.dev0-py3-none-any.whl size=425949 sha256=38df449f1bd3a5a7e3602d2bd74aa0c1dec3696720dded021434940e37d7a84c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n_c0upx4/wheels/3a/45/0e/63c9084b904cb2caa327c3f51a851f636e9599a841018194b1\n",
            "Successfully built trl\n",
            "Installing collected packages: trl\n",
            "Successfully installed trl-0.25.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install trl/."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LO4xBBqJSE3p",
        "outputId": "cda7b9e2-ffb4-4715-94fa-b0c137438957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGlRFwYL9TV5"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "import os\n",
        "import textwrap\n",
        "from collections import defaultdict, deque\n",
        "from contextlib import nullcontext\n",
        "from functools import partial\n",
        "from pathlib import Path\n",
        "from typing import Any, Callable, Optional, Union\n",
        "print(\"h1\")\n",
        "import datasets\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import transformers\n",
        "from accelerate import logging\n",
        "from accelerate.utils import (\n",
        "    broadcast_object_list,\n",
        "    gather,\n",
        "    gather_object,\n",
        "    is_peft_model,\n",
        "    set_seed,\n",
        ")\n",
        "print(\"h2\")\n",
        "from datasets import Dataset, IterableDataset\n",
        "from torch import nn\n",
        "from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n",
        "from torch.utils.data import DataLoader, Sampler\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoProcessor,\n",
        "    AutoTokenizer,\n",
        "    GenerationConfig,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizerBase,\n",
        "    ProcessorMixin,\n",
        "    TrainerCallback,\n",
        "    is_wandb_available,\n",
        ")\n",
        "from transformers.trainer_utils import seed_worker\n",
        "from transformers.utils import (\n",
        "    is_datasets_available,\n",
        "    is_flash_attn_2_available,\n",
        "    is_peft_available,\n",
        "    is_rich_available,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u5Tk9rf9XLo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b7ff221-04bc-4e7b-d240-b322e3d96f5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUU8rhkG9eeT"
      },
      "outputs": [],
      "source": [
        "\n",
        "from trl.data_utils import (\n",
        "    apply_chat_template,\n",
        "    is_conversational,\n",
        "   # maybe_apply_chat_template,\n",
        "    prepare_multimodal_messages,\n",
        ")\n",
        "from trl.extras.profiling import profiling_context, profiling_decorator\n",
        "from trl.extras.vllm_client import VLLMClient\n",
        "from trl.import_utils import is_liger_kernel_available, is_vllm_available\n",
        "from trl.models import (\n",
        "    prepare_deepspeed,\n",
        "    prepare_fsdp,\n",
        "    prepare_peft_model,\n",
        "    unwrap_model_for_generation,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZZUkvBf9n_i"
      },
      "outputs": [],
      "source": [
        "from trl.models.utils import _ForwardRedirection\n",
        "from trl.trainer.base_trainer import BaseTrainer\n",
        "from trl.trainer.callbacks import SyncRefModelCallback\n",
        "from trl.trainer.grpo_config import GRPOConfig\n",
        "from trl.trainer.utils import (\n",
        "    RepeatSampler,\n",
        "    disable_dropout_in_model,\n",
        "    ensure_master_addr_port,\n",
        "    entropy_from_logits,\n",
        "    identity,\n",
        "    nanmax,\n",
        "    nanmin,\n",
        "    nanstd,\n",
        "    pad,\n",
        "    print_prompt_completions_sample,\n",
        "    selective_log_softmax,\n",
        "    shuffle_sequence_dict,\n",
        "    split_pixel_values_by_grid,\n",
        "    split_tensor_dict,\n",
        "    unsplit_pixel_values_by_grid,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ErsOZkR-Q0L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82ff6751-a69e-4670-b263-ec9f587d2dff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grpo_trainer.py called 3\n",
            "peft is available\n",
            "wandb present\n"
          ]
        }
      ],
      "source": [
        "print(\"grpo_trainer.py called 3\")\n",
        "if is_peft_available():\n",
        "    print(\"peft is available\")\n",
        "    from peft import PeftConfig, PeftModel\n",
        "\n",
        "if is_liger_kernel_available():\n",
        "    print(\"liger present\")\n",
        "    from liger_kernel.chunked_loss import LigerFusedLinearGRPOLoss\n",
        "\n",
        "if is_vllm_available():\n",
        "    print(\"vllm present\")\n",
        "    from vllm import LLM, SamplingParams\n",
        "    from vllm.sampling_params import GuidedDecodingParams\n",
        "\n",
        "if is_wandb_available():\n",
        "    print(\"wandb present\")\n",
        "    import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y5YpAVV-TfQ"
      },
      "outputs": [],
      "source": [
        "logger = logging.get_logger(__name__)\n",
        "\n",
        "# What we call a reward function is a callable that takes a list of prompts and completions and returns a list of\n",
        "# rewards. When it's a string, it's a model ID, so it's loaded as a pretrained model.\n",
        "RewardFunc = Union[str, PreTrainedModel, Callable[[list, list], list[float]]]\n",
        "\n",
        "\n",
        "from datetime import datetime, timedelta, timezone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pspq5p7U9CJK"
      },
      "outputs": [],
      "source": [
        "def clog(*ks):\n",
        "    # Define IST timezone (UTC +5:30)\n",
        "    IST = timezone(timedelta(hours=5, minutes=30))\n",
        "    # Get current time in IST\n",
        "    now_ist = datetime.now(IST).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    # Join all arguments into a single string\n",
        "    op_str = \", \".join(str(k) for k in ks)\n",
        "\n",
        "    # Print time and message\n",
        "    print(f\"[{now_ist} IST] {op_str}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgLg0q0s8aQw"
      },
      "outputs": [],
      "source": [
        "\n",
        "gen_ip = \"\"\n",
        "p_t = \"\"\n",
        "gen =\"\"\n",
        "class myGRPOTrainer(BaseTrainer):\n",
        "    \"\"\"Args:\n",
        "        model (`Union[str, PreTrainedModel]`):\n",
        "            Model to be trained. Can be either:\n",
        "\n",
        "            - A string, being the *model id* of a pretrained model hosted inside a model repo on huggingface.co, or a\n",
        "              path to a *directory* containing model weights saved using\n",
        "              [`~transformers.PreTrainedModel.save_pretrained`], e.g., `'./my_model_directory/'`. The model is loaded\n",
        "              using [`~transformers.AutoModelForCausalLM.from_pretrained`] with the keyword arguments in\n",
        "              `args.model_init_kwargs`.\n",
        "            - A [`~transformers.PreTrainedModel`] object. Only causal language models are supported.\n",
        "        reward_funcs (`Union[RewardFunc, list[RewardFunc]]`):\n",
        "            Reward functions to be used for computing the rewards. To compute the rewards, we call all the reward\n",
        "            functions with the prompts and completions and sum the rewards. Can be either:\n",
        "\n",
        "            - A single reward function, such as:\n",
        "                - A string: The *model ID* of a pretrained model hosted inside a model repo on huggingface.co, or a\n",
        "                path to a *directory* containing model weights saved using\n",
        "                [`~transformers.PreTrainedModel.save_pretrained`], e.g., `'./my_model_directory/'`. The model is loaded\n",
        "                using [`~transformers.AutoModelForSequenceClassification.from_pretrained`] with `num_labels=1` and the\n",
        "                keyword arguments in `args.model_init_kwargs`.\n",
        "                - A [`~transformers.PreTrainedModel`] object: Only sequence classification models are supported.\n",
        "                - A custom reward function: The function is provided with the prompts and the generated completions,\n",
        "                  plus any additional columns in the dataset. It should return a list of rewards. Custom reward\n",
        "                  functions can also return `None` when the reward is not applicable to those samples. This is useful\n",
        "                  for multi-task training where different reward functions apply to different types of samples. When a\n",
        "                  reward function returns `None` for a sample, that reward function is excluded from the reward\n",
        "                  calculation for that sample. For more details, see [Using a custom reward\n",
        "                  function](#using-a-custom-reward-function).\n",
        "\n",
        "                  The trainer's state is also passed to the reward function. The trainer's state is an instance of\n",
        "                  [`~transformers.TrainerState`] and can be accessed by accessing the `trainer_state` argument to the\n",
        "                  reward function's signature.\n",
        "            - A list of reward functions, where each item can independently be any of the above types. Mixing different\n",
        "            types within the list (e.g., a string model ID and a custom reward function) is allowed.\n",
        "        args ([`GRPOConfig`], *optional*):\n",
        "            Configuration for this trainer. If `None`, a default configuration is used.\n",
        "        train_dataset ([`~datasets.Dataset`] or [`~datasets.IterableDataset`]):\n",
        "            Dataset to use for training. It must include a column `\"prompt\"`. Any additional columns in the dataset is\n",
        "            ignored. The format of the samples can be either:\n",
        "            - [Standard](dataset_formats#standard): Each sample contains plain text.\n",
        "            - [Conversational](dataset_formats#conversational): Each sample contains structured messages (e.g., role\n",
        "              and content).\n",
        "        eval_dataset ([`~datasets.Dataset`], [`~datasets.IterableDataset`] or `dict[str, Union[Dataset, IterableDataset]]`):\n",
        "            Dataset to use for evaluation. It must meet the same requirements as `train_dataset`.\n",
        "        processing_class ([`~transformers.PreTrainedTokenizerBase`], [`~transformers.ProcessorMixin`], *optional*):\n",
        "            Processing class used to process the data. The padding side must be set to \"left\". If `None`, the\n",
        "            processing class is loaded from the model's name with [`~transformers.AutoProcessor.from_pretrained`]. A\n",
        "            padding token, `tokenizer.pad_token`, must be set. If the processing class has not set a padding token,\n",
        "            `tokenizer.eos_token` will be used as the default.\n",
        "        reward_processing_classes ([`~transformers.PreTrainedTokenizerBase`] or `list[PreTrainedTokenizerBase]`, *optional*):\n",
        "            Processing classes corresponding to the reward functions specified in `reward_funcs`. Can be either:\n",
        "            - A single processing class: Used when `reward_funcs` contains only one reward function.\n",
        "            - A list of processing classes: Must match the order and length of the reward functions in `reward_funcs`.\n",
        "            If set to `None`, or if an element of the list corresponding to a [`~transformers.PreTrainedModel`] is\n",
        "            `None`, the tokenizer for the model is automatically loaded using\n",
        "            [`~transformers.AutoTokenizer.from_pretrained`]. For elements in `reward_funcs` that are custom reward\n",
        "            functions (not [`~transformers.PreTrainedModel`]), the corresponding entries in `reward_processing_classes`\n",
        "            are ignored.\n",
        "        callbacks (list of [`~transformers.TrainerCallback`], *optional*):\n",
        "            List of callbacks to customize the training loop. Will add those to the list of default callbacks detailed\n",
        "            in [here](https://huggingface.co/docs/transformers/main_classes/callback).\n",
        "\n",
        "            If you want to remove one of the default callbacks used, use the [`~transformers.Trainer.remove_callback`]\n",
        "            method.\n",
        "        optimizers (`tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]`, *optional*, defaults to `(None, None)`):\n",
        "            A tuple containing the optimizer and the scheduler to use. Will default to an instance of [`AdamW`] on your\n",
        "            model and a scheduler given by [`get_linear_schedule_with_warmup`] controlled by `args`.\n",
        "        peft_config ([`~peft.PeftConfig`], *optional*):\n",
        "            PEFT configuration used to wrap the model. If `None`, the model is not wrapped.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: Union[str, PreTrainedModel],\n",
        "        reward_funcs: Union[RewardFunc, list[RewardFunc]],\n",
        "        args: Optional[GRPOConfig] = None,\n",
        "        train_dataset: Optional[Union[Dataset, IterableDataset]] = None,\n",
        "        eval_dataset: Optional[\n",
        "            Union[Dataset, IterableDataset, dict[str, Union[Dataset, IterableDataset]]]\n",
        "        ] = None,\n",
        "        processing_class: Optional[\n",
        "            Union[PreTrainedTokenizerBase, ProcessorMixin]\n",
        "        ] = None,\n",
        "        reward_processing_classes: Optional[\n",
        "            Union[PreTrainedTokenizerBase, list[PreTrainedTokenizerBase]]\n",
        "        ] = None,\n",
        "        callbacks: Optional[list[TrainerCallback]] = None,\n",
        "        optimizers: tuple[\n",
        "            Optional[torch.optim.Optimizer], Optional[torch.optim.lr_scheduler.LambdaLR]\n",
        "        ] = (None, None),\n",
        "        peft_config: Optional[\"PeftConfig\"] = None,\n",
        "    ):\n",
        "        clog(\"ENTER GRPOTrainer.__init__\", f\"model={getattr(model, 'name_or_path', model)}\", f\"args_provided={args is not None}\")\n",
        "        # Args\n",
        "        if args is None:\n",
        "            model_name = model if isinstance(model, str) else model.config._name_or_path\n",
        "            model_name = model_name.split(\"/\")[-1]\n",
        "            args = GRPOConfig(f\"{model_name}-GRPO\")\n",
        "\n",
        "        # Models\n",
        "        # Trained model\n",
        "        model_init_kwargs = args.model_init_kwargs or {}\n",
        "        clog(\"model_init_kwargs \",model_init_kwargs)\n",
        "        if isinstance(model, str):\n",
        "            model_id = model\n",
        "            dtype = model_init_kwargs.get(\"dtype\")\n",
        "            if isinstance(dtype, torch.dtype) or dtype == \"auto\" or dtype is None:\n",
        "                pass  # dtype is already a torch.dtype or \"auto\" or None\n",
        "            elif isinstance(dtype, str):  # it's a str, but not \"auto\"\n",
        "                dtype = getattr(torch, dtype)\n",
        "                model_init_kwargs[\"dtype\"] = dtype\n",
        "            else:\n",
        "                raise ValueError(\n",
        "                    \"Invalid `dtype` passed to `GRPOConfig`. Expected either 'auto' or a string representing \"\n",
        "                    f\"a `torch.dtype` (e.g., 'float32'), but got {dtype}.\"\n",
        "                )\n",
        "            # Disable caching if gradient checkpointing is enabled (not supported)\n",
        "            config = AutoConfig.from_pretrained(model_id)\n",
        "            architecture = getattr(transformers, config.architectures[0])\n",
        "            model = architecture.from_pretrained(model_id, **model_init_kwargs)\n",
        "            clog(\"Model loaded from id\", f\"model_id={model_id}\", f\"dtype={dtype}\")\n",
        "        else:\n",
        "            model_id = model.config._name_or_path\n",
        "            if args.model_init_kwargs is not None:\n",
        "                logger.warning(\n",
        "                    \"You passed `model_init_kwargs` to the `GRPOConfig`, but your model is already instantiated. \"\n",
        "                    \"The `model_init_kwargs` will be ignored.\"\n",
        "                )\n",
        "            clog(\"Using provided model instance\", f\"model_id={model_id}\")\n",
        "\n",
        "        # Some models (SmolVLM/Idefics3) don't support `logits_to_keep` argument and error out if we pass it\n",
        "        # Inspect the forward method before we wrap the model with PEFT\n",
        "        self.model_kwarg_keys = (\n",
        "            inspect.signature(model.forward).parameters.keys()\n",
        "            if not hasattr(model, \"get_base_model\")\n",
        "            else inspect.signature(model.get_base_model().forward).parameters.keys()\n",
        "        )\n",
        "        clog(\"Model forward kwargs inspected\", f\"supports_logits_to_keep={'logits_to_keep' in self.model_kwarg_keys}\")\n",
        "\n",
        "        if peft_config is not None or (\n",
        "            is_peft_available() and isinstance(model, PeftModel)\n",
        "        ):\n",
        "            clog(\"Preparing PEFT model\")\n",
        "            model = prepare_peft_model(model, peft_config, args)\n",
        "            clog(\"PEFT prepared\")\n",
        "\n",
        "        # Processing class\n",
        "        if processing_class is None:\n",
        "            processing_class = AutoProcessor.from_pretrained(\n",
        "                model.config._name_or_path, truncation_side=\"left\"\n",
        "            )\n",
        "            clog(\"AutoProcessor internally loaded\", f\"name_or_path={model.config._name_or_path}\")\n",
        "\n",
        "        # Handle pad token for processors or tokenizers\n",
        "        if isinstance(processing_class, ProcessorMixin):\n",
        "            tokenizer = processing_class.tokenizer\n",
        "            clog(\"setting tokenizer = processing_class.tokenizer\")\n",
        "        elif isinstance(processing_class, PreTrainedTokenizerBase):\n",
        "            tokenizer = processing_class\n",
        "            clog(\"setting tokenizer = processing_class\")\n",
        "        else:\n",
        "            raise TypeError(\n",
        "                \"The `processing_class` must be either a `PreTrainedTokenizerBase` or a `ProcessorMixin`\"\n",
        "            )\n",
        "\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "        self.pad_token = tokenizer.pad_token\n",
        "        self.pad_token_id = tokenizer.pad_token_id\n",
        "        self.eos_token_id = tokenizer.eos_token_id\n",
        "        clog(\"Tokenizer configured\", f\"pad_token_id={self.pad_token_id}\", f\"eos_token_id={self.eos_token_id}\")\n",
        "\n",
        "        # Reward functions\n",
        "        if not isinstance(reward_funcs, list):\n",
        "            reward_funcs = [reward_funcs]\n",
        "        self.reward_func_names = []\n",
        "        for i, reward_func in enumerate(reward_funcs):\n",
        "            if isinstance(reward_func, str):\n",
        "                clog(\"reward_func is str\")\n",
        "                reward_funcs[i] = AutoModelForSequenceClassification.from_pretrained(\n",
        "                    reward_func, num_labels=1, **model_init_kwargs\n",
        "                )\n",
        "            if isinstance(\n",
        "                reward_funcs[i], nn.Module\n",
        "            ):  # Use Module over PretrainedModel for compat w/ compiled models\n",
        "                clog(\"reward_func is nn.Module\")\n",
        "                self.reward_func_names.append(\n",
        "                    reward_funcs[i].config._name_or_path.split(\"/\")[-1]\n",
        "                )\n",
        "            else:\n",
        "                self.reward_func_names.append(reward_funcs[i].__name__)\n",
        "        self.reward_funcs = reward_funcs\n",
        "        clog(\"Reward funcs prepared\", f\"count={len(self.reward_funcs)}\", f\"names={self.reward_func_names}\")\n",
        "\n",
        "        # Reward weights\n",
        "        if args.reward_weights is not None:\n",
        "            clog(\"args.reward_weights is not None\")\n",
        "            if len(args.reward_weights) != len(reward_funcs):\n",
        "                raise ValueError(\n",
        "                    f\"Number of reward weights ({len(args.reward_weights)}) must match number of reward \"\n",
        "                    f\"functions ({len(reward_funcs)})\"\n",
        "                )\n",
        "            self.reward_weights = torch.tensor(args.reward_weights, dtype=torch.float32)\n",
        "        else:\n",
        "            clog(\"args.reward_weights is None\")\n",
        "            self.reward_weights = torch.ones(len(reward_funcs), dtype=torch.float32)\n",
        "        clog(\"Reward weights\",self.reward_weights)\n",
        "\n",
        "        # Reward processing class\n",
        "        if reward_processing_classes is None:\n",
        "            clog(\"reward_processing_classes is None \")\n",
        "            reward_processing_classes = [None] * len(reward_funcs)\n",
        "        elif not isinstance(reward_processing_classes, list):\n",
        "            reward_processing_classes = [reward_processing_classes]\n",
        "        if len(reward_processing_classes) != len(reward_funcs):\n",
        "            raise ValueError(\n",
        "                f\"The number of reward processing classes ({len(reward_processing_classes)}) must match the number of \"\n",
        "                f\"reward functions ({len(reward_funcs)}).\"\n",
        "            )\n",
        "\n",
        "        for i, (reward_processing_class, reward_func) in enumerate(\n",
        "            zip(reward_processing_classes, reward_funcs)\n",
        "        ):\n",
        "            if isinstance(reward_func, PreTrainedModel):\n",
        "                if reward_processing_class is None:\n",
        "                    reward_processing_class = AutoTokenizer.from_pretrained(\n",
        "                        reward_func.config._name_or_path\n",
        "                    )\n",
        "                if reward_processing_class.pad_token_id is None:\n",
        "                    reward_processing_class.pad_token = (\n",
        "                        reward_processing_class.eos_token\n",
        "                    )\n",
        "                # The reward model computes the reward for the latest non-padded token in the input sequence.\n",
        "                # So it's important to set the pad token ID to the padding token ID of the processing class.\n",
        "                reward_func.config.pad_token_id = reward_processing_class.pad_token_id\n",
        "                reward_processing_classes[i] = reward_processing_class\n",
        "\n",
        "        self.reward_processing_classes = reward_processing_classes\n",
        "        clog(\"Reward processing classes prepared\", reward_processing_classes)\n",
        "        # Training arguments\n",
        "        self.max_prompt_length = args.max_prompt_length\n",
        "        self.max_completion_length = (\n",
        "            args.max_completion_length\n",
        "        )  # = |o_i| in the GRPO paper\n",
        "        self.num_generations = args.num_generations  # = G in the GRPO paper\n",
        "        self.temperature = args.temperature\n",
        "        self.top_p = args.top_p\n",
        "        self.top_k = args.top_k\n",
        "        self.min_p = args.min_p\n",
        "        self.repetition_penalty = args.repetition_penalty\n",
        "        self.use_transformers_paged = args.use_transformers_paged\n",
        "        self.use_vllm = args.use_vllm\n",
        "        self.vllm_mode = args.vllm_mode\n",
        "        self.vllm_gpu_memory_utilization = (\n",
        "            args.vllm_gpu_memory_utilization\n",
        "        )  # only applies to colocation mode\n",
        "        self.vllm_tensor_parallel_size = (\n",
        "            args.vllm_tensor_parallel_size\n",
        "        )  # only applies to colocation mode\n",
        "        self.vllm_importance_sampling_correction = (\n",
        "            args.vllm_importance_sampling_correction\n",
        "        )\n",
        "        self.vllm_importance_sampling_cap = args.vllm_importance_sampling_cap\n",
        "        self.use_liger_loss = args.use_liger_loss\n",
        "        self.loss_type = args.loss_type\n",
        "        self.scale_rewards = args.scale_rewards\n",
        "        self.importance_sampling_level = args.importance_sampling_level\n",
        "        self.mask_truncated_completions = args.mask_truncated_completions\n",
        "        self.top_entropy_quantile = args.top_entropy_quantile\n",
        "        clog(\"Train args\",\n",
        "             f\"max_prompt_length={self.max_prompt_length}\",\n",
        "             f\"max_completion_length={self.max_completion_length}\",\n",
        "             f\"num_generations={self.num_generations}\",\n",
        "             f\"use_vllm={self.use_vllm}\",\n",
        "             f\"vllm_mode={self.vllm_mode}\",\n",
        "             f\"use_liger_loss={self.use_liger_loss}\",\n",
        "             f\"loss_type={self.loss_type}\")\n",
        "\n",
        "        if self.use_liger_loss and self.top_entropy_quantile < 1.0:\n",
        "            raise NotImplementedError(\n",
        "                \"Liger Kernels don't currently support masking token positions based on entropy.\"\n",
        "            )\n",
        "        if self.use_liger_loss and not self.importance_sampling_level == \"token\":\n",
        "            raise NotImplementedError(\n",
        "                \"Liger Kernels currently only support token-level importance sampling. Please set\"\n",
        "                \"`importance_sampling_level` to 'token'.\"\n",
        "            )\n",
        "\n",
        "        # Datasets\n",
        "        self.shuffle_dataset = args.shuffle_dataset\n",
        "        clog(\"self.shuffle_dataset \",self.shuffle_dataset)\n",
        "        if (\n",
        "            isinstance(train_dataset, IterableDataset)\n",
        "            or isinstance(eval_dataset, IterableDataset)\n",
        "            or (\n",
        "                isinstance(eval_dataset, dict)\n",
        "                and any(isinstance(ds, IterableDataset) for ds in eval_dataset.values())\n",
        "            )\n",
        "        ):\n",
        "            # See https://github.com/huggingface/trl/issues/3213\n",
        "            raise NotImplementedError(\n",
        "                \"Iterable datasets are not yet supported in GRPOTrainer. Please use a standard dataset instead.\"\n",
        "            )\n",
        "\n",
        "        # Multi-step\n",
        "        self.num_iterations = args.num_iterations  # = 𝜇 in the GRPO paper\n",
        "        self.epsilon_low = args.epsilon\n",
        "        self.epsilon_high = (\n",
        "            args.epsilon_high if args.epsilon_high is not None else args.epsilon\n",
        "        )\n",
        "        # Tracks the number of iterations (forward + backward passes), including those within a grad accum cycle\n",
        "        self._step = 0\n",
        "        # Buffer the batch to reuse generated outputs across multiple updates. For more details, see\n",
        "        # `_get_train_sampler` and `_prepare_inputs`.\n",
        "        self._buffered_inputs = None\n",
        "\n",
        "        # The trainer estimates the number of FLOPs (floating-point operations) using the number of elements in the\n",
        "        # input tensor associated with the key \"input_ids\". However, in GRPO, the sampled data does not include the\n",
        "        # \"input_ids\" key. Instead, the available keys is \"prompt\". As a result, the trainer issues the warning:\n",
        "        # \"Could not estimate the number of tokens of the input, floating-point operations will not be computed.\" To\n",
        "        # suppress this warning, we set the \"estimate_tokens\" key in the model's \"warnings_issued\" dictionary to True.\n",
        "        # This acts as a flag to indicate that the warning has already been issued.\n",
        "        model.warnings_issued[\"estimate_tokens\"] = True\n",
        "\n",
        "        super().__init__(\n",
        "            model=model,\n",
        "            args=args,\n",
        "            data_collator=identity,  # No data collation is needed in GRPO\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=eval_dataset,\n",
        "            processing_class=processing_class,\n",
        "            callbacks=callbacks,\n",
        "            optimizers=optimizers,\n",
        "            # In Trainer, `training_step` scales the loss by `gradient_accumulation_steps` only if `compute_loss_func`\n",
        "            # is None. For DAPO, loss scaling instead depends on the total number of completions tokens across the\n",
        "            # global accumulated batch. To control scaling ourselves, we must disable Trainer’s built-in scaling. The\n",
        "            # simplest (though a bit hacky) way is to set `compute_loss_func` to any non-None value, which bypasses\n",
        "            # that behavior without rewriting `training_step`.\n",
        "            compute_loss_func=\"non-None value to disable scaling\",\n",
        "        )\n",
        "        clog(\"BaseTrainer initialized\", f\"per_device_train_batch_size={self.args.per_device_train_batch_size}\")\n",
        "\n",
        "        # Reference model\n",
        "        self.beta = args.beta\n",
        "        if self.beta == 0.0:\n",
        "            # If beta is 0.0, the reference model is not needed\n",
        "            self.ref_model = None\n",
        "            clog(\"Ref model disabled (beta=0.0)\")\n",
        "        elif is_peft_model(model):\n",
        "            # If PEFT is used, the reference model is not needed since the adapter can be disabled\n",
        "            # to revert to the initial model.\n",
        "            self.ref_model = None\n",
        "            clog(\"Ref model not needed (PEFT active)\")\n",
        "        else:\n",
        "            # For deepspeed, fsdp or non-distributed models, create a reference model from scratch\n",
        "            config = AutoConfig.from_pretrained(model_id)\n",
        "            architecture = getattr(transformers, config.architectures[0])\n",
        "            self.ref_model = architecture.from_pretrained(model_id, **model_init_kwargs)\n",
        "            clog(\"Ref model created\", f\"model_id={model_id}\")\n",
        "\n",
        "        # Disable dropout in the models\n",
        "        if args.disable_dropout:\n",
        "            disable_dropout_in_model(model)\n",
        "            if self.ref_model is not None:\n",
        "                disable_dropout_in_model(self.ref_model)\n",
        "            clog(\"Dropout disabled\")\n",
        "\n",
        "        # Liger loss\n",
        "        if self.use_liger_loss:\n",
        "            if not is_liger_kernel_available():\n",
        "                raise ImportError(\n",
        "                    \"Liger is required to use `liger_loss` as the GRPO loss. Run `pip install liger-kernel`.\"\n",
        "                )\n",
        "            # redirect the model.module forward to the model forward to ensure pre-forward hooks are called\n",
        "            self._forward_redirection = _ForwardRedirection()\n",
        "\n",
        "            self.liger_grpo_loss = LigerFusedLinearGRPOLoss(\n",
        "                beta=self.beta,\n",
        "                epsilon_low=self.epsilon_low,\n",
        "                epsilon_high=self.epsilon_high,\n",
        "                temperature=self.temperature,\n",
        "                use_ref_model=self.beta != 0.0,\n",
        "                loss_type=self.loss_type,\n",
        "                max_completion_length=self.max_completion_length,\n",
        "            )\n",
        "            clog(\"Liger loss initialized\")\n",
        "\n",
        "        # Initialize the metrics\n",
        "        self._metrics = {\"train\": defaultdict(list), \"eval\": defaultdict(list)}\n",
        "        self._total_train_tokens = 0\n",
        "        self.log_completions = args.log_completions\n",
        "        self.wandb_log_unique_prompts = args.wandb_log_unique_prompts\n",
        "        self.num_completions_to_print = args.num_completions_to_print\n",
        "        # Keep logs sized to the generation batch to record only outputs from the latest model update.\n",
        "        self._logs = {\n",
        "            \"images\": deque(maxlen=args.generation_batch_size),\n",
        "            \"prompt\": deque(maxlen=args.generation_batch_size),\n",
        "            \"completion\": deque(maxlen=args.generation_batch_size),\n",
        "            \"rewards\": defaultdict(lambda: deque(maxlen=args.generation_batch_size)),\n",
        "            \"advantages\": deque(maxlen=args.generation_batch_size),\n",
        "        }\n",
        "\n",
        "        # Ensure each process receives a unique seed to prevent duplicate completions when generating with\n",
        "        # transformers if num_generations exceeds per_device_train_batch_size. We could skip it if we use vLLM, but\n",
        "        # it's safer to set it in all cases.\n",
        "        set_seed(args.seed, device_specific=True)\n",
        "        clog(\"Seed set\", f\"seed={args.seed}\")\n",
        "\n",
        "        if self.use_vllm:\n",
        "            clog(\"using vllm\")\n",
        "            if not is_vllm_available():\n",
        "                raise ImportError(\n",
        "                    \"vLLM is not available and `use_vllm` is set to True. Please install vLLM with \"\n",
        "                    \"`pip install trl[vllm]` to use it.\"\n",
        "                )\n",
        "\n",
        "            if self.vllm_mode == \"server\":\n",
        "\n",
        "                if self.accelerator.is_main_process:\n",
        "                    if args.vllm_server_base_url is not None:\n",
        "                        base_url = args.vllm_server_base_url\n",
        "                    else:\n",
        "                        base_url = (\n",
        "                            f\"http://{args.vllm_server_host}:{args.vllm_server_port}\"\n",
        "                        )\n",
        "                    self.vllm_client = VLLMClient(\n",
        "                        base_url=base_url, connection_timeout=args.vllm_server_timeout\n",
        "                    )\n",
        "                    self.vllm_client.init_communicator(\n",
        "                        device=torch.cuda.current_device()\n",
        "                    )\n",
        "                    clog(\"vLLM server client initialized\", f\"base_url={base_url}\")\n",
        "\n",
        "            elif self.vllm_mode == \"colocate\":\n",
        "                # Make sure vllm_tensor_parallel_size group size evenly divides the world size - each group should have\n",
        "                # the same number of ranks\n",
        "                if (\n",
        "                    not self.accelerator.num_processes % self.vllm_tensor_parallel_size\n",
        "                    == 0\n",
        "                ):\n",
        "                    raise ValueError(\n",
        "                        f\"vllm_tensor_parallel_size ({self.vllm_tensor_parallel_size}) must divide world size \"\n",
        "                        f\"({self.accelerator.num_processes}) evenly.\"\n",
        "                    )\n",
        "\n",
        "                if self.vllm_tensor_parallel_size > 1:\n",
        "                    # Create subgroups of ranks for TP, each group with `vllm_tensor_parallel_size` ranks.\n",
        "                    # For example, if world_size=8 and vllm_tensor_parallel_size=2 → groups: [0,1], [2,3], [4,5], [6,7]\n",
        "                    self.tp_group, _ = torch.distributed.new_subgroups_by_enumeration(\n",
        "                        [\n",
        "                            list(\n",
        "                                range(\n",
        "                                    i * self.vllm_tensor_parallel_size,\n",
        "                                    (i + 1) * self.vllm_tensor_parallel_size,\n",
        "                                )\n",
        "                            )\n",
        "                            for i in range(\n",
        "                                self.accelerator.num_processes\n",
        "                                // self.vllm_tensor_parallel_size\n",
        "                            )\n",
        "                        ]\n",
        "                    )\n",
        "                    clog(\"vLLM TP groups created\", f\"tp_size={self.vllm_tensor_parallel_size}\")\n",
        "\n",
        "                # vLLM requires the environment variables to be set for distributed training.\n",
        "                os.environ[\"RANK\"] = str(self.accelerator.process_index)\n",
        "                os.environ[\"LOCAL_RANK\"] = str(self.accelerator.local_process_index)\n",
        "                os.environ[\"WORLD_SIZE\"] = str(self.accelerator.num_processes)\n",
        "                # Ensure distributed rendezvous variables are set without colliding across concurrent runs\n",
        "                ensure_master_addr_port()\n",
        "\n",
        "                if (\n",
        "                    self.max_prompt_length is not None\n",
        "                    and self.max_completion_length is not None\n",
        "                ):\n",
        "                    max_model_len = self.max_prompt_length + self.max_completion_length\n",
        "                else:\n",
        "                    max_model_len = None\n",
        "                self.llm = LLM(\n",
        "                    model=model.name_or_path,\n",
        "                    tensor_parallel_size=args.vllm_tensor_parallel_size,\n",
        "                    gpu_memory_utilization=self.vllm_gpu_memory_utilization,\n",
        "                    max_num_seqs=self.args.per_device_train_batch_size\n",
        "                    * self.vllm_tensor_parallel_size\n",
        "                    * self.args.steps_per_generation,\n",
        "                    max_model_len=max_model_len,\n",
        "                    distributed_executor_backend=\"external_launcher\",\n",
        "                    # Feed identical seed for tp groups to ensure sampling results are the same across workers\n",
        "                    seed=self.accelerator.process_index\n",
        "                    // self.vllm_tensor_parallel_size,\n",
        "                    # Latest vLLM v1 memory profiler is misled by the high default value (i.e., 32768) - thinking there's not enough memory\n",
        "                    max_num_batched_tokens=4096,\n",
        "                    model_impl=self.args.vllm_model_impl,\n",
        "                    enable_sleep_mode=self.args.vllm_enable_sleep_mode,\n",
        "                    # Important so temperature scaling/logit tweaking affects the TIS log probs\n",
        "                    logprobs_mode=\"processed_logprobs\",\n",
        "                )\n",
        "                if self.args.vllm_enable_sleep_mode:\n",
        "                    self.llm.sleep(level=1)\n",
        "                clog(\"vLLM colocated LLM initialized\", f\"max_model_len={max_model_len}\")\n",
        "            else:\n",
        "                raise ValueError(\n",
        "                    f\"vllm_mode must be either 'server' or 'colocate', got '{self.vllm_mode}'.\"\n",
        "                )\n",
        "\n",
        "            # vLLM specific sampling arguments\n",
        "            self.guided_decoding_regex = args.vllm_guided_decoding_regex\n",
        "\n",
        "            self._last_loaded_step = (\n",
        "                -1\n",
        "            )  # tag to avoid useless loading during grad accumulation\n",
        "\n",
        "            # When using vLLM, the main process is responsible for loading the model weights. This can cause process\n",
        "            # desynchronization and seems to lead to DeepSpeed hanging during initialization. To prevent this, we\n",
        "            # synchronize all processes after vLLM has been fully initialized.\n",
        "            self.accelerator.wait_for_everyone()\n",
        "            clog(\"vLLM setup complete\")\n",
        "        else:\n",
        "            generation_kwargs = {\n",
        "                \"max_new_tokens\": self.max_completion_length,\n",
        "                \"do_sample\": True,\n",
        "                \"pad_token_id\": tokenizer.pad_token_id,\n",
        "                \"bos_token_id\": tokenizer.bos_token_id,\n",
        "                \"eos_token_id\": tokenizer.eos_token_id,\n",
        "                \"temperature\": self.temperature,\n",
        "                \"top_p\": self.top_p,\n",
        "                \"top_k\": self.top_k,\n",
        "                \"min_p\": self.min_p,\n",
        "                \"repetition_penalty\": self.repetition_penalty,\n",
        "                \"cache_implementation\": args.cache_implementation,\n",
        "            }\n",
        "            if args.generation_kwargs is not None:\n",
        "                generation_kwargs.update(args.generation_kwargs)\n",
        "            self.generation_config = GenerationConfig(**generation_kwargs)\n",
        "            clog(\"Transformers generation_kwargs\",generation_kwargs)\n",
        "\n",
        "        # Gradient accumulation requires scaled loss. Normally, loss scaling in the parent class depends on whether the\n",
        "        # model accepts loss-related kwargs. Since we compute our own loss, this check is irrelevant. We set\n",
        "        # self.model_accepts_loss_kwargs to False to enable scaling.\n",
        "        self.model_accepts_loss_kwargs = False\n",
        "\n",
        "        # Add tags to the model\n",
        "        self.model.add_model_tags(self._tag_names)\n",
        "        clog(\"Model tags added\", f\"tags={self._tag_names}\")\n",
        "\n",
        "        if self.ref_model is not None:\n",
        "            clog(\"Ref model preparing\")\n",
        "            if self.is_deepspeed_enabled:\n",
        "                clog(\"deepseed is enabled\")\n",
        "                self.ref_model = prepare_deepspeed(self.ref_model, self.accelerator)\n",
        "            elif self.is_fsdp_enabled:\n",
        "                clog(\"fsdp is enabled\")\n",
        "                self.ref_model = prepare_fsdp(self.ref_model, self.accelerator)\n",
        "            else:\n",
        "                clog(\"using accelerator\")\n",
        "                self.ref_model = self.accelerator.prepare_model(\n",
        "                    self.ref_model, evaluation_mode=True\n",
        "                )\n",
        "\n",
        "\n",
        "        if args.sync_ref_model:\n",
        "            self.add_callback(\n",
        "                SyncRefModelCallback(\n",
        "                    ref_model=self.ref_model, accelerator=self.accelerator\n",
        "                )\n",
        "            )\n",
        "            clog(\"SyncRefModelCallback added\")\n",
        "\n",
        "        for i, reward_func in enumerate(self.reward_funcs):\n",
        "            if isinstance(reward_func, PreTrainedModel):\n",
        "                if self.is_deepspeed_enabled:\n",
        "                    self.reward_funcs[i] = prepare_deepspeed(\n",
        "                        reward_func, self.accelerator\n",
        "                    )\n",
        "                else:\n",
        "                    # set device placement to True to make `prepare_model` move `reward_func` to device when using fsdp\n",
        "                    self.reward_funcs[i] = self.accelerator.prepare_model(\n",
        "                        reward_func, evaluation_mode=True, device_placement=True\n",
        "                    )\n",
        "        clog(\"END GRPOTrainer.__init__\")\n",
        "\n",
        "    def _set_signature_columns_if_needed(self):\n",
        "        clog(\"ENTER _set_signature_columns_if_needed\")\n",
        "        # If `self.args.remove_unused_columns` is True, non-signature columns are removed.\n",
        "        # By default, this method sets `self._signature_columns` to the model's expected inputs.\n",
        "        # In GRPOTrainer, we preprocess data, so using the model's signature columns doesn't work.\n",
        "        # Instead, we set them to the columns expected by the `training_step` method, hence the override.\n",
        "        if self._signature_columns is None:\n",
        "            self._signature_columns = [\"prompt\", \"image\", \"images\"]\n",
        "            clog(\"Set signature columns\", f\"columns={self._signature_columns}\")\n",
        "        clog(\"END _set_signature_columns_if_needed\")\n",
        "\n",
        "    def get_train_dataloader(self):\n",
        "        clog(\"ENTER get_train_dataloader \",\"No_1\")\n",
        "        if self.train_dataset is None:\n",
        "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
        "\n",
        "        train_dataset = self.train_dataset\n",
        "        data_collator = self.data_collator\n",
        "        if is_datasets_available() and isinstance(train_dataset, datasets.Dataset):\n",
        "            clog(\"defining train_dataset\")\n",
        "            train_dataset = self._remove_unused_columns(\n",
        "                train_dataset, description=\"training\"\n",
        "            )\n",
        "            clog(\"train_dataset \",train_dataset)\n",
        "        else:\n",
        "            clog(\"defining data_collator\")\n",
        "            data_collator = self._get_collator_with_removed_columns(\n",
        "                data_collator, description=\"training\"\n",
        "            )\n",
        "            clog(\"data_collator \",data_collator)\n",
        "\n",
        "        clog(\"train_dataset \",train_dataset)\n",
        "\n",
        "        clog(\"self._train_batch_size * self.args.steps_per_generation \", self._train_batch_size * self.args.steps_per_generation)\n",
        "        dataloader_params = {\n",
        "            \"batch_size\": self._train_batch_size\n",
        "            * self.args.steps_per_generation,  # < this is the change\n",
        "            \"collate_fn\": data_collator,\n",
        "            \"num_workers\": self.args.dataloader_num_workers,\n",
        "            \"pin_memory\": self.args.dataloader_pin_memory,\n",
        "            \"persistent_workers\": self.args.dataloader_persistent_workers,\n",
        "        }\n",
        "        clog(\"Dataloader params \", dataloader_params)\n",
        "\n",
        "        if not isinstance(train_dataset, torch.utils.data.IterableDataset):\n",
        "            clog(\"not isinstance(train_dataset, torch.utils.data.IterableDataset)\")\n",
        "            dataloader_params[\"sampler\"] = self._get_train_sampler()\n",
        "            dataloader_params[\"drop_last\"] = self.args.dataloader_drop_last\n",
        "            dataloader_params[\"worker_init_fn\"] = partial(\n",
        "                seed_worker,\n",
        "                num_workers=self.args.dataloader_num_workers,\n",
        "                rank=self.args.process_index,\n",
        "            )\n",
        "\n",
        "            dataloader_params[\"prefetch_factor\"] = self.args.dataloader_prefetch_factor\n",
        "\n",
        "        clog(\"Dataloader params \", dataloader_params)\n",
        "        dl = self.accelerator.prepare(DataLoader(train_dataset, **dataloader_params))\n",
        "        clog(\"dl is \",dl)\n",
        "        clog(\"END get_train_dataloader\")\n",
        "        return dl\n",
        "\n",
        "    def _get_train_sampler(self, dataset: Optional[Dataset] = None) -> Sampler:\n",
        "        clog(\"ENTER _get_train_sampler\", f\"dataset_provided={dataset is not None}\")\n",
        "        # Returns a sampler that\n",
        "        # 1. ensures each prompt is repeated across multiple processes. This guarantees that identical prompts are\n",
        "        #    distributed to different GPUs, allowing rewards to be computed and normalized correctly within each prompt\n",
        "        #    group. Using the same seed across processes ensures consistent prompt assignment, preventing discrepancies\n",
        "        #    in group formation.\n",
        "        # 2. repeats the batch multiple times to allow reusing generations across multiple updates. Refer to\n",
        "        #    _prepare_inputs to see how the generations are stored and reused.\n",
        "        if dataset is None:\n",
        "            dataset = self.train_dataset\n",
        "        sampler = RepeatSampler(\n",
        "            data_source=dataset,\n",
        "            mini_repeat_count=self.num_generations,\n",
        "            batch_size=self.args.generation_batch_size // self.num_generations,\n",
        "            repeat_count=self.num_iterations * self.args.steps_per_generation,\n",
        "            shuffle=self.shuffle_dataset,\n",
        "            seed=self.args.seed,\n",
        "        )\n",
        "        clog(\"END _get_train_sampler\",\n",
        "             f\"mini_repeat_count={self.num_generations}\",\n",
        "             f\"batch_size={self.args.generation_batch_size // self.num_generations}\",\n",
        "             f\"repeat_count={self.num_iterations * self.args.steps_per_generation}\",\n",
        "             f\"shuffle={self.shuffle_dataset}\")\n",
        "        return sampler\n",
        "\n",
        "    def _get_eval_sampler(self, eval_dataset) -> Sampler:\n",
        "        clog(\"ENTER _get_eval_sampler\")\n",
        "        sampler = RepeatSampler(\n",
        "            data_source=eval_dataset,\n",
        "            mini_repeat_count=self.num_generations,\n",
        "            seed=self.args.seed,\n",
        "        )\n",
        "        clog(\"END _get_eval_sampler\", f\"mini_repeat_count={self.num_generations}\")\n",
        "        return sampler\n",
        "\n",
        "    @profiling_decorator\n",
        "    def _get_last_hidden_state(\n",
        "        self,\n",
        "        unwrapped_model,\n",
        "        input_ids,\n",
        "        attention_mask,\n",
        "        logits_to_keep,\n",
        "        pixel_values=None,\n",
        "        image_grid_thw=None,\n",
        "        pixel_attention_mask=None,\n",
        "        image_sizes=None,\n",
        "    ):\n",
        "        clog(\"ENTER _get_last_hidden_state\",\n",
        "             f\"input_ids.shape={tuple(input_ids.shape)}\",\n",
        "             f\"attention_mask.shape={tuple(attention_mask.shape)}\",\n",
        "             f\"logits_to_keep={logits_to_keep}\",\n",
        "             f\"pixel_values={'None' if pixel_values is None else 'set'}\")\n",
        "        if is_peft_model(unwrapped_model):\n",
        "            unwrapped_model = unwrapped_model.base_model.model\n",
        "\n",
        "        # Build model inputs - check if the model supports logits_to_keep (some models and VLMs don't)\n",
        "        model_inputs = {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
        "\n",
        "        # For Qwen models:\n",
        "        if image_grid_thw is not None and pixel_values is not None:\n",
        "            model_inputs[\"image_grid_thw\"] = image_grid_thw\n",
        "        # For Gemma, SmolVLM2, LLaVa-Next etc.:\n",
        "        if pixel_values is not None:\n",
        "            model_inputs[\"pixel_values\"] = pixel_values\n",
        "        # For SmolVLM2\n",
        "        if pixel_attention_mask is not None:\n",
        "            model_inputs[\"pixel_attention_mask\"] = pixel_attention_mask\n",
        "        # For LLaVa-Next\n",
        "        if image_sizes is not None:\n",
        "            model_inputs[\"image_sizes\"] = image_sizes\n",
        "\n",
        "        # Only add logits_to_keep if the model supports it\n",
        "        if \"logits_to_keep\" in self.model_kwarg_keys:\n",
        "            # We add 1 to `logits_to_keep` because the last logits of the sequence is later excluded\n",
        "            model_inputs[\"logits_to_keep\"] = logits_to_keep + 1\n",
        "\n",
        "        model_inputs[\"use_cache\"] = (\n",
        "            False  # only used in generation; set False to suppress warnings\n",
        "        )\n",
        "\n",
        "        last_hidden_state = unwrapped_model.model(**model_inputs).last_hidden_state\n",
        "        # Exclude the last value: it corresponds to the next token pred\n",
        "        last_hidden_state = last_hidden_state[:, :-1, :]  # (B, L-1, H)\n",
        "        # Only keep the last logits_to_keep. For model that support logits_to_keep, this is a no-op.\n",
        "        last_hidden_state = last_hidden_state[\n",
        "            :, -logits_to_keep:, :\n",
        "        ]  # (B, logits_to_keep, H)\n",
        "        clog(\"END _get_last_hidden_state\", f\"last_hidden_state.shape={tuple(last_hidden_state.shape)}\")\n",
        "        return last_hidden_state\n",
        "\n",
        "    def get_high_entropy_mask(\n",
        "        self, entropies: torch.Tensor, mask: torch.Tensor, threshold: float\n",
        "    ) -> torch.Tensor:\n",
        "        clog(\"ENTER get_high_entropy_mask\",\n",
        "             f\"entropies.shape={tuple(entropies.shape)}\",\n",
        "             f\"mask.shape={tuple(mask.shape)}\",\n",
        "             f\"threshold={threshold}\")\n",
        "        \"\"\"\n",
        "        Returns a binary mask identifying tokens whose entropy exceeds a given quantile threshold.\n",
        "\n",
        "        Args:\n",
        "            entropies (`torch.Tensor`):\n",
        "                Tensor of shape (batch_size, seq_len) with per-token entropy values.\n",
        "            mask (`torch.Tensor`):\n",
        "                Binary mask of the same shape as `entropies`, where `1` indicates valid tokens and `0` padding.\n",
        "            threshold (`float`):\n",
        "                Quantile threshold between `0.0` and `1.0` to select high-entropy tokens.\n",
        "\n",
        "        Returns:\n",
        "            `torch.Tensor`:\n",
        "                Boolean mask of shape (batch_size, seq_len), where `True` indicates tokens with entropy >= threshold\n",
        "                and `False` otherwise.\n",
        "        \"\"\"\n",
        "        local = entropies[mask.bool()].float()\n",
        "\n",
        "        # Use a negative pad_value as a sentinel because entropy values are always >= 0.\n",
        "        # This guarantees that the sentinel cannot collide with any real entropy value.\n",
        "        pad_value = -1e9\n",
        "\n",
        "        # Pad across processes so that every rank has the same tensor length\n",
        "        padded = self.accelerator.pad_across_processes(\n",
        "            local, dim=0, pad_index=pad_value\n",
        "        )\n",
        "        gathered = self.accelerator.gather(padded)\n",
        "\n",
        "        # Drop sentinel values (safe because no entropy can be negative)\n",
        "        gathered = gathered[gathered != pad_value]\n",
        "\n",
        "        if gathered.numel() == 0:\n",
        "            clog(\"END get_high_entropy_mask\", \"no_valid_tokens=True\")\n",
        "            return torch.zeros_like(entropies, dtype=torch.bool)\n",
        "\n",
        "        entropy_threshold = torch.quantile(gathered, threshold)\n",
        "        masked_entropies = entropies * mask.float()\n",
        "        entropy_mask = masked_entropies >= entropy_threshold\n",
        "        result = entropy_mask & mask.bool()  # ensure padding tokens are always masked out\n",
        "        clog(\"END get_high_entropy_mask\", f\"entropy_threshold={float(entropy_threshold)}\")\n",
        "        return result\n",
        "\n",
        "    @profiling_decorator\n",
        "    def _get_per_token_logps_and_entropies(\n",
        "        self,\n",
        "        model,\n",
        "        input_ids,\n",
        "        attention_mask,\n",
        "        logits_to_keep,\n",
        "        batch_size=None,\n",
        "        compute_entropy=False,\n",
        "        pixel_values=None,\n",
        "        image_grid_thw=None,\n",
        "        num_images=None,\n",
        "        pixel_attention_mask=None,\n",
        "        image_sizes=None,\n",
        "        token_type_ids=None,\n",
        "    ) -> dict[str, Optional[torch.Tensor]]:\n",
        "        clog(\"ENTER _get_per_token_logps_and_entropies\",\n",
        "             f\"input_ids.shape={tuple(input_ids.shape)}\",\n",
        "             f\"attention_mask.shape={tuple(attention_mask.shape)}\",\n",
        "             f\"logits_to_keep={logits_to_keep}\",\n",
        "             f\"batch_size={batch_size}\",\n",
        "             f\"compute_entropy={compute_entropy}\")\n",
        "        \"\"\"Compute log-probs and (optionally) entropies for each token.\"\"\"\n",
        "        batch_size = batch_size or input_ids.size(\n",
        "            0\n",
        "        )  # Chunk inputs into smaller batches to reduce memory peak\n",
        "        all_logps = []\n",
        "        all_entropies = []\n",
        "        for start in range(0, input_ids.size(0), batch_size):\n",
        "            input_ids_batch = input_ids[start : start + batch_size]\n",
        "            attention_mask_batch = attention_mask[start : start + batch_size]\n",
        "\n",
        "            # Build model inputs - check if the model supports logits_to_keep (some models and VLMs don't)\n",
        "            model_inputs = {\n",
        "                \"input_ids\": input_ids_batch,\n",
        "                \"attention_mask\": attention_mask_batch,\n",
        "            }\n",
        "            if image_grid_thw is not None and pixel_values is not None:\n",
        "                rows_per_image = image_grid_thw.prod(dim=-1)\n",
        "                rows_per_sample = torch.split(rows_per_image, num_images)\n",
        "                rows_per_sample = torch.stack([s.sum() for s in rows_per_sample])\n",
        "                cum_rows = torch.cat(\n",
        "                    [\n",
        "                        torch.tensor([0], device=rows_per_sample.device),\n",
        "                        rows_per_sample.cumsum(0),\n",
        "                    ]\n",
        "                )\n",
        "                row_start, row_end = (\n",
        "                    cum_rows[start].item(),\n",
        "                    cum_rows[start + batch_size].item(),\n",
        "                )\n",
        "                model_inputs[\"pixel_values\"] = pixel_values[row_start:row_end]\n",
        "                cum_imgs = torch.tensor([0] + num_images).cumsum(0)\n",
        "                img_start, img_end = cum_imgs[start], cum_imgs[start + batch_size]\n",
        "                model_inputs[\"image_grid_thw\"] = image_grid_thw[img_start:img_end]\n",
        "            elif pixel_values is not None:\n",
        "                model_inputs[\"pixel_values\"] = pixel_values[start : start + batch_size]\n",
        "            if pixel_attention_mask is not None:\n",
        "                model_inputs[\"pixel_attention_mask\"] = pixel_attention_mask[\n",
        "                    start : start + batch_size\n",
        "                ]\n",
        "            if image_sizes is not None:\n",
        "                model_inputs[\"image_sizes\"] = image_sizes[start : start + batch_size]\n",
        "            if token_type_ids is not None:\n",
        "                model_inputs[\"token_type_ids\"] = token_type_ids[\n",
        "                    start : start + batch_size\n",
        "                ]\n",
        "\n",
        "            # Only add logits_to_keep if the model supports it\n",
        "            if \"logits_to_keep\" in self.model_kwarg_keys:\n",
        "                # We add 1 to `logits_to_keep` because the last logits of the sequence is later excluded\n",
        "                model_inputs[\"logits_to_keep\"] = logits_to_keep + 1\n",
        "\n",
        "            model_inputs[\"use_cache\"] = (\n",
        "                False  # only used in generation; set False to suppress warnings\n",
        "            )\n",
        "\n",
        "            logits = model(**model_inputs).logits\n",
        "            # Exclude the last value: it corresponds to the next token pred\n",
        "            logits = logits[:, :-1, :]  # (B, L-1, H)\n",
        "            # Only keep the last logits_to_keep. For model that support logits_to_keep, this is a no-op.\n",
        "            logits = logits[:, -logits_to_keep:, :]  # (B, logits_to_keep, H)\n",
        "            # Divide logits by sampling temperature.\n",
        "            # See https://huggingface.co/blog/the_n_implementation_details_of_rlhf_with_ppo#policy-training-implementation-details\n",
        "            logits = logits / self.temperature\n",
        "\n",
        "            completion_ids = input_ids_batch[:, -logits_to_keep:]\n",
        "            logps = selective_log_softmax(logits, completion_ids)  # compute logprobs\n",
        "            all_logps.append(logps)\n",
        "\n",
        "            if compute_entropy:\n",
        "                with torch.no_grad():\n",
        "                    entropies = entropy_from_logits(logits)\n",
        "                all_entropies.append(entropies)\n",
        "\n",
        "        logps = torch.cat(all_logps, dim=0)\n",
        "        entropies = torch.cat(all_entropies, dim=0) if compute_entropy else None\n",
        "        clog(\"END _get_per_token_logps_and_entropies\",\n",
        "             f\"logps.shape={tuple(logps.shape)}\",\n",
        "             f\"entropies={'None' if entropies is None else tuple(entropies.shape)}\")\n",
        "        return logps, entropies\n",
        "\n",
        "    def _fix_param_name_to_vllm(self, name, extra_prefixes: Optional[list[str]] = None):\n",
        "        extra_prefixes = extra_prefixes or []\n",
        "        prefixes = [\"_checkpoint_wrapped_module.\"] + extra_prefixes\n",
        "        for prefix in prefixes:\n",
        "            name = name.replace(prefix, \"\")\n",
        "        return name\n",
        "\n",
        "    def _sync_fsdp1_params_to_vllm(\n",
        "        self, module: nn.Module, prefix: str = \"\", visited=None\n",
        "    ):\n",
        "        clog(\"ENTER _sync_fsdp1_params_to_vllm\", f\"prefix={prefix}\")\n",
        "        \"\"\"Memory-efficient post-order traversal of FSDP modules to extract full parameters and sync with vLLM.\"\"\"\n",
        "        # For FSDP1, we need to recurse into children and also use summon_full_params\n",
        "        if visited is None:\n",
        "            visited = set()\n",
        "        for child_name, child_module in module.named_children():\n",
        "            child_prefix = f\"{prefix}.{child_name}\" if prefix else child_name\n",
        "            self._sync_fsdp1_params_to_vllm(\n",
        "                child_module, prefix=child_prefix, visited=visited\n",
        "            )  # recurse into the child\n",
        "\n",
        "        if isinstance(module, FSDP):\n",
        "            with FSDP.summon_full_params(module, recurse=False, writeback=False):\n",
        "                for param_name, param in module.named_parameters():\n",
        "                    full_name = f\"{prefix}.{param_name}\" if prefix else param_name\n",
        "                    full_name = self._fix_param_name_to_vllm(\n",
        "                        full_name, extra_prefixes=[\"_fsdp_wrapped_module.\"]\n",
        "                    )\n",
        "\n",
        "                    if full_name in visited:\n",
        "                        continue  # skip FSDP subtrees already traversed\n",
        "                    visited.add(full_name)\n",
        "\n",
        "                    if self.vllm_mode == \"server\" and self.accelerator.is_main_process:\n",
        "                        self.vllm_client.update_named_param(full_name, param.data)\n",
        "                    elif self.vllm_mode == \"colocate\":\n",
        "                        llm_model = self.llm.llm_engine.model_executor.driver_worker.model_runner.model\n",
        "                        llm_model.load_weights([(full_name, param.data)])\n",
        "        clog(\"END _sync_fsdp1_params_to_vllm\", f\"visited_count={len(visited)}\")\n",
        "\n",
        "    def _sync_fsdp2_params_to_vllm(self, module: nn.Module):\n",
        "        clog(\"ENTER _sync_fsdp2_params_to_vllm\")\n",
        "        # For FSDP2, module.state_dict() already covers all parameters, so no need for recursion\n",
        "        for name, param in module.state_dict().items():\n",
        "            if param.is_cpu:\n",
        "                param = param.to(torch.device(\"cuda\"))\n",
        "            param = param.full_tensor()\n",
        "\n",
        "            if self.vllm_mode == \"server\" and self.accelerator.is_main_process:\n",
        "                self.vllm_client.update_named_param(name, param)\n",
        "            elif self.vllm_mode == \"colocate\":\n",
        "                llm_model = (\n",
        "                    self.llm.llm_engine.model_executor.driver_worker.model_runner.model\n",
        "                )\n",
        "                llm_model.load_weights([(name, param)])\n",
        "        clog(\"END _sync_fsdp2_params_to_vllm\")\n",
        "\n",
        "    @profiling_decorator\n",
        "    def _move_model_to_vllm(self):\n",
        "        clog(\"ENTER _move_model_to_vllm\", f\"vllm_mode={self.vllm_mode}\")\n",
        "        # For DeepSpeed ZeRO-3 and FSDP, we need to gather all parameters before operations\n",
        "        deepspeed_plugin = self.accelerator.state.deepspeed_plugin\n",
        "        zero_stage_3 = deepspeed_plugin is not None and deepspeed_plugin.zero_stage == 3\n",
        "        if zero_stage_3:\n",
        "            import deepspeed\n",
        "\n",
        "            gather_if_zero3 = deepspeed.zero.GatheredParameters\n",
        "        else:\n",
        "            gather_if_zero3 = nullcontext\n",
        "\n",
        "        if is_peft_model(self.model):\n",
        "            # With PEFT and FSDP/DeepSpeed ZeRO Stage 3, we must gather the full model at once before merging, as\n",
        "            # merging adapters in a sharded manner is not supported.\n",
        "            # TODO: does this work with FSDP?\n",
        "            with gather_if_zero3(list(self.model.parameters())):\n",
        "                self.model.merge_adapter()\n",
        "\n",
        "                # Update vLLM weights while parameters are gathered\n",
        "                if (\n",
        "                    self.is_fsdp_enabled\n",
        "                ):  # note if using FSDP, gather_if_zero3 is nullcontext\n",
        "                    # Update vLLM weights while parameters are gathered\n",
        "                    # For PEFT with FSDP we need to use the memory efficient post-order traversal\n",
        "                    fsdp_plugin = getattr(self.accelerator.state, \"fsdp_plugin\", None)\n",
        "                    fsdp_version = (\n",
        "                        getattr(fsdp_plugin, \"fsdp_version\", 1) if fsdp_plugin else 1\n",
        "                    )\n",
        "                    if fsdp_version == 1:\n",
        "                        self._sync_fsdp1_params_to_vllm(\n",
        "                            self.model\n",
        "                        )  # use memory-efficient post-order traversal for FSDP\n",
        "                    elif fsdp_version == 2:\n",
        "                        self._sync_fsdp2_params_to_vllm(self.model)\n",
        "                else:\n",
        "                    # DeepSpeed ZeRO-3 with PEFT\n",
        "                    for name, param in self.model.named_parameters():\n",
        "                        # When using PEFT, we need to recover the original parameter name and discard some parameters\n",
        "                        name = name.removeprefix(\"base_model.model.\").replace(\n",
        "                            \".base_layer\", \"\"\n",
        "                        )\n",
        "                        if self.model.prefix in name:\n",
        "                            continue\n",
        "                        # When module to save, remove its prefix and discard the original module\n",
        "                        if \"original_module\" in name:\n",
        "                            continue\n",
        "                        name = self._fix_param_name_to_vllm(\n",
        "                            name, extra_prefixes=[\"modules_to_save.default.\"]\n",
        "                        )\n",
        "\n",
        "                        if (\n",
        "                            self.vllm_mode == \"server\"\n",
        "                            and self.accelerator.is_main_process\n",
        "                        ):\n",
        "                            self.vllm_client.update_named_param(name, param.data)\n",
        "                        elif self.vllm_mode == \"colocate\":\n",
        "                            llm_model = self.llm.llm_engine.model_executor.driver_worker.model_runner.model\n",
        "                            llm_model.load_weights([(name, param.data)])\n",
        "                # Unmerge adapters while parameters are still gathered\n",
        "                self.model.unmerge_adapter()\n",
        "                # Parameters will automatically be repartitioned when exiting the context\n",
        "        else:\n",
        "            # For non-PEFT models, simply gather (if needed) and update each parameter individually.\n",
        "            if self.is_fsdp_enabled:\n",
        "                fsdp_plugin = getattr(self.accelerator.state, \"fsdp_plugin\", None)\n",
        "                fsdp_version = (\n",
        "                    getattr(fsdp_plugin, \"fsdp_version\", 1) if fsdp_plugin else 1\n",
        "                )\n",
        "                if fsdp_version == 1:\n",
        "                    self._sync_fsdp1_params_to_vllm(\n",
        "                        self.model\n",
        "                    )  # use memory-efficient post-order traversal for FSDP\n",
        "                elif fsdp_version == 2:\n",
        "                    self._sync_fsdp2_params_to_vllm(self.model)\n",
        "            else:\n",
        "                for name, param in self.model.named_parameters():\n",
        "                    name = self._fix_param_name_to_vllm(name)\n",
        "                    with gather_if_zero3([param]):\n",
        "                        if (\n",
        "                            self.vllm_mode == \"server\"\n",
        "                            and self.accelerator.is_main_process\n",
        "                        ):\n",
        "                            self.vllm_client.update_named_param(name, param.data)\n",
        "                        elif self.vllm_mode == \"colocate\":\n",
        "                            llm_model = self.llm.llm_engine.model_executor.driver_worker.model_runner.model\n",
        "                            llm_model.load_weights([(name, param.data)])\n",
        "\n",
        "        # Reset cache on vLLM\n",
        "        if self.vllm_mode == \"server\" and self.accelerator.is_main_process:\n",
        "            self.vllm_client.reset_prefix_cache()\n",
        "        elif self.vllm_mode == \"colocate\":\n",
        "            self.llm.reset_prefix_cache()\n",
        "        clog(\"END _move_model_to_vllm\", \"prefix cache reset\")\n",
        "\n",
        "    @profiling_decorator\n",
        "    def _prepare_inputs(\n",
        "        self, generation_batch: dict[str, Union[torch.Tensor, Any]]\n",
        "    ) -> dict[str, Union[torch.Tensor, Any]]:\n",
        "        clog(\"ENTER _prepare_inputs\",\n",
        "             f\"training={self.model.training}\",\n",
        "             f\"_step={self._step}\",\n",
        "             f\"len_batch={len(generation_batch) if isinstance(generation_batch, dict) else 'n/a'}\",\"si_2\")\n",
        "        # Prepares inputs for model training/evaluation by managing completion generation and batch handling.\n",
        "        # During training:\n",
        "        #   - Receives the local generation batch (Per-GPU batch size × steps per generation)\n",
        "        #     from the modified training dataloader instead of the standard local batch\n",
        "        #   - Generates completions once for the entire generation batch and splits it into batches of size\n",
        "        #     `per_device_train_batch_size`\n",
        "        #   - Buffers these completions and returns the appropriate slice for the current accumulation step\n",
        "        #   - Optimizes by regenerating completions only periodically (every steps_per_generation * num_iterations)\n",
        "        # During evaluation:\n",
        "        #   - The input is treated as a standard local batch (no accumulation, no multiple iterations)\n",
        "        #   - Completions are generated for each batch without buffering or reuse\n",
        "        # Returns a single local batch in both cases.\n",
        "\n",
        "        mode = \"train\" if self.model.training else \"eval\"\n",
        "        if mode == \"train\":\n",
        "            clog(\"mode is \",mode)\n",
        "\n",
        "            generate_every = self.args.steps_per_generation * self.num_iterations\n",
        "            clog(f\"generate_every {generate_every} = self.args.steps_per_generation {self.args.steps_per_generation} * self.num_iterations {self.num_iterations}\")\n",
        "            clog(\"self._step is \",self._step)\n",
        "            clog(\"self._buffered_inputs \",self._buffered_inputs)\n",
        "            if self._step % generate_every == 0 or self._buffered_inputs is None:\n",
        "                # self._buffered_inputs=None can occur when resuming from a checkpoint\n",
        "               # clog(\"generation_batch_v1 is \",generation_batch)\n",
        "                generation_batch = self._generate_and_score_completions(\n",
        "                    generation_batch\n",
        "                )\n",
        "               # clog(\"generation_batch_v2 is \",generation_batch)\n",
        "                generation_batch = split_pixel_values_by_grid(generation_batch)\n",
        "               # clog(\"generation_batch_v3 is \",generation_batch)\n",
        "                generation_batch = shuffle_sequence_dict(generation_batch)\n",
        "               # clog(\"generation_batch_v4 is \",generation_batch)\n",
        "                generation_batches = split_tensor_dict(\n",
        "                    generation_batch, self.args.steps_per_generation\n",
        "                )\n",
        "               # clog(\"generation_batches_v5 is \",generation_batches)\n",
        "                self._buffered_inputs = [\n",
        "                    unsplit_pixel_values_by_grid(batch) for batch in generation_batches\n",
        "                ]\n",
        "                clog(\"_buffered_inputs is \",self._buffered_inputs)\n",
        "                clog(\"_prepare_inputs regenerated completions\",\n",
        "                     f\"generate_every={generate_every}\",\n",
        "                     f\"buffered_slices={len(self._buffered_inputs)}\")\n",
        "            inputs = self._buffered_inputs[self._step % self.args.steps_per_generation]\n",
        "\n",
        "            self._step += 1\n",
        "        else:\n",
        "            # In evaluation, there is neither batch grouping for generation, nor multiple iterations, hence\n",
        "            # local generation batch == local eval batch\n",
        "            inputs = self._generate_and_score_completions(generation_batch)\n",
        "        clog(\"inputs are \",inputs)\n",
        "        clog(\"END _prepare_inputs\",\n",
        "             f\"keys={list(inputs.keys())}\",\n",
        "             f\"prompt_ids.shape={tuple(inputs['prompt_ids'].shape)}\",\n",
        "             f\"completion_ids.shape={tuple(inputs['completion_ids'].shape)}\")\n",
        "        return inputs\n",
        "\n",
        "    @profiling_decorator\n",
        "    def _calculate_rewards(self, inputs, prompts, completions, completion_ids_list):\n",
        "        clog(\"ENTER _calculate_rewards\",\n",
        "             f\"num_samples={len(prompts)}\",\n",
        "             f\"num_reward_funcs={len(self.reward_funcs)}\")\n",
        "        device = self.accelerator.device\n",
        "        rewards_per_func = torch.zeros(\n",
        "            len(prompts), len(self.reward_funcs), device=device\n",
        "        )\n",
        "\n",
        "        # Repeat all input columns (but \"prompt\", \"completion\", and \"completion_ids\") to match the num of generations\n",
        "        keys = [\n",
        "            key\n",
        "            for key in inputs[0]\n",
        "            if key not in [\"prompt\", \"completion\", \"completion_ids\"]\n",
        "        ]\n",
        "        reward_kwargs = {key: [example[key] for example in inputs] for key in keys}\n",
        "\n",
        "        # This allows for dynamic reward shaping based on training progress.\n",
        "        reward_kwargs[\"trainer_state\"] = self.state\n",
        "\n",
        "        for i, (reward_func, reward_processing_class, reward_func_name) in enumerate(\n",
        "            zip(\n",
        "                self.reward_funcs,\n",
        "                self.reward_processing_classes,\n",
        "                self.reward_func_names,\n",
        "            )\n",
        "        ):\n",
        "            with profiling_context(self, reward_func_name):\n",
        "                if isinstance(\n",
        "                    reward_func, nn.Module\n",
        "                ):  # Module (no PretrainedModel) for compat with compiled models\n",
        "                    if is_conversational(inputs[0]):\n",
        "                        messages = [\n",
        "                            {\"messages\": p + c} for p, c in zip(prompts, completions)\n",
        "                        ]\n",
        "                        texts = [\n",
        "                            apply_chat_template(x, reward_processing_class)[\"text\"]\n",
        "                            for x in messages\n",
        "                        ]\n",
        "                    else:\n",
        "                        texts = [p + c for p, c in zip(prompts, completions)]\n",
        "                    reward_inputs = reward_processing_class(\n",
        "                        text=texts,\n",
        "                        return_tensors=\"pt\",\n",
        "                        padding=True,\n",
        "                        padding_side=\"right\",\n",
        "                        add_special_tokens=False,\n",
        "                    )\n",
        "                    reward_inputs = super()._prepare_inputs(reward_inputs)\n",
        "                    with torch.inference_mode():\n",
        "                        rewards_per_func[:, i] = reward_func(**reward_inputs).logits[\n",
        "                            :, 0\n",
        "                        ]  # Shape (B*G,)\n",
        "                else:\n",
        "                    output_reward_func = reward_func(\n",
        "                        prompts=prompts,\n",
        "                        completions=completions,\n",
        "                        completion_ids=completion_ids_list,\n",
        "                        **reward_kwargs,\n",
        "                    )\n",
        "                    # Convert None values to NaN\n",
        "                    output_reward_func = [\n",
        "                        reward if reward is not None else torch.nan\n",
        "                        for reward in output_reward_func\n",
        "                    ]\n",
        "\n",
        "                    rewards_per_func[:, i] = torch.tensor(\n",
        "                        output_reward_func, dtype=torch.float32, device=device\n",
        "                    )\n",
        "\n",
        "        # If all reward functions return None for a given row, issue a detailed warning\n",
        "        if torch.isnan(rewards_per_func).all(dim=1).any():\n",
        "            nan_row_idx = (\n",
        "                torch.isnan(rewards_per_func).all(dim=1).nonzero(as_tuple=True)[0][0]\n",
        "            )\n",
        "            row_reward_kwargs = {\n",
        "                key: value[nan_row_idx]\n",
        "                for key, value in reward_kwargs.items()\n",
        "                if key != \"trainer_state\"\n",
        "            }\n",
        "            row_reward_kwargs[\"prompt\"] = prompts[nan_row_idx]\n",
        "            row_reward_kwargs[\"completion\"] = completions[nan_row_idx]\n",
        "            logger.warning(\n",
        "                f\"All reward functions returned None for the following kwargs:\\n{row_reward_kwargs}\\n\"\n",
        "                \"Please ensure that at least one reward function returns a valid reward.\"\n",
        "            )\n",
        "\n",
        "        # Gather the reward per function: this part is crucial, because the rewards are normalized per group and the\n",
        "        # completions may be distributed across processes\n",
        "        rewards_per_func = gather(rewards_per_func)\n",
        "        clog(\"END _calculate_rewards\", f\"rewards_per_func.shape={tuple(rewards_per_func.shape)}\")\n",
        "        return rewards_per_func\n",
        "\n",
        "    def _generate_single_turn(self, prompts: list[str], images: Optional[list], audios: Optional[list]):\n",
        "        clog(\"ENTER _generate_single_turn\",\n",
        "             f\"num_prompts={len(prompts)}\",\n",
        "             f\"images={'None' if images is None else 'set'}\",\n",
        "             f\"use_vllm={self.use_vllm}\",\n",
        "             f\"vllm_mode={self.vllm_mode}\",\"2.1.1.1\")\n",
        "        device = self.accelerator.device\n",
        "\n",
        "        # If the prompts are conversational and the inputs contain images, we need to convert the prompts from\n",
        "        # [{\"role\": \"user\", \"content\": \"What color is the sky?\"}] to\n",
        "        # [{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": \"What color is the sky?\"}]}]\n",
        "        kwargs = {}\n",
        "        if images is not None:\n",
        "            kwargs = {\"images\": images}\n",
        "            for prompt, image_list in zip(prompts, images):\n",
        "                if isinstance(prompt, list):  # i.e., when using conversational data\n",
        "                    prepare_multimodal_messages(prompt, num_images=len(image_list))\n",
        "\n",
        "        #clog( f\"self.processing_class={self.processing_class}\")\n",
        "      #  prompts_text = []\n",
        "        prompts_pp = [remove_none_fields(prompt) for prompt in prompts]\n",
        "        prompts_text = self.processing_class.apply_chat_template(prompts_pp).to(\"cuda\")\n",
        "        generate_inputs = prompts_text\n",
        "\n",
        "       #   [\n",
        "       #     maybe_apply_chat_template({\"prompt\": prompt}, self.processing_class)[\n",
        "       #         \"prompt\"\n",
        "       #     ]\n",
        "       #     for prompt in prompts\n",
        "       # ]\n",
        "        clog(\"_generate_single_turn prompts_text\", f\"prompts_text={prompts_text}\")\n",
        "        forward_kwargs = {}\n",
        "\n",
        "\n",
        "        #if images is not None:\n",
        "            #clog( f\"images={images}\")\n",
        "            #prompt_inputs = self.processing_class(\n",
        "            #    text=prompts_text, padding=True, return_tensors=\"pt\", **kwargs\n",
        "            #)\n",
        "            #prompt_inputs = super()._prepare_inputs(prompt_inputs)\n",
        "            #forward_kwargs = {\n",
        "            #    k: v\n",
        "            #    for k, v in prompt_inputs.items()\n",
        "            #    if k not in [\"input_ids\", \"attention_mask\"]\n",
        "            #}\n",
        "        #else:\n",
        "            #clog(\"_generate_single_turn no images\")\n",
        "            #forward_kwargs = {}\n",
        "\n",
        "        clog( f\"forward_kwargs={forward_kwargs}\")\n",
        "        # Generate completions using either vLLM or regular generation\n",
        "        if self.use_vllm:\n",
        "            clog(\"_generate_single_turn using vLLM\")\n",
        "            if self.vllm_mode == \"colocate\" and self.args.vllm_enable_sleep_mode:\n",
        "                # wake up colocated vLLM instances if needed\n",
        "                torch.cuda.empty_cache()  # required to avoid OOM in some cases\n",
        "                self.llm.wake_up()\n",
        "\n",
        "            # First, update the vLLM weights if needed\n",
        "            if self.state.global_step != self._last_loaded_step:\n",
        "                self._move_model_to_vllm()\n",
        "                self._last_loaded_step = self.state.global_step\n",
        "\n",
        "            # Generate completions using vLLM: gather all prompts and use them in a single call in the main process\n",
        "            if self.vllm_mode == \"server\":\n",
        "                all_prompts_text = gather_object(prompts_text)\n",
        "                if images is not None:\n",
        "                    all_images = gather_object(images)\n",
        "\n",
        "                if self.accelerator.is_main_process:\n",
        "                    # Since 'prompts' contains 'num_generations' duplicates, we first take unique prompts, and generate\n",
        "                    # num_generations outputs for each one. This is faster than generating outputs for each duplicate\n",
        "                    # prompt individually.\n",
        "                    ordered_set_of_prompts = all_prompts_text[:: self.num_generations]\n",
        "\n",
        "                    if images is not None:\n",
        "                        ordered_set_of_images = all_images[:: self.num_generations]\n",
        "                    else:\n",
        "                        ordered_set_of_images = None\n",
        "\n",
        "                    with profiling_context(self, \"vLLM.generate\"):\n",
        "                        output = self.vllm_client.generate(\n",
        "                            prompts=ordered_set_of_prompts,\n",
        "                            images=ordered_set_of_images,\n",
        "                            n=self.num_generations,\n",
        "                            repetition_penalty=self.repetition_penalty,\n",
        "                            temperature=self.temperature,\n",
        "                            top_p=self.top_p,\n",
        "                            top_k=-1 if self.top_k is None else self.top_k,\n",
        "                            min_p=0.0 if self.min_p is None else self.min_p,\n",
        "                            max_tokens=self.max_completion_length,\n",
        "                            truncate_prompt_tokens=self.max_prompt_length,\n",
        "                            guided_decoding_regex=self.guided_decoding_regex,\n",
        "                            generation_kwargs=self.args.generation_kwargs,\n",
        "                        )\n",
        "                        payload = (\n",
        "                            output[\"prompt_ids\"],\n",
        "                            output[\"completion_ids\"],\n",
        "                            output[\"logprobs\"],\n",
        "                        )\n",
        "                        clog(\"_generate_single_turn vLLM server main generated\",\n",
        "                             f\"num_prompts={len(ordered_set_of_prompts)}\",\n",
        "                             f\"n={self.num_generations}\")\n",
        "                else:\n",
        "                    payload = None\n",
        "\n",
        "                # Broadcast the completions from the main process to all processes, ensuring each process receives its corresponding slice.\n",
        "                obj_list = [payload]\n",
        "                broadcast_object_list(obj_list, from_process=0)\n",
        "                all_prompt_ids, all_completion_ids, all_logprobs = obj_list[0]\n",
        "\n",
        "                # At this point, we only get 1 copy of each prompt, so we need to repeat them num_generations times\n",
        "                all_prompt_ids = [\n",
        "                    ids for ids in all_prompt_ids for _ in range(self.num_generations)\n",
        "                ]\n",
        "\n",
        "                process_slice = slice(\n",
        "                    self.accelerator.process_index * len(prompts),\n",
        "                    (self.accelerator.process_index + 1) * len(prompts),\n",
        "                )\n",
        "                prompt_ids = all_prompt_ids[process_slice]\n",
        "                completion_ids = all_completion_ids[process_slice]\n",
        "                logprobs = all_logprobs[process_slice]\n",
        "\n",
        "            # Generate completions using colocated vLLM instances: each device holds vLLM copy and work on their own batch of prompts\n",
        "            elif self.vllm_mode == \"colocate\":\n",
        "                if self.guided_decoding_regex:\n",
        "                    guided_decoding = GuidedDecodingParams(\n",
        "                        regex=self.guided_decoding_regex\n",
        "                    )\n",
        "                else:\n",
        "                    guided_decoding = None\n",
        "\n",
        "                generation_kwargs = {\n",
        "                    \"n\": 1,  # vLLM on each GPU generates only 1 in colocate mode\n",
        "                    \"repetition_penalty\": self.repetition_penalty,\n",
        "                    \"temperature\": self.temperature,\n",
        "                    \"top_p\": self.top_p,\n",
        "                    \"top_k\": -1 if self.top_k is None else self.top_k,\n",
        "                    \"min_p\": 0.0 if self.min_p is None else self.min_p,\n",
        "                    \"max_tokens\": self.max_completion_length,\n",
        "                    \"truncate_prompt_tokens\": self.max_prompt_length,\n",
        "                    \"guided_decoding\": guided_decoding,\n",
        "                    \"logprobs\": 0,  # only return the logprob of the generated token\n",
        "                }\n",
        "                if self.args.generation_kwargs is not None:\n",
        "                    generation_kwargs.update(self.args.generation_kwargs)\n",
        "                sampling_params = SamplingParams(**generation_kwargs)\n",
        "\n",
        "                if self.vllm_tensor_parallel_size > 1:\n",
        "                    # Gather prompts from all ranks in the TP group and flatten.\n",
        "                    # Each rank starts with its own prompts; after gathering, all ranks see the full group set.\n",
        "                    orig_size = len(prompts_text)\n",
        "                    gathered_prompts = [\n",
        "                        None for _ in range(self.vllm_tensor_parallel_size)\n",
        "                    ]\n",
        "                    torch.distributed.all_gather_object(\n",
        "                        gathered_prompts, prompts_text, group=self.tp_group\n",
        "                    )\n",
        "                    all_prompts_text = [\n",
        "                        p for sublist in gathered_prompts for p in sublist\n",
        "                    ]\n",
        "\n",
        "                    if images is not None:\n",
        "                        gathered_images = [\n",
        "                            None for _ in range(self.vllm_tensor_parallel_size)\n",
        "                        ]\n",
        "                        torch.distributed.all_gather_object(\n",
        "                            gathered_images, images, group=self.tp_group\n",
        "                        )\n",
        "                        all_images = [\n",
        "                            img for sublist in gathered_images for img in sublist\n",
        "                        ]\n",
        "                    else:\n",
        "                        all_images = None\n",
        "                else:\n",
        "                    all_prompts_text = prompts_text\n",
        "                    all_images = images\n",
        "\n",
        "                if images is not None and all_images:\n",
        "                    vllm_inputs = []\n",
        "                    for prompt, image_list in zip(all_prompts_text, all_images):\n",
        "                        vllm_inputs.append(\n",
        "                            {\n",
        "                                \"prompt\": prompt,\n",
        "                                \"multi_modal_data\": {\"image\": image_list},\n",
        "                            }\n",
        "                        )\n",
        "\n",
        "                else:\n",
        "                    vllm_inputs = all_prompts_text\n",
        "\n",
        "                with profiling_context(self, \"vLLM.generate\"):\n",
        "                    all_outputs = self.llm.generate(\n",
        "                        vllm_inputs, sampling_params=sampling_params, use_tqdm=False\n",
        "                    )\n",
        "\n",
        "                all_prompt_ids = [output.prompt_token_ids for output in all_outputs]\n",
        "                all_completion_ids = [\n",
        "                    output.token_ids\n",
        "                    for outputs in all_outputs\n",
        "                    for output in outputs.outputs\n",
        "                ]\n",
        "                all_logprobs = [\n",
        "                    [next(iter(lp.values())).logprob for lp in output.logprobs]\n",
        "                    for outputs in all_outputs\n",
        "                    for output in outputs.outputs\n",
        "                ]\n",
        "\n",
        "                if self.vllm_tensor_parallel_size > 1:\n",
        "                    # Slice completions for this rank within its TP group.\n",
        "                    # Each rank generates all outputs — we keep only our share.\n",
        "                    local_rank_in_group = torch.distributed.get_rank(\n",
        "                        group=self.tp_group\n",
        "                    )\n",
        "                    tp_slice = slice(\n",
        "                        local_rank_in_group * orig_size,\n",
        "                        (local_rank_in_group + 1) * orig_size,\n",
        "                    )\n",
        "                    prompt_ids = all_prompt_ids[tp_slice]\n",
        "                    completion_ids = all_completion_ids[tp_slice]\n",
        "                    logprobs = all_logprobs[tp_slice]\n",
        "                else:\n",
        "                    prompt_ids = all_prompt_ids\n",
        "                    completion_ids = all_completion_ids\n",
        "                    logprobs = all_logprobs\n",
        "\n",
        "                if self.args.vllm_enable_sleep_mode:\n",
        "                    self.llm.sleep(level=1)\n",
        "\n",
        "        elif self.use_transformers_paged:\n",
        "            clog(\"_generate_single_turn using transformers paged\")\n",
        "            # Re-process inputs for paged generation if needed\n",
        "            # Note: images are already validated and preprocessed above\n",
        "            paged_prompt_inputs = self.processing_class(text=prompts_text, **kwargs)\n",
        "            previous_attn = self.model_wrapped.config._attn_implementation\n",
        "\n",
        "            if is_flash_attn_2_available():\n",
        "                self.model_wrapped.config._attn_implementation = \"paged_attention\"\n",
        "            else:\n",
        "                self.model_wrapped.config._attn_implementation = \"sdpa_paged\"\n",
        "            with (\n",
        "                profiling_context(self, \"transformers.generate_batch\"),\n",
        "                unwrap_model_for_generation(\n",
        "                    self.model_wrapped,\n",
        "                    self.accelerator,\n",
        "                    gather_deepspeed3_params=self.args.ds3_gather_for_generation,\n",
        "                ) as unwrapped_model,\n",
        "                torch.no_grad(),\n",
        "                FSDP.summon_full_params(self.model_wrapped, recurse=False)\n",
        "                if self.is_fsdp_enabled\n",
        "                else nullcontext(),\n",
        "            ):\n",
        "                # Cast to the appropriate dtype based on training configuration\n",
        "                if self.args.bf16:\n",
        "                    unwrapped_model.to(torch.bfloat16)\n",
        "                elif self.args.fp16:\n",
        "                    unwrapped_model.to(torch.float16)\n",
        "                with torch.inference_mode():\n",
        "                    all_outputs = unwrapped_model.generate_batch(\n",
        "                        paged_prompt_inputs.input_ids,\n",
        "                        generation_config=self.generation_config,\n",
        "                        progress_bar=False,\n",
        "                    )\n",
        "                    unwrapped_model.train()  # restore training mode, as generate_batch forces eval mode\n",
        "            completion_ids = [\n",
        "                output.generated_tokens for output in all_outputs.values()\n",
        "            ]\n",
        "            prompt_ids = paged_prompt_inputs.input_ids\n",
        "            # Restore the original attention implementation, training mode\n",
        "            self.model_wrapped.config._attn_implementation = previous_attn\n",
        "            logprobs = None  # not used in this case\n",
        "\n",
        "        else:\n",
        "            clog(\"_generate_single_turn using transformers\")\n",
        "            # Regular generation path\n",
        "           # clog(\"_generate_single_turn prompts_text\", f\"prompts_text={prompts_text}\")\n",
        "            global p_t\n",
        "            global gen_ip\n",
        "            #gen_ip = \"\"\n",
        "            #gen =\"\"\n",
        "\n",
        "            #if audios is not None:\n",
        "            #    clog(\"audios is not None\")\n",
        "            #    audios_pp = [np.array(aud) for aud in audios]\n",
        "            #    clog(\"audios_pp \",len(audios_pp))\n",
        "            #    p_t = prompts_text\n",
        "            #    clog(\"()()() prompts_text is \",prompts_text)\n",
        "            #    generate_inputs = self.processing_class(\n",
        "            #       text=prompts_text,\n",
        "            ##        return_tensors=\"pt\",\n",
        "             #       padding=True,\n",
        "             #       padding_side=\"left\",\n",
        "                   # max_length=self.max_prompt_length,\n",
        "            #        truncation=True,\n",
        "            #        add_special_tokens=False,\n",
        "            #        audio=audios_pp,\n",
        "            #        **kwargs,\n",
        "            #    )\n",
        "            #    clog(\"setting global variables\")\n",
        "\n",
        "#                gen_ip = generate_inputs\n",
        " ##           else:\n",
        "   #             clog(\"audios is None\")\n",
        "    #            generate_inputs = self.processing_class(\n",
        "      #              text=prompts_text,\n",
        "      #              return_tensors=\"pt\",\n",
        "      #              padding=True,\n",
        "      #              padding_side=\"left\",\n",
        "      #              max_length=self.max_prompt_length,\n",
        "      #              truncation=True,\n",
        "      #              add_special_tokens=False,\n",
        "      #              **kwargs,\n",
        "      #          )\n",
        "            generate_inputs = super()._prepare_inputs(generate_inputs)\n",
        "           # clog(\"_generate_single_turn generate_inputs\", f\"generate_inputs={generate_inputs}\")\n",
        "\n",
        "            with (\n",
        "                profiling_context(self, \"transformers.generate\"),\n",
        "                unwrap_model_for_generation(\n",
        "                    self.model_wrapped,\n",
        "                    self.accelerator,\n",
        "                    gather_deepspeed3_params=self.args.ds3_gather_for_generation,\n",
        "                ) as unwrapped_model,\n",
        "                torch.no_grad(),\n",
        "                FSDP.summon_full_params(self.model_wrapped, recurse=False)\n",
        "                if self.is_fsdp_enabled\n",
        "                else nullcontext(),\n",
        "            ):\n",
        "                #clog( f\"unwrapped_model={unwrapped_model}\")\n",
        "                clog( f\"generate_inputs={generate_inputs}\")\n",
        "                clog( f\"generation_config={self.generation_config}\")\n",
        "                prompt_completion_ids = unwrapped_model.generate(\n",
        "                    **generate_inputs,\n",
        "                    generation_config=self.generation_config,\n",
        "                    disable_compile=True,\n",
        "                )\n",
        "                clog( f\"prompt_completion_ids={prompt_completion_ids}\")\n",
        "\n",
        "            # Compute prompt length and extract completion ids\n",
        "            prompt_ids, prompt_mask = (\n",
        "                generate_inputs[\"input_ids\"],\n",
        "                generate_inputs[\"attention_mask\"],\n",
        "            )\n",
        "            prompt_length = prompt_ids.size(1)\n",
        "            completion_ids = prompt_completion_ids[:, prompt_length:]\n",
        "\n",
        "            # Mask everything after the first EOS token\n",
        "            is_eos = completion_ids == self.eos_token_id\n",
        "            eos_idx = torch.full(\n",
        "                (is_eos.size(0),), is_eos.size(1), dtype=torch.long, device=device\n",
        "            )\n",
        "            eos_idx[is_eos.any(dim=1)] = is_eos.int().argmax(dim=1)[is_eos.any(dim=1)]\n",
        "            sequence_indices = torch.arange(is_eos.size(1), device=device).expand(\n",
        "                is_eos.size(0), -1\n",
        "            )\n",
        "            completion_mask = (sequence_indices <= eos_idx.unsqueeze(1)).int()\n",
        "            prompt_ids = [p[m].tolist() for p, m in zip(prompt_ids, prompt_mask.bool())]\n",
        "            completion_ids = [\n",
        "                c[m].tolist() for c, m in zip(completion_ids, completion_mask.bool())\n",
        "            ]\n",
        "            clog(\"completion_ids\", f\"completion_ids={completion_ids}\")\n",
        "\n",
        "            logprobs = None  # not used in this case\n",
        "\n",
        "        clog(\"END _generate_single_turn\",\n",
        "             f\"prompt_ids_len={len(prompt_ids)}\",\n",
        "             f\"completion_ids_len={len(completion_ids)}\")\n",
        "        return prompt_ids, completion_ids, logprobs, forward_kwargs\n",
        "\n",
        "    def _generate(self, prompts: list[str], images: Optional[list], audios: Optional[list]):\n",
        "        clog(\"ENTER _generate\", f\"num_prompts={len(prompts)}\",\"2.1.1\")\n",
        "        device = self.accelerator.device\n",
        "        mode = \"train\" if self.model.training else \"eval\"\n",
        "\n",
        "        prompt_ids, completion_ids, logprobs, forward_kwargs = (\n",
        "            self._generate_single_turn(prompts, images, audios)\n",
        "        )\n",
        "\n",
        "        # Get completion length per sequence, used for logging\n",
        "        prompt_lengths = torch.tensor([len(ids) for ids in prompt_ids], device=device)\n",
        "        clog(\"prompt_lengths \",prompt_lengths)\n",
        "        completion_lengths = torch.tensor(\n",
        "            [len(ids) for ids in completion_ids], device=device\n",
        "        )\n",
        "        clog(\"completion_lengths \",completion_lengths)\n",
        "        agg_prompt_lengths = self.accelerator.gather(prompt_lengths)\n",
        "        clog(\"agg_prompt_lengths \",agg_prompt_lengths)\n",
        "        agg_completion_lengths = self.accelerator.gather(completion_lengths)\n",
        "        clog(\"agg_completion_lengths \",agg_completion_lengths)\n",
        "        total_prompt_tokens = agg_prompt_lengths.sum()\n",
        "        clog(\"total_prompt_tokens \",total_prompt_tokens)\n",
        "        total_completion_tokens = (\n",
        "            agg_completion_lengths.sum()\n",
        "        )  # = num_items_in_batch, required for the DAPO loss\n",
        "        clog(\"_generate token stats\",\n",
        "             f\"total_prompt_tokens={int(total_prompt_tokens)}\",\n",
        "             f\"total_completion_tokens={int(total_completion_tokens)}\",\n",
        "             f\"mode={mode}\")\n",
        "\n",
        "        # Log the metrics\n",
        "        if mode == \"train\":\n",
        "            self.state.num_input_tokens_seen += (\n",
        "                total_prompt_tokens + total_completion_tokens\n",
        "            ).item()\n",
        "        self._metrics[mode][\"num_tokens\"] = [self.state.num_input_tokens_seen]\n",
        "\n",
        "        # Log completion lengths, mean, min, max\n",
        "        self._metrics[mode][\"completions/mean_length\"].append(\n",
        "            agg_completion_lengths.float().mean().item()\n",
        "        )\n",
        "        self._metrics[mode][\"completions/min_length\"].append(\n",
        "            agg_completion_lengths.float().min().item()\n",
        "        )\n",
        "        self._metrics[mode][\"completions/max_length\"].append(\n",
        "            agg_completion_lengths.float().max().item()\n",
        "        )\n",
        "\n",
        "        # Identify sequences that terminated with EOS and log their lengths\n",
        "        eos_and_pad = [self.eos_token_id, self.pad_token_id]\n",
        "        is_truncated = torch.tensor(\n",
        "            [ids[-1] not in eos_and_pad for ids in completion_ids], device=device\n",
        "        )\n",
        "        agg_is_truncated = self.accelerator.gather(is_truncated)\n",
        "        self._metrics[mode][\"completions/clipped_ratio\"].append(\n",
        "            agg_is_truncated.float().mean().item()\n",
        "        )\n",
        "        term_completion_lengths = agg_completion_lengths[~agg_is_truncated]\n",
        "        if (\n",
        "            len(term_completion_lengths) == 0\n",
        "        ):  # edge case where no terminated sequences are found\n",
        "            term_completion_lengths = torch.zeros(1, device=device)\n",
        "        self._metrics[mode][\"completions/mean_terminated_length\"].append(\n",
        "            term_completion_lengths.float().mean().item()\n",
        "        )\n",
        "        self._metrics[mode][\"completions/min_terminated_length\"].append(\n",
        "            term_completion_lengths.float().min().item()\n",
        "        )\n",
        "        self._metrics[mode][\"completions/max_terminated_length\"].append(\n",
        "            term_completion_lengths.float().max().item()\n",
        "        )\n",
        "        clog(\"END _generate\")\n",
        "        return (\n",
        "            prompt_ids,\n",
        "            completion_ids,\n",
        "            total_completion_tokens,\n",
        "            logprobs,\n",
        "            forward_kwargs,\n",
        "        )\n",
        "\n",
        "    def _generate_and_score_completions(\n",
        "        self, inputs: list[dict[str, Union[torch.Tensor, Any]]]\n",
        "    ) -> dict[str, Union[torch.Tensor, Any]]:\n",
        "        clog(\"ENTER _generate_and_score_completions\", f\"batch_size={len(inputs)}\",\" si_2.1\")\n",
        "        device = self.accelerator.device\n",
        "        mode = \"train\" if self.model.training else \"eval\"\n",
        "\n",
        "        prompts = [x[\"prompt\"] for x in inputs]\n",
        "        clog(\"prompts are \",prompts)\n",
        "\n",
        "        if \"images\" in inputs[0]:\n",
        "            images = [example.get(\"images\") for example in inputs]\n",
        "        elif \"image\" in inputs[0]:\n",
        "            images = [\n",
        "                [example.get(\"image\")] if example.get(\"image\") is not None else None\n",
        "                for example in inputs\n",
        "            ]\n",
        "        else:\n",
        "            images = None\n",
        "\n",
        "        if \"audio\" in inputs[0]:\n",
        "            audios = [example.get(\"audio\") for example in inputs]\n",
        "        else:\n",
        "            audios = None\n",
        "\n",
        "        clog(\"images are \",images)\n",
        "        #clog(\"inputs is \",inputs)\n",
        "       # clog(\"audios are \",audios)\n",
        "       # clog(\"shape of audios \",audios.shape)\n",
        "        # Transformers requires at least one image in the batch, otherwise it throws an error\n",
        "        if images is not None and all(img_list == [] for img_list in images):\n",
        "            images = None\n",
        "\n",
        "        (\n",
        "            prompt_ids_list,\n",
        "            completion_ids_list,\n",
        "            num_items_in_batch,\n",
        "            sampling_per_token_logps_list,\n",
        "            forward_kwargs,\n",
        "        ) = self._generate(prompts, images, audios)\n",
        "\n",
        "\n",
        "        clog(\"prompt_ids_list is \",prompt_ids_list)\n",
        "        clog(\"completion_ids_list is \",completion_ids_list)\n",
        "        clog(f\"num_items_in_batch={int(num_items_in_batch)}\")\n",
        "        clog(\"sampling_per_token_logps_list \",sampling_per_token_logps_list)\n",
        "        clog(\"forward_kwargs is \",forward_kwargs)\n",
        "\n",
        "        # Convert lists of token IDs to padded tensors\n",
        "        prompt_ids = [torch.tensor(ids, device=device) for ids in prompt_ids_list]\n",
        "        prompt_mask = [torch.ones_like(ids, dtype=torch.long) for ids in prompt_ids]\n",
        "        prompt_ids = pad(\n",
        "            prompt_ids, padding_value=self.pad_token_id, padding_side=\"left\"\n",
        "        )\n",
        "        prompt_mask = pad(prompt_mask, padding_value=0, padding_side=\"left\")\n",
        "\n",
        "        clog(\"prompt_ids \",prompt_ids)\n",
        "        clog(\"prompt_mask \",prompt_mask)\n",
        "        completion_ids = [\n",
        "            torch.tensor(ids, device=device) for ids in completion_ids_list\n",
        "        ]\n",
        "        completion_mask = [\n",
        "            torch.ones_like(ids, dtype=torch.long) for ids in completion_ids\n",
        "        ]\n",
        "        completion_ids = pad(\n",
        "            completion_ids, padding_value=self.pad_token_id, padding_side=\"right\"\n",
        "        )\n",
        "        completion_mask = pad(completion_mask, padding_value=0, padding_side=\"right\")\n",
        "        clog(\"completion_ids \",completion_ids)\n",
        "        clog(\"completion_mask \",completion_mask)\n",
        "        if sampling_per_token_logps_list is not None:\n",
        "            sampling_per_token_logps = [\n",
        "                torch.tensor(logps, device=device)\n",
        "                for logps in sampling_per_token_logps_list\n",
        "            ]\n",
        "            sampling_per_token_logps = pad(\n",
        "                sampling_per_token_logps, padding_value=0.0, padding_side=\"right\"\n",
        "            )\n",
        "        else:\n",
        "            sampling_per_token_logps = None\n",
        "\n",
        "        clog(\"sampling_per_token_logps \",sampling_per_token_logps)\n",
        "\n",
        "        # If mask_truncated_completions is enabled, zero out truncated completions in completion_mask\n",
        "        if self.mask_truncated_completions:\n",
        "            clog(\"mask_truncated_completions is enabled\")\n",
        "            eos_and_pad = [self.eos_token_id, self.pad_token_id]\n",
        "            clog(\"eos_and_pad \",eos_and_pad)\n",
        "            is_truncated = torch.tensor(\n",
        "                [ids[-1] not in eos_and_pad for ids in completion_ids_list],\n",
        "                device=device,\n",
        "            )\n",
        "            completion_mask = completion_mask * (~is_truncated).unsqueeze(1).int()\n",
        "            clog(\"completion_mask \",completion_mask)\n",
        "\n",
        "        # Concatenate prompt_mask with completion_mask for logit computation\n",
        "        prompt_completion_ids = torch.cat(\n",
        "            [prompt_ids, completion_ids], dim=1\n",
        "        )  # (B, P+C)\n",
        "        clog(\"prompt_completion_ids \",prompt_completion_ids)\n",
        "        attention_mask = torch.cat([prompt_mask, completion_mask], dim=1)  # (B, P+C)\n",
        "        clog(\"attention_mask is \", attention_mask)\n",
        "        # If token_type_ids are used, extend them with zeros for the completion part\n",
        "        if \"token_type_ids\" in forward_kwargs:\n",
        "            clog(\"token_type_ids is used\")\n",
        "            token_type_ids = forward_kwargs[\"token_type_ids\"]\n",
        "            forward_kwargs[\"token_type_ids\"] = torch.cat(\n",
        "                [token_type_ids, token_type_ids.new_zeros(completion_ids.shape)], dim=1\n",
        "            )\n",
        "            #clog()\n",
        "\n",
        "        logits_to_keep = completion_ids.size(\n",
        "            1\n",
        "        )  # we only need to compute the logits for the completion tokens\n",
        "        clog(\"logits_to_keep \",logits_to_keep)\n",
        "        batch_size = (\n",
        "            self.args.per_device_train_batch_size\n",
        "            if mode == \"train\"\n",
        "            else self.args.per_device_eval_batch_size\n",
        "        )\n",
        "        clog(\"batch_size \",batch_size)\n",
        "        num_images = (\n",
        "            [len(img_list) for img_list in images] if images is not None else None\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # If the generation and optimization steps are misaligned—i.e., if generation does not occur at the end of\n",
        "            # a full optimizer step (when gradient_accumulation_steps is not a multiple of generate_every)—then the\n",
        "            # samples may come from an earlier version of the model. In that case, we need to track old_per_token_logps\n",
        "            # for importance sampling. If the steps are aligned, importance sampling isn't necessary and we set\n",
        "            # old_per_token_logps to None.\n",
        "            # When using vLLM, we always compute old_per_token_logps for importance sampling, it was shown that the\n",
        "            # distribution mismatch between vLLM and the training model can be large and harm the training.\n",
        "            generate_every = (\n",
        "                self.args.steps_per_generation * self.num_iterations\n",
        "            )  # generation frequency\n",
        "            clog(\"generate_every \",generate_every)\n",
        "            if self.args.gradient_accumulation_steps % generate_every != 0 or (\n",
        "                self.use_vllm and self.vllm_importance_sampling_correction\n",
        "            ):\n",
        "                clog(\"old_per_token_logps is computed\")\n",
        "                old_per_token_logps, _ = self._get_per_token_logps_and_entropies(\n",
        "                    self.model,\n",
        "                    prompt_completion_ids,\n",
        "                    attention_mask,\n",
        "                    logits_to_keep,\n",
        "                    batch_size,\n",
        "                    num_images=num_images,\n",
        "                    **forward_kwargs,  # may contain pixel_values, image_grid_thw, pixel_attention_mask and image_sizes\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                clog(\"old_per_token_logps is not computed\")\n",
        "                old_per_token_logps = None\n",
        "\n",
        "            clog(\"old_per_token_logps \",old_per_token_logps)\n",
        "            # Compute the importance sampling ratio when using vLLM, to correct for potential distribution mismatch\n",
        "            if self.use_vllm and self.vllm_importance_sampling_correction:\n",
        "                clog(\"importance_sampling_ratio is computed\")\n",
        "                importance_sampling_ratio = torch.exp(\n",
        "                    old_per_token_logps - sampling_per_token_logps\n",
        "                )\n",
        "                importance_sampling_ratio = torch.clamp(\n",
        "                    importance_sampling_ratio, max=self.vllm_importance_sampling_cap\n",
        "                )\n",
        "\n",
        "            # Compute the per-token log probabilities for the reference model\n",
        "            if self.beta != 0.0:\n",
        "                clog(\"ref_per_token_logps is computed\")\n",
        "                if self.ref_model is not None:\n",
        "                    ref_per_token_logps, _ = self._get_per_token_logps_and_entropies(\n",
        "                        self.ref_model,\n",
        "                        prompt_completion_ids,\n",
        "                        attention_mask,\n",
        "                        logits_to_keep,\n",
        "                        batch_size=batch_size,\n",
        "                        num_images=num_images,\n",
        "                        **forward_kwargs,  # may contain pixel_values, image_grid_thw, pixel_attention_mask and image_sizes\n",
        "                    )\n",
        "                else:\n",
        "                    with self.accelerator.unwrap_model(self.model).disable_adapter():\n",
        "                        ref_per_token_logps, _ = (\n",
        "                            self._get_per_token_logps_and_entropies(\n",
        "                                self.model,\n",
        "                                prompt_completion_ids,\n",
        "                                attention_mask,\n",
        "                                logits_to_keep,\n",
        "                                batch_size=batch_size,\n",
        "                                num_images=num_images,\n",
        "                                **forward_kwargs,  # may contain pixel_values, image_grid_thw, pixel_attention_mask and image_sizes\n",
        "                            )\n",
        "                        )\n",
        "            else:\n",
        "                clog(\"ref_per_token_logps is not computed\")\n",
        "                ref_per_token_logps = None\n",
        "\n",
        "        # Decode\n",
        "        prompts_text = self.processing_class.batch_decode(\n",
        "            prompt_ids, skip_special_tokens=True\n",
        "        )\n",
        "        clog(\"prompts_text is \",prompts_text)\n",
        "        completions_text = self.processing_class.batch_decode(\n",
        "            completion_ids, skip_special_tokens=True\n",
        "        )\n",
        "        clog(\"completions_text is \",completions_text)\n",
        "\n",
        "        if is_conversational(inputs[0]):\n",
        "            clog(\"is_conversational is true\")\n",
        "            completions = []\n",
        "            for prompt, completion in zip(prompts, completions_text):\n",
        "                bootstrap = (\n",
        "                    prompt.pop()[\"content\"] if prompt[-1][\"role\"] == \"assistant\" else \"\"\n",
        "                )\n",
        "                completions.append(\n",
        "                    [{\"role\": \"assistant\", \"content\": bootstrap + completion}]\n",
        "                )\n",
        "        else:\n",
        "            completions = completions_text\n",
        "\n",
        "        # Calculate rewards for each reward function. rewards_per_func aggregates rewards across all processes. This is\n",
        "        # important because rewards will be normalized per group, and completions are distributed. We will later slice\n",
        "        # rewards_per_func to extract each process's subset.\n",
        "        rewards_per_func = self._calculate_rewards(\n",
        "            inputs, prompts, completions, completion_ids_list\n",
        "        )\n",
        "\n",
        "        # Apply weights to each reward function's output and sum\n",
        "        rewards = (\n",
        "            rewards_per_func * self.reward_weights.to(device).unsqueeze(0)\n",
        "        ).nansum(dim=1)\n",
        "\n",
        "        clog(\"rewards \",rewards)\n",
        "        # Compute grouped-wise rewards\n",
        "        mean_grouped_rewards = rewards.view(-1, self.num_generations).mean(dim=1)\n",
        "        clog(\"mean_grouped_rewards \",mean_grouped_rewards)\n",
        "        # Normalize the rewards to compute the advantages\n",
        "        mean_grouped_rewards = mean_grouped_rewards.repeat_interleave(\n",
        "            self.num_generations, dim=0\n",
        "        )\n",
        "        advantages = rewards - mean_grouped_rewards\n",
        "        clog(\"advantages \",advantages)\n",
        "\n",
        "        clog(\"self.scale_rewards \",self.scale_rewards)\n",
        "        if self.scale_rewards in [\"group\", \"none\"]:\n",
        "            # If self.scale_rewards = \"none\", we'll still log group level std\n",
        "            std_rewards = rewards.view(-1, self.num_generations).std(dim=1)\n",
        "            std_rewards = std_rewards.repeat_interleave(self.num_generations, dim=0)\n",
        "        elif self.scale_rewards == \"batch\":\n",
        "            # Compute global std\n",
        "            std_rewards = rewards.std().expand_as(rewards)\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Invalid value for scale_rewards: {self.scale_rewards}. Must be one of 'batch', 'group', or 'none'.\"\n",
        "            )\n",
        "        clog(\"std_rewards \",std_rewards)\n",
        "        is_std_zero = torch.isclose(std_rewards, torch.zeros_like(std_rewards))\n",
        "        clog(\"is_std_zero \",is_std_zero)\n",
        "        if self.scale_rewards != \"none\":\n",
        "            advantages = advantages / (std_rewards + 1e-4)\n",
        "\n",
        "        # Slice to keep only the local part of the data\n",
        "        process_slice = slice(\n",
        "            self.accelerator.process_index * len(prompts),\n",
        "            (self.accelerator.process_index + 1) * len(prompts),\n",
        "        )\n",
        "        clog(\"process_slice \",process_slice)\n",
        "        all_process_advantages = (\n",
        "            advantages.clone()\n",
        "        )  # keep the aggregated advantages for logging\n",
        "        advantages = advantages[process_slice]\n",
        "\n",
        "        # Calculate mean reward per function, but only for samples where the function was applied (non-NaN values)\n",
        "        for i, reward_func_name in enumerate(self.reward_func_names):\n",
        "            mean_rewards = torch.nanmean(rewards_per_func[:, i]).item()\n",
        "            self._metrics[mode][f\"rewards/{reward_func_name}/mean\"].append(mean_rewards)\n",
        "            std_func_rewards = nanstd(rewards_per_func[:, i]).item()\n",
        "            self._metrics[mode][f\"rewards/{reward_func_name}/std\"].append(\n",
        "                std_func_rewards\n",
        "            )\n",
        "        self._metrics[mode][\"reward\"].append(mean_grouped_rewards.mean().item())\n",
        "        self._metrics[mode][\"reward_std\"].append(std_rewards.mean().item())\n",
        "        self._metrics[mode][\"frac_reward_zero_std\"].append(\n",
        "            is_std_zero.float().mean().item()\n",
        "        )\n",
        "\n",
        "        # Log prompt and completion texts\n",
        "        self._logs[\"prompt\"].extend(gather_object(prompts_text))\n",
        "        self._logs[\"completion\"].extend(gather_object(completions_text))\n",
        "        for i, name in enumerate(self.reward_func_names):\n",
        "            self._logs[\"rewards\"][name].extend(rewards_per_func[:, i].tolist())\n",
        "        self._logs[\"advantages\"].extend(all_process_advantages.tolist())\n",
        "\n",
        "        if images is not None:\n",
        "            self._logs[\"images\"].extend(gather_object(images))\n",
        "\n",
        "        if self.use_vllm and self.vllm_importance_sampling_correction:\n",
        "            delta = torch.abs(old_per_token_logps - sampling_per_token_logps)\n",
        "            delta = delta[completion_mask.bool()]\n",
        "            mean_delta = (\n",
        "                torch.mean(delta)\n",
        "                if delta.numel() > 0\n",
        "                else torch.tensor(0.0, device=device)\n",
        "            )\n",
        "            max_delta = (\n",
        "                torch.max(delta)\n",
        "                if delta.numel() > 0\n",
        "                else torch.tensor(0.0, device=device)\n",
        "            )\n",
        "            self._metrics[mode][\"sampling/sampling_logp_difference/mean\"].append(\n",
        "                self.accelerator.gather(mean_delta).mean().item()\n",
        "            )\n",
        "            self._metrics[mode][\"sampling/sampling_logp_difference/max\"].append(\n",
        "                self.accelerator.gather(max_delta).max().item()\n",
        "            )\n",
        "\n",
        "            flat_is_ratio = importance_sampling_ratio[completion_mask.bool()]\n",
        "            min_importance_sampling_ratio = (\n",
        "                torch.min(flat_is_ratio)\n",
        "                if flat_is_ratio.numel() > 0\n",
        "                else torch.tensor(0.0, device=device)\n",
        "            )\n",
        "            mean_importance_sampling_ratio = (\n",
        "                torch.mean(flat_is_ratio)\n",
        "                if flat_is_ratio.numel() > 0\n",
        "                else torch.tensor(0.0, device=device)\n",
        "            )\n",
        "            max_importance_sampling_ratio = (\n",
        "                torch.max(flat_is_ratio)\n",
        "                if flat_is_ratio.numel() > 0\n",
        "                else torch.tensor(0.0, device=device)\n",
        "            )\n",
        "            self._metrics[mode][\"sampling/importance_sampling_ratio/min\"].append(\n",
        "                nanmin(self.accelerator.gather(min_importance_sampling_ratio)).item()\n",
        "            )\n",
        "            self._metrics[mode][\"sampling/importance_sampling_ratio/mean\"].append(\n",
        "                self.accelerator.gather(mean_importance_sampling_ratio).nanmean().item()\n",
        "            )\n",
        "            self._metrics[mode][\"sampling/importance_sampling_ratio/max\"].append(\n",
        "                nanmax(self.accelerator.gather(max_importance_sampling_ratio)).item()\n",
        "            )\n",
        "\n",
        "        output = {\n",
        "            \"prompt_ids\": prompt_ids,\n",
        "            \"prompt_mask\": prompt_mask,\n",
        "            \"completion_ids\": completion_ids,\n",
        "            \"completion_mask\": completion_mask,\n",
        "            \"advantages\": advantages,\n",
        "            \"num_items_in_batch\": num_items_in_batch,\n",
        "        }\n",
        "        if old_per_token_logps is not None:\n",
        "            output[\"old_per_token_logps\"] = old_per_token_logps\n",
        "        if self.use_vllm and self.vllm_importance_sampling_correction:\n",
        "            output[\"importance_sampling_ratio\"] = importance_sampling_ratio\n",
        "        if ref_per_token_logps is not None:\n",
        "            output[\"ref_per_token_logps\"] = ref_per_token_logps\n",
        "        if \"pixel_values\" in forward_kwargs:\n",
        "            output[\"pixel_values\"] = forward_kwargs[\"pixel_values\"]\n",
        "        if \"image_grid_thw\" in forward_kwargs:\n",
        "            output[\"image_grid_thw\"] = forward_kwargs[\"image_grid_thw\"]\n",
        "        if \"pixel_attention_mask\" in forward_kwargs:\n",
        "            output[\"pixel_attention_mask\"] = forward_kwargs[\"pixel_attention_mask\"]\n",
        "        if \"image_sizes\" in forward_kwargs:\n",
        "            output[\"image_sizes\"] = forward_kwargs[\"image_sizes\"]\n",
        "        if \"token_type_ids\" in forward_kwargs:\n",
        "            output[\"token_type_ids\"] = forward_kwargs[\"token_type_ids\"]\n",
        "        if images is not None:\n",
        "            output[\"num_images\"] = num_images\n",
        "        clog(\"END _generate_and_score_completions\",\n",
        "             f\"prompt_ids.shape={tuple(prompt_ids.shape)}\",\n",
        "             f\"completion_ids.shape={tuple(completion_ids.shape)}\")\n",
        "        return output\n",
        "\n",
        "    def compute_liger_loss(self, unwrapped_model, inputs):\n",
        "        clog(\"ENTER compute_liger_loss\",\n",
        "             f\"prompt_ids.shape={tuple(inputs['prompt_ids'].shape)}\",\n",
        "             f\"completion_ids.shape={tuple(inputs['completion_ids'].shape)}\")\n",
        "        # Compute the per-token log probabilities for the model\n",
        "        prompt_ids, prompt_mask = inputs[\"prompt_ids\"], inputs[\"prompt_mask\"]\n",
        "        completion_ids, completion_mask = (\n",
        "            inputs[\"completion_ids\"],\n",
        "            inputs[\"completion_mask\"],\n",
        "        )\n",
        "        input_ids = torch.cat([prompt_ids, completion_ids], dim=1)\n",
        "        attention_mask = torch.cat([prompt_mask, completion_mask], dim=1)\n",
        "        logits_to_keep = completion_ids.size(\n",
        "            1\n",
        "        )  # we only need to compute the logits for the completion tokens\n",
        "\n",
        "        # Get the last hidden state of the model\n",
        "        last_hidden_state = self._get_last_hidden_state(\n",
        "            unwrapped_model,\n",
        "            input_ids,\n",
        "            attention_mask,\n",
        "            logits_to_keep,\n",
        "            inputs.get(\"pixel_values\"),\n",
        "            inputs.get(\"image_grid_thw\"),\n",
        "            inputs.get(\"pixel_attention_mask\"),\n",
        "            inputs.get(\"image_sizes\"),\n",
        "        )\n",
        "\n",
        "        # compute loss and metrics using liger grpo loss\n",
        "        loss, metrics = self.liger_grpo_loss(\n",
        "            _input=last_hidden_state,\n",
        "            lin_weight=unwrapped_model.lm_head.weight,\n",
        "            selected_token_ids=completion_ids,\n",
        "            attention_mask=completion_mask,\n",
        "            advantages=inputs[\"advantages\"],\n",
        "            bias=unwrapped_model.lm_head.bias,\n",
        "            old_per_token_logps=inputs.get(\"old_per_token_logps\"),\n",
        "            ref_per_token_logps=inputs.get(\"ref_per_token_logps\"),\n",
        "        )\n",
        "        # Extract metrics from the liger_grpo_loss output\n",
        "        # KL divergence is the first metric when beta is non-zero\n",
        "        mean_kl = metrics[0] if self.beta != 0.0 else None\n",
        "        clip_ratio = metrics[-1]\n",
        "\n",
        "        mode = \"train\" if self.model.training else \"eval\"\n",
        "        if self.beta != 0.0:\n",
        "            self._metrics[mode][\"kl\"].append(\n",
        "                self.accelerator.gather(mean_kl).mean().item()\n",
        "            )\n",
        "        self._metrics[mode][\"clip_ratio\"].append(\n",
        "            self.accelerator.gather(clip_ratio).mean().item()\n",
        "        )\n",
        "        clog(\"END compute_liger_loss\", f\"loss={float(loss.detach().float())}\")\n",
        "        return loss / self.current_gradient_accumulation_steps\n",
        "\n",
        "    @profiling_decorator\n",
        "    def compute_loss(\n",
        "        self, model, inputs, return_outputs=False, num_items_in_batch=None\n",
        "    ):\n",
        "        clog(\"ENTER compute_loss\", f\"use_liger_loss={self.use_liger_loss}\")\n",
        "        if return_outputs:\n",
        "            raise ValueError(\"The GRPOTrainer does not support returning outputs\")\n",
        "        if self.use_liger_loss:\n",
        "            # Compute the loss using the liger grpo loss\n",
        "            unwrapped_model = self.accelerator.unwrap_model(model)\n",
        "            result = self._forward_redirection(\n",
        "                model, unwrapped_model, self.compute_liger_loss, unwrapped_model, inputs\n",
        "            )\n",
        "            clog(\"END compute_loss (liger)\")\n",
        "            return result\n",
        "        else:\n",
        "            result = self._compute_loss(model, inputs)\n",
        "            clog(\"END compute_loss (standard)\")\n",
        "            return result\n",
        "\n",
        "    def _compute_loss(self, model, inputs):\n",
        "        clog(\"ENTER _compute_loss\",\n",
        "             f\"prompt_ids.shape={tuple(inputs['prompt_ids'].shape)}\",\n",
        "             f\"completion_ids.shape={tuple(inputs['completion_ids'].shape)}\",\n",
        "             f\"loss_type={self.loss_type}\",\n",
        "             f\"beta={self.beta}\",\n",
        "             f\"importance_sampling_level={self.importance_sampling_level}\")\n",
        "        # Compute the per-token log probabilities for the model\n",
        "        prompt_ids, prompt_mask = inputs[\"prompt_ids\"], inputs[\"prompt_mask\"]\n",
        "        completion_ids, completion_mask = (\n",
        "            inputs[\"completion_ids\"],\n",
        "            inputs[\"completion_mask\"],\n",
        "        )\n",
        "        input_ids = torch.cat([prompt_ids, completion_ids], dim=1)\n",
        "        attention_mask = torch.cat([prompt_mask, completion_mask], dim=1)\n",
        "        logits_to_keep = completion_ids.size(\n",
        "            1\n",
        "        )  # we only need to compute the logits for the completion tokens\n",
        "\n",
        "        # Compute the KL divergence between the model and the reference model\n",
        "        # Compute the per_token_logps and the entropy at each position in the completion\n",
        "        per_token_logps, entropies = self._get_per_token_logps_and_entropies(\n",
        "            model,\n",
        "            input_ids,\n",
        "            attention_mask,\n",
        "            logits_to_keep,\n",
        "            compute_entropy=True,\n",
        "            pixel_values=inputs.get(\"pixel_values\"),\n",
        "            image_grid_thw=inputs.get(\"image_grid_thw\"),\n",
        "            num_images=inputs.get(\"num_images\"),\n",
        "            pixel_attention_mask=inputs.get(\"pixel_attention_mask\"),\n",
        "            image_sizes=inputs.get(\"image_sizes\"),\n",
        "            token_type_ids=inputs.get(\"token_type_ids\"),\n",
        "        )\n",
        "\n",
        "        if self.top_entropy_quantile < 1.0:\n",
        "            entropy_mask = self.get_high_entropy_mask(\n",
        "                entropies, completion_mask, 1 - self.top_entropy_quantile\n",
        "            )\n",
        "        else:\n",
        "            entropy_mask = None\n",
        "\n",
        "        # Compute the KL divergence between the model and the reference model\n",
        "        if self.beta != 0.0:\n",
        "            ref_per_token_logps = inputs[\"ref_per_token_logps\"]\n",
        "            per_token_kl = (\n",
        "                torch.exp(ref_per_token_logps - per_token_logps)\n",
        "                - (ref_per_token_logps - per_token_logps)\n",
        "                - 1\n",
        "            )\n",
        "\n",
        "        # Compute the loss\n",
        "        advantages = inputs[\"advantages\"]\n",
        "        # When num_iterations == 1 and steps_per_generation <= gradient_accumulation_steps,\n",
        "        # old_per_token_logps == per_token_logps. In this case we can skip its computation\n",
        "        # (see _generate_and_score_completions) and instead use per_token_logps.detach().\n",
        "        # The exception is when using vLLM, where we always compute old_per_token_logps\n",
        "        # for importance sampling\n",
        "        old_per_token_logps = inputs.get(\"old_per_token_logps\")\n",
        "        old_per_token_logps = (\n",
        "            per_token_logps.detach()\n",
        "            if old_per_token_logps is None\n",
        "            else old_per_token_logps\n",
        "        )\n",
        "\n",
        "        log_ratio = per_token_logps - old_per_token_logps\n",
        "        if self.importance_sampling_level == \"token\":\n",
        "            log_importance_weights = log_ratio\n",
        "        elif self.importance_sampling_level == \"sequence\":\n",
        "            log_importance_weights = (log_ratio * completion_mask).sum(\n",
        "                -1\n",
        "            ) / completion_mask.sum(-1).clamp(min=1.0)\n",
        "            log_importance_weights = log_importance_weights.unsqueeze(-1)\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Unknown importance sampling level: {self.importance_sampling_level}. Possible values are 'token' \"\n",
        "                \"and 'sequence'.\"\n",
        "            )\n",
        "        # From here, log_importance_weights (and all subsequent tensors, coef_1, coef_2, etc.) shape depends on\n",
        "        # importance_sampling_level: \"token\" level: (B, T); \"sequence\" level: (B, 1)\n",
        "\n",
        "        coef_1 = torch.exp(log_importance_weights)\n",
        "        coef_2 = torch.clamp(coef_1, 1 - self.epsilon_low, 1 + self.epsilon_high)\n",
        "\n",
        "        # Two-sided clipping\n",
        "        if self.args.delta is not None:\n",
        "            coef_1 = torch.clamp(coef_1, max=self.args.delta)\n",
        "\n",
        "        per_token_loss1 = coef_1 * advantages.unsqueeze(1)\n",
        "        per_token_loss2 = coef_2 * advantages.unsqueeze(1)\n",
        "        per_token_loss = -torch.min(per_token_loss1, per_token_loss2)\n",
        "        if entropy_mask is not None:\n",
        "            per_token_loss = per_token_loss * entropy_mask\n",
        "\n",
        "        if self.use_vllm and self.vllm_importance_sampling_correction:\n",
        "            per_token_loss = per_token_loss * inputs[\"importance_sampling_ratio\"]\n",
        "\n",
        "        if self.beta != 0.0:\n",
        "            per_token_loss = per_token_loss + self.beta * per_token_kl\n",
        "\n",
        "        if self.loss_type == \"grpo\":\n",
        "            loss = (\n",
        "                (per_token_loss * completion_mask).sum(-1)\n",
        "                / completion_mask.sum(-1).clamp(min=1.0)\n",
        "            ).mean()\n",
        "            loss = loss / self.current_gradient_accumulation_steps\n",
        "        elif self.loss_type == \"bnpo\":\n",
        "            loss = (\n",
        "                per_token_loss * completion_mask\n",
        "            ).sum() / completion_mask.sum().clamp(min=1.0)\n",
        "            loss = loss / self.current_gradient_accumulation_steps\n",
        "        elif self.loss_type == \"dr_grpo\":\n",
        "            loss = (per_token_loss * completion_mask).sum() / (\n",
        "                per_token_loss.size(0) * self.max_completion_length\n",
        "            )\n",
        "            loss = loss / self.current_gradient_accumulation_steps\n",
        "        elif self.loss_type == \"dapo\":\n",
        "            normalizer = inputs[\"num_items_in_batch\"] / self.accelerator.num_processes\n",
        "            loss = (per_token_loss * completion_mask).sum() / normalizer\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown loss type: {self.loss_type}\")\n",
        "\n",
        "        # Log the metrics\n",
        "        mode = \"train\" if self.model.training else \"eval\"\n",
        "\n",
        "        completion_token_count = completion_mask.sum().clamp(min=1.0)\n",
        "\n",
        "        def masked_batch_mean(x):\n",
        "            if x.shape[1] == 1:  # when importance_sampling_level == \"sequence\"\n",
        "                return x.mean()\n",
        "            else:\n",
        "                return (x * completion_mask).sum() / completion_token_count\n",
        "\n",
        "        if self.beta != 0.0:\n",
        "            mean_kl = masked_batch_mean(per_token_kl)\n",
        "            self._metrics[mode][\"kl\"].append(\n",
        "                self.accelerator.gather(mean_kl).nanmean().item()\n",
        "            )\n",
        "\n",
        "        mean_entropy = masked_batch_mean(entropies)\n",
        "        self._metrics[mode][\"entropy\"].append(\n",
        "            self.accelerator.gather(mean_entropy).nanmean().item()\n",
        "        )\n",
        "\n",
        "        # Compute the clipped probability ratios\n",
        "        is_low_clipped = (coef_1 < 1 - self.epsilon_low) & (advantages.unsqueeze(1) < 0)\n",
        "        is_high_clipped = (coef_1 > 1 + self.epsilon_high) & (\n",
        "            advantages.unsqueeze(1) > 0\n",
        "        )\n",
        "        is_region_clipped = is_low_clipped | is_high_clipped\n",
        "\n",
        "        low_clip = masked_batch_mean(is_low_clipped.float())\n",
        "        high_clip = masked_batch_mean(is_high_clipped.float())\n",
        "        clip_ratio = masked_batch_mean(is_region_clipped.float())\n",
        "\n",
        "        gathered_low_clip = self.accelerator.gather(low_clip)\n",
        "        self._metrics[mode][\"clip_ratio/low_mean\"].append(\n",
        "            gathered_low_clip.nanmean().item()\n",
        "        )\n",
        "        self._metrics[mode][\"clip_ratio/low_min\"].append(\n",
        "            nanmin(gathered_low_clip).item()\n",
        "        )\n",
        "        gathered_high_clip = self.accelerator.gather(high_clip)\n",
        "        self._metrics[mode][\"clip_ratio/high_mean\"].append(\n",
        "            gathered_high_clip.nanmean().item()\n",
        "        )\n",
        "        self._metrics[mode][\"clip_ratio/high_max\"].append(\n",
        "            nanmax(gathered_high_clip).item()\n",
        "        )\n",
        "        gathered_clip_ratio = self.accelerator.gather(clip_ratio)\n",
        "        self._metrics[mode][\"clip_ratio/region_mean\"].append(\n",
        "            gathered_clip_ratio.nanmean().item()\n",
        "        )\n",
        "        clog(\"END _compute_loss\", f\"loss={float(loss.detach().float())}\")\n",
        "        return loss\n",
        "\n",
        "    def prediction_step(\n",
        "        self,\n",
        "        model,\n",
        "        inputs,\n",
        "        prediction_loss_only,\n",
        "        ignore_keys: Optional[list[str]] = None,\n",
        "    ):\n",
        "        clog(\"ENTER prediction_step\", f\"prediction_loss_only={prediction_loss_only}\")\n",
        "        inputs = self._prepare_inputs(inputs)\n",
        "        with torch.no_grad():\n",
        "            with self.compute_loss_context_manager():\n",
        "                loss = self.compute_loss(model, inputs)\n",
        "            loss = loss.mean().detach()\n",
        "        clog(\"END prediction_step\", f\"loss={float(loss)}\")\n",
        "        return loss, None, None\n",
        "\n",
        "    def log(self, logs: dict[str, float], start_time: Optional[float] = None) -> None:\n",
        "        clog(\"ENTER log\", f\"keys={list(logs.keys())}\")\n",
        "        mode = \"train\" if self.model.training else \"eval\"\n",
        "        metrics = {\n",
        "            key: sum(val) / len(val) for key, val in self._metrics[mode].items()\n",
        "        }  # average the metrics\n",
        "\n",
        "        # This method can be called both in training and evaluation. When called in evaluation, the keys in `logs`\n",
        "        # start with \"eval_\". We need to add the prefix \"eval_\" to the keys in `metrics` to match the format.\n",
        "        if mode == \"eval\":\n",
        "            metrics = {f\"eval_{key}\": val for key, val in metrics.items()}\n",
        "\n",
        "        logs = {**logs, **metrics}\n",
        "        super().log(logs, start_time)\n",
        "        self._metrics[mode].clear()\n",
        "\n",
        "        if self.accelerator.is_main_process and self.log_completions:\n",
        "            if is_rich_available():\n",
        "                print_prompt_completions_sample(\n",
        "                    self._logs[\"prompt\"],\n",
        "                    self._logs[\"completion\"],\n",
        "                    self._logs[\"rewards\"],\n",
        "                    self._logs[\"advantages\"],\n",
        "                    self.state.global_step,\n",
        "                    self.num_completions_to_print,\n",
        "                )\n",
        "\n",
        "            if (\n",
        "                self.args.report_to\n",
        "                and \"wandb\" in self.args.report_to\n",
        "                and wandb.run is not None\n",
        "            ):\n",
        "                import pandas as pd\n",
        "\n",
        "                table = {\n",
        "                    \"step\": [str(self.state.global_step)] * len(self._logs[\"prompt\"]),\n",
        "                    \"prompt\": self._logs[\"prompt\"],\n",
        "                    \"completion\": self._logs[\"completion\"],\n",
        "                    **self._logs[\"rewards\"],\n",
        "                    \"advantage\": self._logs[\"advantages\"],\n",
        "                }\n",
        "\n",
        "                if self._logs[\"images\"]:\n",
        "                    table[\"images\"] = []\n",
        "                    for image_list in self._logs[\"images\"]:\n",
        "                        # Convert images to wandb Image objects for proper visualization\n",
        "                        table[\"images\"].append(\n",
        "                            [wandb.Image(image) for image in image_list]\n",
        "                        )\n",
        "\n",
        "                df = pd.DataFrame(table)\n",
        "                if self.wandb_log_unique_prompts:\n",
        "                    df = df.drop_duplicates(subset=[\"prompt\"])\n",
        "                wandb.log({\"completions\": wandb.Table(dataframe=df)})\n",
        "        clog(\"END log\")\n",
        "\n",
        "    # Ensure the model card is saved along with the checkpoint\n",
        "    def _save_checkpoint(self, model, trial):\n",
        "        clog(\"ENTER _save_checkpoint\")\n",
        "        if self.args.hub_model_id is None:\n",
        "            model_name = Path(self.args.output_dir).name\n",
        "        else:\n",
        "            model_name = self.args.hub_model_id.split(\"/\")[-1]\n",
        "        self.create_model_card(model_name=model_name)\n",
        "        clog(\"_save_checkpoint created model card\", f\"model_name={model_name}\")\n",
        "        super()._save_checkpoint(model, trial)\n",
        "        clog(\"END _save_checkpoint\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BN2DtPB2EtH"
      },
      "outputs": [],
      "source": [
        "\n",
        "from trl import GRPOConfig\n",
        "from peft import LoraConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9l74BQb2VxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e7c3161-c9b6-4754-f79a-a51ad0dd202a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run_name  Voxtral-Mini-3B-2507 , output_dir  mistralai/Voxtral-Mini-3B-2507\n"
          ]
        }
      ],
      "source": [
        "model_name = \"mistralai/Voxtral-Mini-3B-2507\"\n",
        "#model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "output_dir = model_name\n",
        "#\"outputs/SmolLM2-135M-GRPO\"\n",
        "run_name = model_name.split(\"/\")[1]\n",
        "print(\"run_name \",run_name,\", output_dir \",output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import trackio"
      ],
      "metadata": {
        "id": "VP7udjOM2bYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wandb\n",
        "\n",
        "# Option A: Set as environment variable within the script\n",
        "os.environ[\"WANDB_API_KEY\"] = \"8d4c03a7885d2ce91c96eddd4b885228560cea7c\"\n"
      ],
      "metadata": {
        "id": "EFkoNTIAYBUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFgsgkHX2M7Y"
      },
      "outputs": [],
      "source": [
        "max_prompt_length = 1024\n",
        "max_completion_length = 1024\n",
        "\n",
        "training_args = GRPOConfig(\n",
        "    output_dir=output_dir,\n",
        "    run_name=run_name,\n",
        "    learning_rate=5e-6,\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.99,\n",
        "    weight_decay=0.1,\n",
        "    warmup_ratio=0.1,\n",
        "    lr_scheduler_type='cosine',\n",
        "    logging_steps=1,\n",
        "    bf16=True,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    num_generations=8,  # Kept as is\n",
        "    max_prompt_length=max_prompt_length,\n",
        "    max_completion_length=max_completion_length,\n",
        "    num_train_epochs=5,\n",
        "    save_steps=3,\n",
        "    max_grad_norm=0.1,\n",
        "    report_to=[\"trackio\",\"wandb\"][1],\n",
        "    log_on_each_node=False,\n",
        "\n",
        ")\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=8,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    lora_dropout=0.05,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKWVT6bFQU6a"
      },
      "outputs": [],
      "source": [
        "from transformers import VoxtralForConditionalGeneration, AutoProcessor, Gemma3nForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "device = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfTFDx6PQy-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec53f92-e676-4339-a1ab-ef14a0bbd6b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m⚠️  Warning: 'huggingface-cli login' is deprecated. Use 'hf auth login' instead.\u001b[0m\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `hf`CLI if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `gemma` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `gemma`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login --token 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"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name"
      ],
      "metadata": {
        "id": "iE9O0sdaRDPx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "33e2fa19-fe27-4b06-a846-57e3f6f6e4d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mistralai/Voxtral-Mini-3B-2507'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6T_c6n5QVBB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502,
          "referenced_widgets": [
            "f0adb71d94aa48aaa86c0248da3365d6",
            "d36be7ebacdc4b338cb187d7daf6dc86",
            "d49a9e1580cf47ebae51c84b4abee4e1",
            "bdaa85b8c3c94def957dbee1182366c0",
            "1606607d00994d598e214c850cfcbb45",
            "e123d133751747999d2aae91f9b62b93",
            "657d76bca1994b9ca25c6637e2e60cdc",
            "1c0cd1b7423c45ea99914ec00b0f2219",
            "9ad6c3865290477b880e5a76fee9ddb9",
            "7fc68dabf531483ebfa3b22c94080e39",
            "e6f7c7d74aa4461186665dd887aebf43",
            "9890e851b44e484598295c9973638509",
            "c6c9419c8f704780b337655fcb530a29",
            "cb16c9b1a781417abf4da87281304a3a",
            "1da3dd9ad2d54fff863f9a3976243881",
            "0f4d49ef7d484827abe7993423bafe91",
            "c5cb6e4380e0448195f43bd25128cb6d",
            "bc44a5312efe4418b6ec62e1b44e629a",
            "2affea4532ba4e299178a42e50c0ad5f",
            "c30e86b98290471eafe3206c97ff855d",
            "13a1cf86ddd5414aa08df81597d8d367",
            "5701f559ace24569a7f54336d56f35fc",
            "5efe798fc92e4580981ba658489ea76c",
            "d79fe35ea08a4c27aafe1dbe047da724",
            "5a3d8dcac17544fc843454261922feca",
            "adaa3660a07d4d78bafa98c3bdda0273",
            "c686265744fd42a0afa0129c20d3c266",
            "74b8649a73f8477790489d7c6fdffca2",
            "0bc881ca1f8140958e0463c601e3756c",
            "d2b0f5306a9b4d53a3e52be361c770b8",
            "9a2c7f0008ee47cb8b561c10697a74c1",
            "a4ed064312604937815674772a5aedbf",
            "b8f80dd62877436ea8689a65c56c3333",
            "1e307d42209c4d239c848abd2acd810d",
            "8ba7cafca23c43c3a07412941e77bc75",
            "f47424574dca4befa5b12de19607d7ab",
            "adaa34a49d1a4ab1a229afcca981bf0c",
            "79f9e9f7a2d74184b0d518246b9e4cca",
            "f8a6cb448f33424db778b53c7bdc307b",
            "85fd2b98cb324eb38e664725beb6e547",
            "87cf614d786441b0bdd1ee06a5dfa9f6",
            "644f54ec983c4ed1a1b32bc2470dbcce",
            "2e403ce499854d7db175dd1ab6a25167",
            "2eeb4e3807ef45d19bf4c12315c8d788",
            "0fe5a565869b48a5a30a40eeeee791f0",
            "0717b171ed8049739b2c77868250b05d",
            "c7659b613faf4cd0b883df440321ad96",
            "6d7737d5b6eb4876bbc5b1bb34da8736",
            "e830c701986d45b986cac4b7a1d5cd21",
            "ca62a3bcedc64d688fdab69b7d5fadfc",
            "bff6bf1b667141459b026efcc697f3cc",
            "cddce9bd659846ccb24f1dc9c7b79116",
            "c64ddd6b209040d2b5fc322b5f667fe3",
            "a366cc6ee4694985b8aba1124805a6c1",
            "9a77c02c18da480395e090c2f04b60ad",
            "e2868392b4b14e70a1492b919b88c91c",
            "84d826db822b4234803770e703b19af2",
            "bb86c2aec64244f597a70271f46a712f",
            "b6b53d6b67254d2ebfbce463e0936678",
            "1373e095a275455e98972c6381b0d390",
            "9eb93e6485e342b6a7ab16acaa4ed580",
            "86c38bc3296141fe8db6e8b068e162a4",
            "baded0342ef24741a32ba4bff83fb4b5",
            "42e30bf75a8043e99e832dc33c2ea464",
            "29004459c9c547ce8d747ed85c361209",
            "e47dfe51a39d4a079ccf2d7525c23e8e",
            "b255d9239ceb4bef8f6040d84b9b3e28",
            "563cb8bcf79844499624b5bdc2fee012",
            "f46a8ff3b9204b79b49eba9e7322c621",
            "0377e1e5f545456c89a02ced46674bfa",
            "1e5e8aa7d1d344e1bbf60387a85d8466",
            "530f7356a726455992fc264ac8e72896",
            "0708e27dfaf14f6fb9c20000fbd85993",
            "5270abdd471a440c9a036400f67c4c5e",
            "de979f434af54ef1a1784e78994ecd40",
            "3f5747cbbe604108a2b16c999be2bb58",
            "f8c20c61885e4aa6b36c736214cc675f",
            "a2096cd8cc2b48ebbefa01c02fbfb4b5",
            "2bfc8e51f1a645fbb312285342851dc5",
            "55717cbcb872419698c85d1c064540ea",
            "e4d222d6ea65461f9ac3c8743ecf9920",
            "45c4456923044dd8ba18266955ce9e4b",
            "a18cdde4dd414d43af509053ed11538c",
            "f13d4de977184c20a496fe3691bccd46",
            "a82e607fd19b42b185cc11141bf35ea1",
            "abeaf616db5146529e4494e5874d6d4c",
            "56123aa499b2426d8043954bfff22da9",
            "0461ff6e696a4c2cae152e152ec66299",
            "1129f1e5ed3a435581c18ae97c5fdd09",
            "13ccd7ae082c432b9c9ce5a5f049972d",
            "e0e66f21fd9645faae8372fb59f9979c",
            "12bc6224fe384e21bc4d2c034ef59b17",
            "ddec1451cd1441328def6d496f1f363c",
            "8dbe352f6bd140baa259fcb7039c1923",
            "cd2ba848f6fa4846853bdcfd24737620",
            "86d2d52dcca94bbbb06f51cecc2d6252",
            "0d606fcf81524da8a17c1c03e52fc5e5",
            "39b35b61d2dc4901b1ea4f5018a6a1db",
            "a3483e25edb9437a9f0192f89e25d747"
          ]
        },
        "outputId": "4e97d7c4-0513-4b8c-d24e-e97fc4ec9948"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/357 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0adb71d94aa48aaa86c0248da3365d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tekken.json:   0%|          | 0.00/14.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9890e851b44e484598295c9973638509"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5efe798fc92e4580981ba658489ea76c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e307d42209c4d239c848abd2acd810d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0fe5a565869b48a5a30a40eeeee791f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2868392b4b14e70a1492b919b88c91c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/4.38G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b255d9239ceb4bef8f6040d84b9b3e28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2096cd8cc2b48ebbefa01c02fbfb4b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/108 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1129f1e5ed3a435581c18ae97c5fdd09"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#model = Gemma3nForConditionalGeneration.from_pretrained(model_name, dtype=torch.bfloat16,)\n",
        "#.eval()\n",
        "device = \"cuda\"\n",
        "processor = AutoProcessor.from_pretrained(model_name)\n",
        "model = VoxtralForConditionalGeneration.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#del whisper_model"
      ],
      "metadata": {
        "id": "sGKmq2R8S4s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OA95RxXuThgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "daudio_new_dataset = Dataset.from_dict(daudio_new)"
      ],
      "metadata": {
        "id": "N_ni5P5rSZXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daudio_new_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqyq-3n1V4sn",
        "outputId": "240a1d7c-37d4-4777-98cc-936ab675299b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['answer', 'prompt'],\n",
              "    num_rows: 49\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "daudio_new_dataset['prompt'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G0P_l8gL0vt",
        "outputId": "8e206257-1e76-4ee2-a632-c91bcd0991bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': [{'path': '/content/chunks/id_1/id_1_chunk_0005.mp3',\n",
              "    'text': None,\n",
              "    'type': 'audio'},\n",
              "   {'path': None,\n",
              "    'text': \"You are given an audio conversation and past conversation happening between an american express customer care professional and a customer.\\nThis customer can be either a genuine customer or a fraudster.\\n\\n## Your Task \\nPredict a probability that the customer is a fraudster\\n\\nIn order to predict the probability of fraud you should think and analyze the situation and create a reasoning.\\nMake sure you see each and every aspect of the case and create a case report while reasoning about the case.\\nNote that the permissible values of probability are 0.0, 0.25, 0.5, 0.75, 1.0\\n\\nThe reasoning process should be enclosed within <think> </think> tags\\nWhile the final answer should be enclosed in <answer> </answer> tags\\n\\nExample Response : \\n<think>This is my reasoning</think>\\n<answer>0.75</answer>\\n\\nPast Conversation : Thank you for calling American Express. You're speaking with Maya. How can I help today? Hi, Maya. This is Alex Bennett. I'm calling about my September statement. The interest looks a lot higher than usual, and I'd like to understand why. I'm happy to explain, Alex. I'll just verify your account. Could you confirm your full name, last four digits on the card, billing ZSB, and email on file? is alex.bennettbaymail.com. 90 days. Thank you. Verified. Looking at August, I see you carried a balance of $1,920. Your payment posted on September 18, two days after the due date, which triggered a $29 late fee and interest on the average daily balance. That's why September's finance charge is higher. Okay, that tracks. I usually pay on the due date, so I must have years. You do have a strong history. I can submit a one-time courtesy waiver right now. It'll post within 2448 hours and reflect on your next statement. I'd appreciate that. Also, the due date is the 16th. Can I move it closer to my paycheck on the 25th? Absolutely. We can shift your statement cycle so the payment due date lands around the 25th. It will take one cycle to To help avoid this again, I recommend auto-pay for statement balance and push reminders. Would you like me to enroll you now? Yes. Use my Chase checking ending FK 187. Auto-pay set. You'll receive confirmation at alex.bennettbaymail.com. Anything else on the statement? There's a $3.50 from CloudStore. I forgot. That's my storage subscription.\",\n",
              "    'type': 'text'}],\n",
              "  'role': 'user'}]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " daudio_new['prompt'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvoaqEEmLuA5",
        "outputId": "0c5c0623-5ee9-410c-f328-ab5e1a64fbb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'user',\n",
              "  'content': [{'type': 'audio',\n",
              "    'path': '/content/chunks/id_1/id_1_chunk_0005.mp3'},\n",
              "   {'type': 'text',\n",
              "    'text': \"You are given an audio conversation and past conversation happening between an american express customer care professional and a customer.\\nThis customer can be either a genuine customer or a fraudster.\\n\\n## Your Task \\nPredict a probability that the customer is a fraudster\\n\\nIn order to predict the probability of fraud you should think and analyze the situation and create a reasoning.\\nMake sure you see each and every aspect of the case and create a case report while reasoning about the case.\\nNote that the permissible values of probability are 0.0, 0.25, 0.5, 0.75, 1.0\\n\\nThe reasoning process should be enclosed within <think> </think> tags\\nWhile the final answer should be enclosed in <answer> </answer> tags\\n\\nExample Response : \\n<think>This is my reasoning</think>\\n<answer>0.75</answer>\\n\\nPast Conversation : Thank you for calling American Express. You're speaking with Maya. How can I help today? Hi, Maya. This is Alex Bennett. I'm calling about my September statement. The interest looks a lot higher than usual, and I'd like to understand why. I'm happy to explain, Alex. I'll just verify your account. Could you confirm your full name, last four digits on the card, billing ZSB, and email on file? is alex.bennettbaymail.com. 90 days. Thank you. Verified. Looking at August, I see you carried a balance of $1,920. Your payment posted on September 18, two days after the due date, which triggered a $29 late fee and interest on the average daily balance. That's why September's finance charge is higher. Okay, that tracks. I usually pay on the due date, so I must have years. You do have a strong history. I can submit a one-time courtesy waiver right now. It'll post within 2448 hours and reflect on your next statement. I'd appreciate that. Also, the due date is the 16th. Can I move it closer to my paycheck on the 25th? Absolutely. We can shift your statement cycle so the payment due date lands around the 25th. It will take one cycle to To help avoid this again, I recommend auto-pay for statement balance and push reminders. Would you like me to enroll you now? Yes. Use my Chase checking ending FK 187. Auto-pay set. You'll receive confirmation at alex.bennettbaymail.com. Anything else on the statement? There's a $3.50 from CloudStore. I forgot. That's my storage subscription.\"}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " daudio_new['prompt'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJAeD0a6E5_A",
        "outputId": "7afd5f53-69f7-409d-d9ef-ef0d61b0fff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'user',\n",
              "  'content': [{'type': 'audio',\n",
              "    'path': '/content/chunks/id_1/id_1_chunk_0005.mp3'},\n",
              "   {'type': 'text',\n",
              "    'text': \"You are given an audio conversation and past conversation happening between an american express customer care professional and a customer.\\nThis customer can be either a genuine customer or a fraudster.\\n\\n## Your Task \\nPredict a probability that the customer is a fraudster\\n\\nIn order to predict the probability of fraud you should think and analyze the situation and create a reasoning.\\nMake sure you see each and every aspect of the case and create a case report while reasoning about the case.\\nNote that the permissible values of probability are 0.0, 0.25, 0.5, 0.75, 1.0\\n\\nThe reasoning process should be enclosed within <think> </think> tags\\nWhile the final answer should be enclosed in <answer> </answer> tags\\n\\nExample Response : \\n<think>This is my reasoning</think>\\n<answer>0.75</answer>\\n\\nPast Conversation : Thank you for calling American Express. You're speaking with Maya. How can I help today? Hi, Maya. This is Alex Bennett. I'm calling about my September statement. The interest looks a lot higher than usual, and I'd like to understand why. I'm happy to explain, Alex. I'll just verify your account. Could you confirm your full name, last four digits on the card, billing ZSB, and email on file? is alex.bennettbaymail.com. 90 days. Thank you. Verified. Looking at August, I see you carried a balance of $1,920. Your payment posted on September 18, two days after the due date, which triggered a $29 late fee and interest on the average daily balance. That's why September's finance charge is higher. Okay, that tracks. I usually pay on the due date, so I must have years. You do have a strong history. I can submit a one-time courtesy waiver right now. It'll post within 2448 hours and reflect on your next statement. I'd appreciate that. Also, the due date is the 16th. Can I move it closer to my paycheck on the 25th? Absolutely. We can shift your statement cycle so the payment due date lands around the 25th. It will take one cycle to To help avoid this again, I recommend auto-pay for statement balance and push reminders. Would you like me to enroll you now? Yes. Use my Chase checking ending FK 187. Auto-pay set. You'll receive confirmation at alex.bennettbaymail.com. Anything else on the statement? There's a $3.50 from CloudStore. I forgot. That's my storage subscription.\"}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor.apply_chat_template( daudio_new['prompt'][0])\n",
        "inputs = inputs.to(device, dtype=torch.bfloat16)\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=500)\n",
        "decoded_outputs = processor.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "print(\"\\nGenerated response:\")\n",
        "print(\"=\" * 80)\n",
        "print(decoded_outputs[0])\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CDSe532FeHt",
        "outputId": "81b21853-c379-4e59-fe40-bdb7256947fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated response:\n",
            "================================================================================\n",
            "<think>\n",
            "The customer, Alex Bennett, is asking about a higher-than-usual finance charge on his September statement, which is a common reason for customers to contact customer service. However, there are a few red flags in the conversation:\n",
            "1. The customer's email address is unusual and not typical for a genuine customer (e.g., \"alex.bennettbaymail.com\").\n",
            "2. The customer's last name is not mentioned, which is unusual for a genuine customer who would typically provide their full name for verification.\n",
            "3. The customer's card number is not provided, which is a common requirement for verification.\n",
            "4. The customer's billing address is not mentioned, which is also unusual for a genuine customer.\n",
            "5. The customer's request to move the due date closer to his paycheck is not typical, as it could be a sign of financial distress or a lack of understanding of the billing cycle.\n",
            "6. The customer's request to enroll in auto-pay and push reminders is not typical, as it could be a sign of a lack of understanding of the billing process or a desire to avoid late fees.\n",
            "7. The customer's request to submit a one-time courtesy waiver is not typical, as it could be a sign of a lack of understanding of the billing process or a desire to avoid paying the late fee.\n",
            "\n",
            "Given these red flags, it is possible that the customer is a fraudster. However, it is also possible that the customer is a genuine customer who is simply not familiar with the billing process. The probability of fraud is higher than the probability of a genuine customer, but it is not certain. The probability of fraud is estimated to be 0.75.\n",
            "</think>\n",
            "<answer>0.75</answer>\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOEA15e7aKvo"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def reasoning_tag_reward(ip):\n",
        "  start_tag = \"<think>\"\n",
        "  end_tag = \"</think>\"\n",
        "  start_index = ip.find(start_tag)\n",
        "  end_index = ip.find(end_tag)\n",
        "  score = 0\n",
        "  if start_index != -1:\n",
        "     score += 1\n",
        "  if end_index != -1:\n",
        "     score +=1\n",
        "  print(\"reasoning_tag_reward -->\",score,\"<--\")\n",
        "  return score\n",
        "\n",
        "def answer_tag_reward(ip):\n",
        "    start_tag = \"<answer>\"\n",
        "    end_tag = \"</answer>\"\n",
        "    start_index = ip.find(start_tag)\n",
        "    end_index = ip.find(end_tag)\n",
        "    score = 0\n",
        "    if start_index != -1:\n",
        "      score += 1\n",
        "    if end_index != -1:\n",
        "      score +=1\n",
        "    print(\"answer_tag_reward -->\",score,\"<--\")\n",
        "    return score\n",
        "\n",
        "\n",
        "def extract_numeric_part(ip_str):\n",
        "  print(\"## start of extract_numeric_part\")\n",
        "  print(\"ip_str -->\",ip_str,\"<--\")\n",
        "  # Extract all numbers (integers and floats)\n",
        "  # This pattern looks for digits, optionally followed by a decimal point and more digits\n",
        "  numbers = re.findall(r'\\d+\\.?\\d*', ip_str)\n",
        "  print(f\"Numbers (including floats): {numbers}\")\n",
        "  numbers_as_float = [float(num) for num in numbers]\n",
        "  print(\"numbers_as_float \",numbers_as_float)\n",
        "  print(\"## end of extract_numeric_part\")\n",
        "  return numbers_as_float\n",
        "\n",
        "\n",
        "def get_answer_from_answer_tag(ip):\n",
        "    print(\"## start of get_answer_from_answer_tag\")\n",
        "    print(\"ip is -->\",ip,\"<--\")\n",
        "    start_tag = \"<answer>\"\n",
        "    end_tag = \"</answer>\"\n",
        "    start_index = ip.find(start_tag)\n",
        "    end_index = ip.find(end_tag)\n",
        "    if start_index == -1:\n",
        "      return \"\"\n",
        "    if end_index == -1:\n",
        "      return \"\"\n",
        "\n",
        "    ip_trimmed = ip[start_index+len(start_tag):end_index]\n",
        "    print(\"ip_trimmed -->\",ip_trimmed,\"<--\")\n",
        "    print(\"## end of get_answer_from_answer_tag\")\n",
        "    return ip_trimmed\n",
        "\n",
        "log = {'completion':[],'c_content':[],'prompt':[],'answer':[],\n",
        "       'correct_answer_reward':[],'answer_tag_reward':[],\n",
        "       'resoning_tag_reward':[],'ith':[],'enp':[],'c_content_answer':[],'final_score':[],\n",
        "       'global_counter':[],'user_prompt':[]}\n",
        "\n",
        "import math\n",
        "def correct_answer_reward(c_content,a):\n",
        "    print(\"## start of correct_answer_reward\")\n",
        "    print(\"c_content -->\",c_content,\"<--\")\n",
        "    print(\"a -->\",a,\"<--\")\n",
        "    c_content_answer = get_answer_from_answer_tag(c_content)\n",
        "    enp = extract_numeric_part(c_content_answer)\n",
        "    if len(enp)==0:\n",
        "      return [],0,\"\"\n",
        "\n",
        "\n",
        "    llm_ans = float(enp[0])\n",
        "    a = float(a)\n",
        "\n",
        "    if (llm_ans<=1) and (llm_ans>=0):\n",
        "      score  = min(1,max(0,1-abs(llm_ans-a)))\n",
        "    else:\n",
        "      score = 0\n",
        "\n",
        "    score = score*2.5\n",
        "\n",
        "    print(f\"enp {enp}, score {score}, c_content_answer {c_content_answer}\")\n",
        "    print(\"## end of correct_answer_reward\")\n",
        "    return enp, score, c_content_answer\n",
        "\n",
        "global global_counter\n",
        "global_counter = 0\n",
        "def check_answer(prompts, completions, answer, **kwargs):\n",
        "    global global_counter\n",
        "    print(\"## start of def check_answer\")\n",
        "    global_counter += 1\n",
        "    scores = []\n",
        "    ith = 0\n",
        "    print(\"*Global Counter \",global_counter)\n",
        "    print(\"# start of iterating over all completions\")\n",
        "    for p,c,a in zip(prompts,completions,answer):\n",
        "        print(f\"ith -> {ith} <-\")\n",
        "       # print(\"prompt ->\",p,\"<-\")\n",
        "        print(\"completion ->\",c,\"<-\")\n",
        "        print(\"answer ->\",a,\"<-\")\n",
        "        ith += 1\n",
        "\n",
        "        user_prompt = \"\"\n",
        "        for p_e in p:\n",
        "           if p_e['role'] == 'user':\n",
        "             user_prompt_content = p_e['content']\n",
        "             for upc in user_prompt_content:\n",
        "               if upc['type'] == 'text':\n",
        "                 user_prompt = upc['text']\n",
        "                 break\n",
        "           if user_prompt != \"\":\n",
        "             break\n",
        "\n",
        "       # user_prompt = p[1]['content']['text']\n",
        "        print(\"user_prompt -->\",user_prompt)\n",
        "        c_content = str(c[0]['content']).strip()\n",
        "        rtr = reasoning_tag_reward(c_content)\n",
        "        atr = answer_tag_reward(c_content)\n",
        "        enp, car, c_content_answer = correct_answer_reward(c_content,a)\n",
        "\n",
        "\n",
        "        score = rtr+atr+car\n",
        "        log['completion'].append(c)\n",
        "        log['c_content'].append(c_content)\n",
        "        log['prompt'].append(p)\n",
        "        log['answer'].append(a)\n",
        "        log['correct_answer_reward'].append(car)\n",
        "        log['answer_tag_reward'].append(atr)\n",
        "        log['resoning_tag_reward'].append(rtr)\n",
        "        log['ith'].append(ith)\n",
        "        log['enp'].append(enp)\n",
        "        log['c_content_answer'].append(c_content_answer)\n",
        "        log['final_score'].append(score)\n",
        "        log['global_counter'].append(global_counter)\n",
        "        log['user_prompt'].append(user_prompt)\n",
        "        log_df = pd.DataFrame(log)\n",
        "        log_df.to_excel(f'log_{log_df.shape}.xlsx',index=False)\n",
        "      #  print(\"score -->\",score,\"<--\")\n",
        "        scores.append(score)\n",
        "        print(f\"--> end of ith {ith}\")\n",
        "\n",
        "    print(\"# end of iterating over all completions\")\n",
        "    print(\"##  end of def check_answer\")\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hcpF-9YZ96A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caaee872-ee02-4c64-a78e-17ff921c6939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['answer', 'prompt'],\n",
            "    num_rows: 49\n",
            "})\n",
            "Features says: {'answer': Value('string'), 'prompt': List({'content': List({'path': Value('string'), 'text': Value('string'), 'type': Value('string')}), 'role': Value('string')})}\n",
            "Actual columns: ['answer', 'prompt']\n"
          ]
        }
      ],
      "source": [
        "print(daudio_new_dataset)  # or whatever variable holds your dataset\n",
        "\n",
        "print(\"Features says:\", daudio_new_dataset.features)\n",
        "\n",
        "print(\"Actual columns:\", daudio_new_dataset.column_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def remove_none_fields(prompt_old):\n",
        "    prompt = prompt_old.copy()\n",
        "    prompt_new = []\n",
        "\n",
        "    for pL in prompt:\n",
        "      pL_new = \"\"\n",
        "      print(\"pL \",pL)\n",
        "      pL_content = pL['content']\n",
        "      pL_content_new = []\n",
        "\n",
        "      for pLc in pL_content:\n",
        "          print(\"pLc \",pLc)\n",
        "          pLc_clean = {k: v for k, v in pLc.items() if v is not None}\n",
        "          pL_content_new.append(pLc_clean)\n",
        "\n",
        "      pL_new = {'content':pL_content_new,'role':pL['role']}\n",
        "      prompt_new.append(pL_new)\n",
        "    return prompt_new\n",
        "\n",
        "\n",
        "\n",
        "def maybe_apply_chat_template(\n",
        "    example: dict[str, list[dict[str, str]]],\n",
        "    tokenizer: Union[PreTrainedTokenizerBase, ProcessorMixin],\n",
        "    tools: Optional[list[Union[dict, Callable]]] = None,\n",
        "    **template_kwargs,\n",
        ") -> dict[str, str]:\n",
        "    r\"\"\"\n",
        "    Apply a chat template to a conversational example along with the schema for a list of functions in `tools`.\n",
        "\n",
        "    For more details, see [`maybe_apply_chat_template`].\n",
        "    \"\"\"\n",
        "    # Check that the example has the correct keys\n",
        "    supported_keys = [\"prompt\", \"chosen\", \"rejected\", \"completion\", \"messages\", \"label\"]\n",
        "    example_keys = {key for key in example.keys() if key in supported_keys}\n",
        "    if example_keys not in [\n",
        "        {\"messages\"},  # language modeling\n",
        "        {\"prompt\"},  # prompt-only\n",
        "        {\"prompt\", \"completion\"},  # prompt-completion\n",
        "        {\"prompt\", \"chosen\", \"rejected\"},  # preference\n",
        "        {\"chosen\", \"rejected\"},  # preference with implicit prompt\n",
        "        {\"prompt\", \"completion\", \"label\"},  # unpaired preference\n",
        "    ]:\n",
        "        raise KeyError(f\"Invalid keys in the example: {example_keys}\")\n",
        "\n",
        "    # Apply the chat template to the whole conversation\n",
        "    if \"messages\" in example:\n",
        "        messages = tokenizer.apply_chat_template(\n",
        "            example[\"messages\"],\n",
        "            tools=tools,\n",
        "            tokenize=False,\n",
        "            **example.get(\"chat_template_kwargs\", {}),\n",
        "            **template_kwargs,\n",
        "        )\n",
        "\n",
        "    # Apply the chat template to the prompt, adding the generation prompt\n",
        "    if \"prompt\" in example:\n",
        "        last_role = example[\"prompt\"][-1][\"role\"]\n",
        "        if last_role == \"user\":\n",
        "            add_generation_prompt = True\n",
        "            continue_final_message = False\n",
        "        elif last_role == \"assistant\":\n",
        "            add_generation_prompt = False\n",
        "            continue_final_message = True\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid role in the last message: {last_role}\")\n",
        "\n",
        "        clog(\"$$$$ start\")\n",
        "\n",
        "        prompt = tokenizer.apply_chat_template(\n",
        "            example[\"prompt\"],\n",
        "           # tokenize=False,\n",
        "            #add_generation_prompt=add_generation_prompt,\n",
        "           # **example.get(\"chat_template_kwargs\", {}),\n",
        "            #**template_kwargs,\n",
        "                       # tools=tools,\n",
        "           # continue_final_message=continue_final_message,\n",
        "        )\n",
        "        clog(\"$$$$ end\")\n",
        "    # Apply the chat template to the entire prompt + completion\n",
        "    if \"prompt\" in example:  # explicit prompt and prompt-completion case\n",
        "        if \"chosen\" in example:\n",
        "            prompt_chosen = tokenizer.apply_chat_template(\n",
        "                example[\"prompt\"] + example[\"chosen\"],\n",
        "                tools=tools,\n",
        "                tokenize=False,\n",
        "                **example.get(\"chat_template_kwargs\", {}),\n",
        "                **template_kwargs,\n",
        "            )\n",
        "            # DeepSeek-R1 inserts a <tool_call> token when using `add_generation_prompt`, which can cause discrepancies\n",
        "            # between the prompt alone and the combined prompt+completion. To ensure consistency, we extract the\n",
        "            # common prefix between the two. In most cases, this is a no-op.\n",
        "            prompt = \"\".join(x for x, _ in takewhile(lambda x: x[0] == x[1], zip(prompt, prompt_chosen)))\n",
        "\n",
        "            chosen = prompt_chosen[len(prompt) :]\n",
        "        if \"rejected\" in example and \"prompt\" in example:  # explicit prompt\n",
        "            prompt_rejected = tokenizer.apply_chat_template(\n",
        "                example[\"prompt\"] + example[\"rejected\"],\n",
        "                tools=tools,\n",
        "                tokenize=False,\n",
        "                **example.get(\"chat_template_kwargs\", {}),\n",
        "                **template_kwargs,\n",
        "            )\n",
        "            # Handle DeepSeek-R1 <tool_call> token, see the above comment for details\n",
        "            prompt = \"\".join(x for x, _ in takewhile(lambda x: x[0] == x[1], zip(prompt, prompt_rejected)))\n",
        "            rejected = prompt_rejected[len(prompt) :]\n",
        "        if \"completion\" in example:\n",
        "            prompt_completion = tokenizer.apply_chat_template(\n",
        "                example[\"prompt\"] + example[\"completion\"],\n",
        "                tools=tools,\n",
        "                tokenize=False,\n",
        "                **example.get(\"chat_template_kwargs\", {}),\n",
        "                **template_kwargs,\n",
        "            )\n",
        "            # Handle DeepSeek-R1 <tool_call> token, see the above comment for details\n",
        "            prompt = \"\".join(x for x, _ in takewhile(lambda x: x[0] == x[1], zip(prompt, prompt_completion)))\n",
        "            completion = prompt_completion[len(prompt) :]\n",
        "    else:  # implicit prompt case\n",
        "        if \"chosen\" in example:\n",
        "            chosen = tokenizer.apply_chat_template(\n",
        "                example[\"chosen\"],\n",
        "                tools=tools,\n",
        "                tokenize=False,\n",
        "                **example.get(\"chat_template_kwargs\", {}),\n",
        "                **template_kwargs,\n",
        "            )\n",
        "        if \"rejected\" in example:\n",
        "            rejected = tokenizer.apply_chat_template(\n",
        "                example[\"rejected\"],\n",
        "                tools=tools,\n",
        "                tokenize=False,\n",
        "                **example.get(\"chat_template_kwargs\", {}),\n",
        "                **template_kwargs,\n",
        "            )\n",
        "\n",
        "    # Extract the completion by removing the prompt part from the prompt-completion string\n",
        "    output = {}\n",
        "    if \"messages\" in example:\n",
        "        output[\"text\"] = messages\n",
        "    if \"prompt\" in example:\n",
        "        output[\"prompt\"] = prompt\n",
        "    if \"chosen\" in example:\n",
        "        output[\"chosen\"] = chosen\n",
        "    if \"rejected\" in example:\n",
        "        output[\"rejected\"] = rejected\n",
        "    if \"completion\" in example:\n",
        "        output[\"completion\"] = completion\n",
        "    if \"label\" in example:\n",
        "        output[\"label\"] = example[\"label\"]\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "WxrfedHe0sre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daudio_new_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv7ai7PBXfAJ",
        "outputId": "536edce7-79cf-4a22-baa3-7b8db95f413f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['answer', 'prompt'],\n",
              "    num_rows: 49\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = myGRPOTrainer(\n",
        "    model=model,\n",
        "    processing_class=processor,\n",
        "    reward_funcs=[check_answer],\n",
        "    args=training_args,\n",
        "    train_dataset=daudio_new_dataset,\n",
        "    peft_config=peft_config\n",
        ")"
      ],
      "metadata": {
        "id": "U4OHYTxw0yBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76916409-e370-4ed6-d150-3dd62351fff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-28 07:26:06 IST] ENTER GRPOTrainer.__init__, model=mistralai/Voxtral-Mini-3B-2507, args_provided=True\n",
            "[2025-10-28 07:26:06 IST] model_init_kwargs , {}\n",
            "[2025-10-28 07:26:06 IST] Using provided model instance, model_id=mistralai/Voxtral-Mini-3B-2507\n",
            "[2025-10-28 07:26:06 IST] Model forward kwargs inspected, supports_logits_to_keep=True\n",
            "[2025-10-28 07:26:06 IST] Preparing PEFT model\n",
            "[2025-10-28 07:26:06 IST] PEFT prepared\n",
            "[2025-10-28 07:26:06 IST] setting tokenizer = processing_class.tokenizer\n",
            "[2025-10-28 07:26:06 IST] Tokenizer configured, pad_token_id=11, eos_token_id=2\n",
            "[2025-10-28 07:26:06 IST] Reward funcs prepared, count=1, names=['check_answer']\n",
            "[2025-10-28 07:26:06 IST] args.reward_weights is None\n",
            "[2025-10-28 07:26:06 IST] Reward weights, tensor([1.])\n",
            "[2025-10-28 07:26:06 IST] reward_processing_classes is None \n",
            "[2025-10-28 07:26:06 IST] Reward processing classes prepared, [None]\n",
            "[2025-10-28 07:26:06 IST] Train args, max_prompt_length=1024, max_completion_length=1024, num_generations=8, use_vllm=False, vllm_mode=server, use_liger_loss=False, loss_type=dapo\n",
            "[2025-10-28 07:26:06 IST] self.shuffle_dataset , True\n",
            "[2025-10-28 07:26:06 IST] BaseTrainer initialized, per_device_train_batch_size=1\n",
            "[2025-10-28 07:26:06 IST] Ref model disabled (beta=0.0)\n",
            "[2025-10-28 07:26:06 IST] Seed set, seed=42\n",
            "[2025-10-28 07:26:06 IST] Transformers generation_kwargs, {'max_new_tokens': 1024, 'do_sample': True, 'pad_token_id': 11, 'bos_token_id': 1, 'eos_token_id': 2, 'temperature': 1.0, 'top_p': 1.0, 'top_k': None, 'min_p': None, 'repetition_penalty': 1.0, 'cache_implementation': None}\n",
            "[2025-10-28 07:26:06 IST] Model tags added, tags=[]\n",
            "[2025-10-28 07:26:06 IST] END GRPOTrainer.__init__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ArPraNPIQ5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce400608-6002-473a-f8f8-9a6a92cb30ab"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1, 'pad_token_id': 11}.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-10-28 07:26:12 IST] ENTER get_train_dataloader , No_1\n",
            "[2025-10-28 07:26:12 IST] defining train_dataset\n",
            "[2025-10-28 07:26:12 IST] train_dataset , Dataset({\n",
            "    features: ['answer', 'prompt'],\n",
            "    num_rows: 49\n",
            "})\n",
            "[2025-10-28 07:26:12 IST] train_dataset , Dataset({\n",
            "    features: ['answer', 'prompt'],\n",
            "    num_rows: 49\n",
            "})\n",
            "[2025-10-28 07:26:12 IST] self._train_batch_size * self.args.steps_per_generation , 8\n",
            "[2025-10-28 07:26:12 IST] Dataloader params , {'batch_size': 8, 'collate_fn': <function identity at 0x7daeac5996c0>, 'num_workers': 0, 'pin_memory': True, 'persistent_workers': False}\n",
            "[2025-10-28 07:26:12 IST] not isinstance(train_dataset, torch.utils.data.IterableDataset)\n",
            "[2025-10-28 07:26:12 IST] ENTER _get_train_sampler, dataset_provided=False\n",
            "[2025-10-28 07:26:12 IST] END _get_train_sampler, mini_repeat_count=8, batch_size=1, repeat_count=8, shuffle=True\n",
            "[2025-10-28 07:26:12 IST] Dataloader params , {'batch_size': 8, 'collate_fn': <function identity at 0x7daeac5996c0>, 'num_workers': 0, 'pin_memory': True, 'persistent_workers': False, 'sampler': <trl.trainer.utils.RepeatSampler object at 0x7dae4c53bb90>, 'drop_last': False, 'worker_init_fn': functools.partial(<function seed_worker at 0x7daebbb41ee0>, num_workers=0, rank=0), 'prefetch_factor': None}\n",
            "[2025-10-28 07:26:12 IST] dl is , <accelerate.data_loader.DataLoaderShard object at 0x7dae32a51280>\n",
            "[2025-10-28 07:26:12 IST] END get_train_dataloader\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamritansh-verma98\u001b[0m (\u001b[33mamritansh-verma98-personal\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251028_015614-iike9pnt</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/amritansh-verma98-personal/huggingface/runs/iike9pnt' target=\"_blank\">Voxtral-Mini-3B-2507</a></strong> to <a href='https://wandb.ai/amritansh-verma98-personal/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/amritansh-verma98-personal/huggingface' target=\"_blank\">https://wandb.ai/amritansh-verma98-personal/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/amritansh-verma98-personal/huggingface/runs/iike9pnt' target=\"_blank\">https://wandb.ai/amritansh-verma98-personal/huggingface/runs/iike9pnt</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [huggingface_hub.inference, mcp, openai] in use.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "          1338,  6958,  1395, 20726,  6904, 29255, 34345, 14146, 44763, 41530,\n",
            "          4266,  1317,  3180, 19599, 28507,  2259, 74045,  1561,  1060, 24613,\n",
            "          1062,  1048,  1046,  1055,  1053,  1885, 24613,  1062,  1975,     2,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.2612], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[1975,    2,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-2.3894], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}]\n",
            "[2025-10-28 07:26:57 IST] inputs are , {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 1060, 74045,  3318,  1784, 14146,  8164,  1455,  2127,  2933,  1317,\n",
            "          6904,  5305,  1317,  1420, 64226,  1321, 60270, 34932,  1435,  2034,\n",
            "         15231, 10284,  1046,  1531, 14146, 23880,  5178, 24244,  1408, 34932,\n",
            "          4275, 27533,  1626,  9076,  1593,  2481,  1402,  1261, 46952, 21823,\n",
            "          1394,  6187,  1261, 18034, 58792,  1044, 34932, 52875,  1710,  1402,\n",
            "          2434,  1435,  1261,  4938,  1536, 41530, 29694,  2274,  4069, 12772,\n",
            "          1307,  1278, 19102,  6904, 29708,  1338, 23811,  6904,  2481,  1402,\n",
            "          1805,  1307,  6983,  1317, 19588,  2034, 32113,  1294,  3542,  1317,\n",
            "         10035, 11093,  1046, 12431,  1044, 58792,  1261, 18034,  1394,  1278,\n",
            "          6960,  3823,  1307,  6904,  2168,  1605,  3180,  3315,  7453,  1693,\n",
            "          1278,  7293, 18034, 30191,  4362,  1584, 11118,  1338, 53093,  1044,\n",
            "         14146, 51622,  1394, 13828,  5702,  2158,  1408,  2034,  7357,  5449,\n",
            "          1317,  9086,  1278, 23582,  1046,  3886,  1044,  1294,  1593,  2937,\n",
            "          1044,  1278,  4597,  6904,  1395, 22528,  2453, 91989,  1420, 11914,\n",
            "          5702,  6123,  1044,  1799, 84083,  1278,  2965,  1394,  4607,  2058,\n",
            "          1325,  1046, 18011,  1044,  1278, 41530,  5032,  2095, 70440, 49241,\n",
            "          6904,  4546,  1394,  2903, 28253, 64226, 34932,  1338,  4380,  1395,\n",
            "          2095,  1307,  4878,  8482,  1536, 41530, 29694,  2478, 46952, 18267,\n",
            "         12663,  1321,  9517,  7091,  1317, 38320, 26907, 97016,  1101,  1626,\n",
            "          1885, 74045,  3318,  1060, 24613,  1062,  1048,  1046,  1055,  1053,\n",
            "          1885, 24613,  1062,     2,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.2612], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}\n",
            "[2025-10-28 07:26:57 IST] END _prepare_inputs, keys=['prompt_ids', 'prompt_mask', 'completion_ids', 'completion_mask', 'advantages', 'num_items_in_batch'], prompt_ids.shape=(1, 646), completion_ids.shape=(1, 485)\n",
            "[2025-10-28 07:26:57 IST] ENTER compute_loss, use_liger_loss=False\n",
            "[2025-10-28 07:26:57 IST] ENTER _compute_loss, prompt_ids.shape=(1, 646), completion_ids.shape=(1, 485), loss_type=dapo, beta=0.0, importance_sampling_level=token\n",
            "[2025-10-28 07:26:57 IST] ENTER _get_per_token_logps_and_entropies, input_ids.shape=(1, 1131), attention_mask.shape=(1, 1131), logits_to_keep=485, batch_size=None, compute_entropy=True\n",
            "[2025-10-28 07:26:57 IST] END _get_per_token_logps_and_entropies, logps.shape=(1, 485), entropies=(1, 485)\n",
            "[2025-10-28 07:26:57 IST] END _compute_loss, loss=-0.0292566679418087\n",
            "[2025-10-28 07:26:57 IST] END compute_loss (standard)\n",
            "[2025-10-28 07:26:58 IST] ENTER _prepare_inputs, training=True, _step=5, len_batch=n/a, si_2\n",
            "[2025-10-28 07:26:58 IST] mode is , train\n",
            "[2025-10-28 07:26:58 IST] generate_every 8 = self.args.steps_per_generation 8 * self.num_iterations 1\n",
            "[2025-10-28 07:26:58 IST] self._step is , 5\n",
            "[2025-10-28 07:26:58 IST] self._buffered_inputs , [{'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[  1060,  74045,   1062,   1785,   1278,   8516,   5055,   1044,   1278,\n",
            "           3330,   7444,   1317,   5100,   1261,   1461,   6278,   1519,  11551,\n",
            "           1046,   9380,   1395,   1278,  38528,   2100,   1049,   1046,   1531,\n",
            "           3330,   1395,   5700,   3923,   5124,   1317,   9662,   1557,   1261,\n",
            "           4036,   1455,   1681,   4963,   1454,   1420,  64226,   1626,   1050,\n",
            "           1046,   3730,   1395,   1836,   5647,   1307,   2258,  52819,   6727,\n",
            "          40294,   1317,   8132,   2203,   2778,  27528,  26684,   1626,   1051,\n",
            "           1046,  34932,   6904, 120368,  14047,   1278,  18817,  11157,   1317,\n",
            "           1420,  20726,   8516,  25077,   2158,  32418,  19803,   1302,   1261,\n",
            "         102835,  30481,   1454,  26873,  18034,  23582,   1626,   1052,   1046,\n",
            "          31205,   1672,   1536,  34081,   1073,   1263,   1321, 128977,   1394,\n",
            "           4514,  12181,   7219,  27528,   1408,   1278,   2147,   4014,   1010,\n",
            "           1053,   1046,  45074,  11549,   1501,  11093,   5033,   1032,  24300,\n",
            "           1294,   5150,  24468,   5510,  18964,  12319,  66505,   3421,   1599,\n",
            "           7655, 118672,   1536,  27976,  44761,  67650,   2779,  10636,   1338,\n",
            "           2596,  20465,   1261,  13864,  32595,   2862,   1044,   1494,  49498,\n",
            "          19685,   1408,   1278,   4319,   6153,   3435,  12276,  49230,   2203,\n",
            "          80046,  13991,   1294,  18847,   1505,  15831,   1279, 130816,   1046,\n",
            "         114210,   1638,   1058,  44250,   7591,  10045,   2405,   1261,  15851,\n",
            "           6706,   1307,  10636,   1294,   2643, 116050,   1532,   2259,  74045,\n",
            "           3318,   1060,  24613,   1062,   1048,   1046,   1050,   1053,   1885,\n",
            "          24613,   1062,      2,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5730], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,  11745,   1584,   1278,   2830,   5305,   1455,\n",
            "           1362,   1855,   4670,   1317,   1974,   2136,   2100,   1049,   1046,\n",
            "           1603,  25413,  18244,   5450,   1531,  14146,   1395,  64897,   7791,\n",
            "           2314,  63536,   1349,   1804,   1120,   5305,   1338,   1050,   1046,\n",
            "           1603,  86626,   1307,  11549,   1501,   5450,   1656,   1278,   3145,\n",
            "           2142,  18106,   1044,   2127,  14404,   1455,   1317,   6904,   5305,\n",
            "           2127,   2534,   1317,   2210,   2034,   2118,   1321,   8160,   1261,\n",
            "          17898,  17959,  25354,   1046,   3060,  10597,  12319,   1536,  23288,\n",
            "           2034,  38576,   1317,   1278,   1349,   1804,   1120,   2118,   1681,\n",
            "          21666,  62183,   1338,   1293,  17475,  10078,  58843,  25787,   8867,\n",
            "         115321,   1058,   1032,   1010,   1293,   1462,  12953,   1710,   4237,\n",
            "           2314,   1278,  10469,   1307,  63536,   5305,   1505,   1402,   8462,\n",
            "           3964,   1317,   4503,   3880,   1267,   1260,   1462,   1531,   2108,\n",
            "           1307,   1429,   1393,   2066,   1302,   1034,  21905, 106714,   7807,\n",
            "           2314,   1278,   5355,   1307,  63536,   1338,   1369,  27923,   7560,\n",
            "           7042,   7807,   1317,   7442,   4069,   2258,   4514,   5966,   1338,\n",
            "           1051,   1046,   1603,  34932,  44250,  87562,   5450,   1531,  14146,\n",
            "           2095,   6136,   2314,  34932,   1681,  19102,  99646,  15021,   5178,\n",
            "           1317,   2424,   1046,   5930,   3686,   1799,   1395,   9210,  77846,\n",
            "           1297,   1505,  77846,   3929,  47210,   2314,   1261,  24149,   4920,\n",
            "           1294,   1278,   8673,   1420,  11083,  17959,   6904,   1562,   1349,\n",
            "           1804,   1120,   1338,   1052,   1046,   1603,  69567,   1307,  18244,\n",
            "          27505,   5450,   1531,   4546,   8688,   5662,  24130,   3629,   3686,\n",
            "           1877,   1293,   1462,  34932,  87562,   1010,   1293,   1462,   8936,\n",
            "          26649,   1058,   8956,   1278,   4275,   3950,   1520,   1293,  14226,\n",
            "           1278,  39373,   2663,   1307,  14381,   1058,   1032,   1051,   1048,\n",
            "           1037,  52211,   1941,   2590,   8123,   1302,  70401,   8911,   1010,\n",
            "           1293,   2157,   1710,   4362,  12957,   1435,   2903,   1435,   8137,\n",
            "          13782,   1338,  25280, 127464,   1278,   8516,   1294,   9576,   2100,\n",
            "           1293,   1656,  11774,   1307,   5443,   1044,   3145,  17365,   1584,\n",
            "          43440,   1536,   2365,   1403,   1403,  38050,   2314,   1278,  10601,\n",
            "           1321,   8617,   7560,   1261,  38576,  12522, 106101,   1505,   4514,\n",
            "          33289,   3823,   5316,   3879,  10431,   1261,   1875,  58792,   1505,\n",
            "           2258,   2832,   1338,  74677,   1501,   5032,   2534,  18819,   1307,\n",
            "           3403,   1505,   3167,   2782,   1294,   2065,   1321,   1454,   2365,\n",
            "           1403,   1403,  38050,   1338,   4380,  17718,   4133,   5355,   1317,\n",
            "           1261,   5270,  50481,   4206,   1321,  10341,   1402,  10372,   5270,\n",
            "           1338,   5475,   1362,   3204,   1494,   2203,   1261,  14381,   1307,\n",
            "          41530,   1044,   1494,   1395, 125427,   4953,   2224,   1032,   1053,\n",
            "           1048,   1037,   1809,   4853,   3964,   1317,   8744,   4005,   1044,\n",
            "          10005,   6167,  34941,   1307, 113640,   2136,   8686,   1321,   1294,\n",
            "          13793,   2314,   1278,   2658,   1307,  10601,   8807,   1626,   1784,\n",
            "          33226,   2632,   1307,   1877,   1060,  24613,   1062,   1048,   1046,\n",
            "           1053,   1885,  24613,   1062,      2,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-0.2066], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,  12598,   1681,  26812,   1278,   5662,  18106,\n",
            "           1877,   1049,   1046,   1603,  25413,  51595,   3795,   1531,  14146,\n",
            "          14725,   8942,  96930,   1505,   1429,   1071,   5988,   1951,   1034,\n",
            "           1319,  93066,   2283,   1261,   5289,  46425,  10788,   9648,   6904,\n",
            "           4342,   1050,   1046,   1603,  12508, 114040,   3795,   4159,   2607,\n",
            "           2405,   7693,   2034,   3145,  11328,  58792,   9576,   1044,  35499,\n",
            "           1302,   2034,   5972,   1394,   6904,   1626,   1051,   1046,   1603,\n",
            "           3877, 112194,   1505,  90771,   1279,   2034,   3145,  10601,   4777,\n",
            "           3795,   1531,   2937,   6122,   1044,   2156,   1395,   1836,  17686,\n",
            "           2127,   2840,  58238,  16278,   1044,   7293,   4777,   1394,  18034,\n",
            "          88099,   1319,   1115,  52512,   1302,  87409,   9576,   4342,   1052,\n",
            "           1046,   1603,   1068,  40501,  88872,   3795,   3730,   1584,  28507,\n",
            "           3844,   1058, 112641,   1408,  34932,   1044, 129184,   1294,  33391,\n",
            "          58376,   1513,   1349,   1804,   1120,   1524,  95366,   2118,  14096,\n",
            "           8223,   1836,  10098, 117424,   1046,   3730,   1395,   5711,   3101,\n",
            "           3643,   9576,   1046,   2259,  74045,   3318,   1060,  24613,   1062,\n",
            "           1048,   1046,   1050,   1053,   1885,  24613,   1062,      2,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5730], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 12598,   1681,  20189,   1278,  18106,   2396,   6585,   1321,   1278,\n",
            "          14146,   2100,   1045,   1603,  29212,  24468,  32868,   1058, 106604,\n",
            "           1438,   1395, 117100,   1317,   6904,   1853,   5305,   1626,   1045,\n",
            "           1603,  51414,   1058,  16566,   2391,   1394,  52546,  12460,  82119,\n",
            "           2591,   1045,   4973,  25079,   2782,   1321,  33673,   1934,   2151,\n",
            "          35801,   1809,   9576,   2479,  85410,   1044,  10126,  28263,   1321,\n",
            "          19024,   1065,   2019,  11117,   1722,  76382,   1338,   4072,   1603,\n",
            "          74677,   1501,  35821,  80143, 120430,  84596,  79103,   1115,   1317,\n",
            "          24185,   1009,   1043,  11549,   1501,  29694,   4139,   6983,  27421,\n",
            "          81743,   1505,  29542,  52257,   1338,   5286,   6186,   1319,  13148,\n",
            "           3205,  25079,   2782,   1321, 119287,  20490,   4127,   2479,  19427,\n",
            "           6218,   9576,   9576,   1456,  11745,   1395,   1261,   4171,   5972,\n",
            "           1394,  55054,   1302,   2576,   9576,   3147,   2127,   1722,  31073,\n",
            "           1261,   4510,   5510,   8265,   1046,  10638,   2801,   5705,   4139,\n",
            "           7529,   2925,   1799,   7560,   1317,   6130,  41562,   1877,   1049,\n",
            "           1046,   1603, 117540,   1294,  19364,  31936,   1438,   2274,   4139,\n",
            "           1402,  18747,   6370,   1317,   6904,   3778,   1661,   1307,   1261,\n",
            "           6410,   1294,   6856,   1307,   2142,   1321,  15021,   1319,  31346,\n",
            "          17959,   6309,   4265,   1875,  98283,   1574,   1294,   1799,   2937,\n",
            "           1494,   4139,   1402,   1261,   8516,   1799,   1395,  49063,   1294,\n",
            "           1799,   2937,   6705,  15021,   4139,   1402,   7960,   1513,   5785,\n",
            "           1462,   1799,  24277,  76137,  15021,   1321,  32795,   5178,   1408,\n",
            "         107494,   5305,   6904,   1562,   5150,  24468,   1626,   1050,   1046,\n",
            "           1603,  70158,   6309,  29949,   1452,  17939,  20974,   1438,  11696,\n",
            "           1799,   1710,   3820,   1394,  36840,   9576,  69785,   4242,   2487,\n",
            "          14715,   1321,   7195,   1317,  21294,   3184,   5510,   1505,  13411,\n",
            "          13955,   1317,  10616,  17183,  47525,   1741,  80691,  29447,   1875,\n",
            "          41530,  29694,   1435,   9700,  32113,   3820,   2203,   2034,   4510,\n",
            "           3992,  45698,   1044,   1809,   4382,  18749,   1319,  92860,   5449,\n",
            "           8091,   1710,  18052,  27825,  28284,   2519,  21464,   4501,   3214,\n",
            "           1435,   5956,   2862,   3314,   5353,   1408,   6705,  15021,   6793,\n",
            "          10477,  73424,   2632,  64983,   1584,   3214,   8617,   1317,  10477,\n",
            "          47036,  58376,   1046,   3964,   1317,   2534,   1394,   7481,   4798,\n",
            "          41562,   1536,  12388,   1307,  15699,   1045,   7299,   5481,   3897,\n",
            "          16574,  15839,  41530,  19004,   1626,  74677,   1501,   5032,   7529,\n",
            "          14025,   1317,   3780,   2576,   2081,  92810,   1044,   1809,  13173,\n",
            "           3148,   1294,  97713,   1395,  28088,   1944,   4171,   1032,   1057,\n",
            "           1053,   1037,  14381,   1046,  56009,   1261,  16094,  26792,  23099,\n",
            "          11551,   1454,   1261,  10616,   6373,   1338,   1785,   1278,   2937,\n",
            "           2478,   1278,   9576,   4139,   1402,  14078,   1317,  10616,  12220,\n",
            "          41530,  20100,   1044,  27923,  10749,  26158,  12270,   1063,   2157,\n",
            "          13536,   1317,  13218,   9576,   2081,  14420,   4688,  26300,   1044,\n",
            "           2878,   1681,  28714,   1454,   1278,   3148,   1044,  39374,  41530,\n",
            "           5965,   1044,   1261,  22868,   1044,   1261,  41530,   9519,   1046,\n",
            "           7295,  49250,   2077,   1062,  25413,  16264,  13709,   1435,   6170,\n",
            "           2520,   2534,   2478,   1059, 118808,  45281,   1450, 109228,   1619,\n",
            "          41562,  27094,   1044,  52990,   9576,   2229,  68082,  66432,  58376,\n",
            "          40052,  41530,  27825,  33630,   1261,  41530,  42302,   1302,   5702,\n",
            "           1046,   1531,  17631,  48830,  38407,  23303,   1086,  11364,   5553,\n",
            "           1307,  32269,   1302,   1261,  16094,  60069,   1321,   3687,   3644,\n",
            "           1317,   3844,  41530,   1429,  27970,   1034,   6906,   1317,   7277,\n",
            "           2269,   5186,   1307,   5965,  37487,   1435,   4171,   1032,   1054,\n",
            "           1048,   1037,  78260,  14381,  15342,  74045,   1561,   1060,  24613,\n",
            "           1062,   1048,   1046,   1054,   1885,  24613,   1062,      2]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1]], device='cuda:0'), 'advantages': tensor([0.3547], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 1060, 74045,  3318,  1784, 14146,  8164,  1455,  2127,  2933,  1317,\n",
            "          6904,  5305,  1317,  1420, 64226,  1321, 60270, 34932,  1435,  2034,\n",
            "         15231, 10284,  1046,  1531, 14146, 23880,  5178, 24244,  1408, 34932,\n",
            "          4275, 27533,  1626,  9076,  1593,  2481,  1402,  1261, 46952, 21823,\n",
            "          1394,  6187,  1261, 18034, 58792,  1044, 34932, 52875,  1710,  1402,\n",
            "          2434,  1435,  1261,  4938,  1536, 41530, 29694,  2274,  4069, 12772,\n",
            "          1307,  1278, 19102,  6904, 29708,  1338, 23811,  6904,  2481,  1402,\n",
            "          1805,  1307,  6983,  1317, 19588,  2034, 32113,  1294,  3542,  1317,\n",
            "         10035, 11093,  1046, 12431,  1044, 58792,  1261, 18034,  1394,  1278,\n",
            "          6960,  3823,  1307,  6904,  2168,  1605,  3180,  3315,  7453,  1693,\n",
            "          1278,  7293, 18034, 30191,  4362,  1584, 11118,  1338, 53093,  1044,\n",
            "         14146, 51622,  1394, 13828,  5702,  2158,  1408,  2034,  7357,  5449,\n",
            "          1317,  9086,  1278, 23582,  1046,  3886,  1044,  1294,  1593,  2937,\n",
            "          1044,  1278,  4597,  6904,  1395, 22528,  2453, 91989,  1420, 11914,\n",
            "          5702,  6123,  1044,  1799, 84083,  1278,  2965,  1394,  4607,  2058,\n",
            "          1325,  1046, 18011,  1044,  1278, 41530,  5032,  2095, 70440, 49241,\n",
            "          6904,  4546,  1394,  2903, 28253, 64226, 34932,  1338,  4380,  1395,\n",
            "          2095,  1307,  4878,  8482,  1536, 41530, 29694,  2478, 46952, 18267,\n",
            "         12663,  1321,  9517,  7091,  1317, 38320, 26907, 97016,  1101,  1626,\n",
            "          1885, 74045,  3318,  1060, 24613,  1062,  1048,  1046,  1055,  1053,\n",
            "          1885, 24613,  1062,     2,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.2612], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 69957,   1044,   3226,   1681,   2036,  38528,   2832,   1394,   1593,\n",
            "          16023,  18106,   2100,  49250,   2077,   3318,   4268,   2534,   1317,\n",
            "           6391,   5627, 106604,   1319,   1288,   1651,   1278,  14146,   3831,\n",
            "          12334,   6585,   1321, 106604,  14282,  10910,   1041,   1395,   1261,\n",
            "          44761,  14146,   1505,   7442,   1261,  41530,   5032,   1338,  10107,\n",
            "           1405,   1044,   4057,   1408,   1278,  16023,  18106,   1877,   1049,\n",
            "           1046,   4159,   2210,   1278,  18348,   2832,   1307,  54348,   2283,\n",
            "           1278,  14146,  44214,   7504,  12598,   1639,  21294,   3804,   3946,\n",
            "          35515,   1044,  81743,   1044,  29542,   1044,   1321,   8686,  11499,\n",
            "           1799,   1395,   1420,  10923,   8482,   1626,   1050,   1046, 106604,\n",
            "           1044,   1294,   4005,   1317,   2576,  18119,  41562,   9578,   1044,\n",
            "           8942,   1853,   8686,   5751,   1435,  12581,   1294,  22506,   3581,\n",
            "           1049,   1056,   1054,   1055,   1064,  22498,   4795,   2354,   1626,\n",
            "           4072,   6585,  19877,   1317,   1278,   6255,  41562,   8686,   5751,\n",
            "          10249,  15421,   9985,   1278,  17718,   1317,   1402,  11110,  94903,\n",
            "           1060,   1044,   1278,  18106,  19877,   1317,   1402,   4352,   1321,\n",
            "          15421,  11688,   1584,   4265,   3816,   4514,  41530,  16591,   1046,\n",
            "           4634,   1653,   1605,   6274,   1317,  23808,   1435,   5965,   1307,\n",
            "          41530,  35821,   2019,  11117,   1267,   8032,   1044,   2878,   2190,\n",
            "           4832,   1536,  11735,   1261,  14381,   2100,   1032,   1032,   1049,\n",
            "           1046,  32955,  41562,   1058,  30460,   1286,  21043,  46004,  62693,\n",
            "           3804,   3946,  48044,   2383,   1398,   9184,  84498,   1321,  33673,\n",
            "           1414,   2519,   1885,  74045,   1561,   1060,  24613,   1062,   1048,\n",
            "           1046,   1050,   1053,   1885,  24613,   1062,      2,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5730], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 1975,  1060, 74045,  1062, 35957,  1408,  1278,  5315,  5662,  1044,\n",
            "          2878,  1681,  5972,  1877,  6958,  1395,  1261,  1032,  1049,  1053,\n",
            "          7133,  6904, 29255,  1044, 14655,  1261, 22870,  1046, 11549,  1501,\n",
            "         29694,  5153, 44765, 99033,  1321,  8031, 11328, 14980,  1394,  7357,\n",
            "         12542,  1044,  1799,  4139, 24441,  6245, 24244, 56355,  1505, 58792,\n",
            "         24244,  2903,  2453,  2034, 18102, 10601,  1046,  9380,  1044,  1278,\n",
            "         14146,  8164,  2127,  7455,  1261,  4811,  5451,  1044, 10138,  5289,\n",
            "         58792,  2903, 17277,  1307,  6186, 29751,  1046,  1032,  4159,  8164,\n",
            "          4433, 30102,  1506, 49208, 60571,  1317,  4978,  9012,  1394,  1457,\n",
            "         63947,  1046, 43888,  4510,  1349,  5180,  1088,  2188,  1736, 14246,\n",
            "          1562, 56220,  1302,  2396,  1278,  2147,  6580, 15249, 33075,  1307,\n",
            "          2142,  1317,  2210, 14146, 52449,  5305,  1046,  2409,  2142,  7404,\n",
            "         35714,  4139, 36840,  1394, 14146,  8198,  2424,  5275, 12772,  1338,\n",
            "          6958,  1395,  1420, 20726, 32795,  1513,  1032,  1049,  1053,  1037,\n",
            "          1394, 52875,  1317, 34932,  1799, 25640, 16581,  1294,  1593,  5526,\n",
            "          1338,  6958,  1395, 20726,  6904, 29255, 34345, 14146, 44763, 41530,\n",
            "          4266,  1317,  3180, 19599, 28507,  2259, 74045,  1561,  1060, 24613,\n",
            "          1062,  1048,  1046,  1055,  1053,  1885, 24613,  1062,  1975,     2,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.2612], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[1975,    2,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-2.3894], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}]\n",
            "[2025-10-28 07:26:58 IST] inputs are , {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 69957,   1044,   3226,   1681,   2036,  38528,   2832,   1394,   1593,\n",
            "          16023,  18106,   2100,  49250,   2077,   3318,   4268,   2534,   1317,\n",
            "           6391,   5627, 106604,   1319,   1288,   1651,   1278,  14146,   3831,\n",
            "          12334,   6585,   1321, 106604,  14282,  10910,   1041,   1395,   1261,\n",
            "          44761,  14146,   1505,   7442,   1261,  41530,   5032,   1338,  10107,\n",
            "           1405,   1044,   4057,   1408,   1278,  16023,  18106,   1877,   1049,\n",
            "           1046,   4159,   2210,   1278,  18348,   2832,   1307,  54348,   2283,\n",
            "           1278,  14146,  44214,   7504,  12598,   1639,  21294,   3804,   3946,\n",
            "          35515,   1044,  81743,   1044,  29542,   1044,   1321,   8686,  11499,\n",
            "           1799,   1395,   1420,  10923,   8482,   1626,   1050,   1046, 106604,\n",
            "           1044,   1294,   4005,   1317,   2576,  18119,  41562,   9578,   1044,\n",
            "           8942,   1853,   8686,   5751,   1435,  12581,   1294,  22506,   3581,\n",
            "           1049,   1056,   1054,   1055,   1064,  22498,   4795,   2354,   1626,\n",
            "           4072,   6585,  19877,   1317,   1278,   6255,  41562,   8686,   5751,\n",
            "          10249,  15421,   9985,   1278,  17718,   1317,   1402,  11110,  94903,\n",
            "           1060,   1044,   1278,  18106,  19877,   1317,   1402,   4352,   1321,\n",
            "          15421,  11688,   1584,   4265,   3816,   4514,  41530,  16591,   1046,\n",
            "           4634,   1653,   1605,   6274,   1317,  23808,   1435,   5965,   1307,\n",
            "          41530,  35821,   2019,  11117,   1267,   8032,   1044,   2878,   2190,\n",
            "           4832,   1536,  11735,   1261,  14381,   2100,   1032,   1032,   1049,\n",
            "           1046,  32955,  41562,   1058,  30460,   1286,  21043,  46004,  62693,\n",
            "           3804,   3946,  48044,   2383,   1398,   9184,  84498,   1321,  33673,\n",
            "           1414,   2519,   1885,  74045,   1561,   1060,  24613,   1062,   1048,\n",
            "           1046,   1050,   1053,   1885,  24613,   1062,      2,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5730], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}\n",
            "[2025-10-28 07:26:58 IST] END _prepare_inputs, keys=['prompt_ids', 'prompt_mask', 'completion_ids', 'completion_mask', 'advantages', 'num_items_in_batch'], prompt_ids.shape=(1, 646), completion_ids.shape=(1, 485)\n",
            "[2025-10-28 07:26:58 IST] ENTER compute_loss, use_liger_loss=False\n",
            "[2025-10-28 07:26:58 IST] ENTER _compute_loss, prompt_ids.shape=(1, 646), completion_ids.shape=(1, 485), loss_type=dapo, beta=0.0, importance_sampling_level=token\n",
            "[2025-10-28 07:26:58 IST] ENTER _get_per_token_logps_and_entropies, input_ids.shape=(1, 1131), attention_mask.shape=(1, 1131), logits_to_keep=485, batch_size=None, compute_entropy=True\n",
            "[2025-10-28 07:26:58 IST] END _get_per_token_logps_and_entropies, logps.shape=(1, 485), entropies=(1, 485)\n",
            "[2025-10-28 07:26:58 IST] END _compute_loss, loss=-0.06733657419681549\n",
            "[2025-10-28 07:26:58 IST] END compute_loss (standard)\n",
            "[2025-10-28 07:26:59 IST] ENTER _prepare_inputs, training=True, _step=6, len_batch=n/a, si_2\n",
            "[2025-10-28 07:26:59 IST] mode is , train\n",
            "[2025-10-28 07:26:59 IST] generate_every 8 = self.args.steps_per_generation 8 * self.num_iterations 1\n",
            "[2025-10-28 07:26:59 IST] self._step is , 6\n",
            "[2025-10-28 07:26:59 IST] self._buffered_inputs , [{'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[  1060,  74045,   1062,   1785,   1278,   8516,   5055,   1044,   1278,\n",
            "           3330,   7444,   1317,   5100,   1261,   1461,   6278,   1519,  11551,\n",
            "           1046,   9380,   1395,   1278,  38528,   2100,   1049,   1046,   1531,\n",
            "           3330,   1395,   5700,   3923,   5124,   1317,   9662,   1557,   1261,\n",
            "           4036,   1455,   1681,   4963,   1454,   1420,  64226,   1626,   1050,\n",
            "           1046,   3730,   1395,   1836,   5647,   1307,   2258,  52819,   6727,\n",
            "          40294,   1317,   8132,   2203,   2778,  27528,  26684,   1626,   1051,\n",
            "           1046,  34932,   6904, 120368,  14047,   1278,  18817,  11157,   1317,\n",
            "           1420,  20726,   8516,  25077,   2158,  32418,  19803,   1302,   1261,\n",
            "         102835,  30481,   1454,  26873,  18034,  23582,   1626,   1052,   1046,\n",
            "          31205,   1672,   1536,  34081,   1073,   1263,   1321, 128977,   1394,\n",
            "           4514,  12181,   7219,  27528,   1408,   1278,   2147,   4014,   1010,\n",
            "           1053,   1046,  45074,  11549,   1501,  11093,   5033,   1032,  24300,\n",
            "           1294,   5150,  24468,   5510,  18964,  12319,  66505,   3421,   1599,\n",
            "           7655, 118672,   1536,  27976,  44761,  67650,   2779,  10636,   1338,\n",
            "           2596,  20465,   1261,  13864,  32595,   2862,   1044,   1494,  49498,\n",
            "          19685,   1408,   1278,   4319,   6153,   3435,  12276,  49230,   2203,\n",
            "          80046,  13991,   1294,  18847,   1505,  15831,   1279, 130816,   1046,\n",
            "         114210,   1638,   1058,  44250,   7591,  10045,   2405,   1261,  15851,\n",
            "           6706,   1307,  10636,   1294,   2643, 116050,   1532,   2259,  74045,\n",
            "           3318,   1060,  24613,   1062,   1048,   1046,   1050,   1053,   1885,\n",
            "          24613,   1062,      2,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5730], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,  11745,   1584,   1278,   2830,   5305,   1455,\n",
            "           1362,   1855,   4670,   1317,   1974,   2136,   2100,   1049,   1046,\n",
            "           1603,  25413,  18244,   5450,   1531,  14146,   1395,  64897,   7791,\n",
            "           2314,  63536,   1349,   1804,   1120,   5305,   1338,   1050,   1046,\n",
            "           1603,  86626,   1307,  11549,   1501,   5450,   1656,   1278,   3145,\n",
            "           2142,  18106,   1044,   2127,  14404,   1455,   1317,   6904,   5305,\n",
            "           2127,   2534,   1317,   2210,   2034,   2118,   1321,   8160,   1261,\n",
            "          17898,  17959,  25354,   1046,   3060,  10597,  12319,   1536,  23288,\n",
            "           2034,  38576,   1317,   1278,   1349,   1804,   1120,   2118,   1681,\n",
            "          21666,  62183,   1338,   1293,  17475,  10078,  58843,  25787,   8867,\n",
            "         115321,   1058,   1032,   1010,   1293,   1462,  12953,   1710,   4237,\n",
            "           2314,   1278,  10469,   1307,  63536,   5305,   1505,   1402,   8462,\n",
            "           3964,   1317,   4503,   3880,   1267,   1260,   1462,   1531,   2108,\n",
            "           1307,   1429,   1393,   2066,   1302,   1034,  21905, 106714,   7807,\n",
            "           2314,   1278,   5355,   1307,  63536,   1338,   1369,  27923,   7560,\n",
            "           7042,   7807,   1317,   7442,   4069,   2258,   4514,   5966,   1338,\n",
            "           1051,   1046,   1603,  34932,  44250,  87562,   5450,   1531,  14146,\n",
            "           2095,   6136,   2314,  34932,   1681,  19102,  99646,  15021,   5178,\n",
            "           1317,   2424,   1046,   5930,   3686,   1799,   1395,   9210,  77846,\n",
            "           1297,   1505,  77846,   3929,  47210,   2314,   1261,  24149,   4920,\n",
            "           1294,   1278,   8673,   1420,  11083,  17959,   6904,   1562,   1349,\n",
            "           1804,   1120,   1338,   1052,   1046,   1603,  69567,   1307,  18244,\n",
            "          27505,   5450,   1531,   4546,   8688,   5662,  24130,   3629,   3686,\n",
            "           1877,   1293,   1462,  34932,  87562,   1010,   1293,   1462,   8936,\n",
            "          26649,   1058,   8956,   1278,   4275,   3950,   1520,   1293,  14226,\n",
            "           1278,  39373,   2663,   1307,  14381,   1058,   1032,   1051,   1048,\n",
            "           1037,  52211,   1941,   2590,   8123,   1302,  70401,   8911,   1010,\n",
            "           1293,   2157,   1710,   4362,  12957,   1435,   2903,   1435,   8137,\n",
            "          13782,   1338,  25280, 127464,   1278,   8516,   1294,   9576,   2100,\n",
            "           1293,   1656,  11774,   1307,   5443,   1044,   3145,  17365,   1584,\n",
            "          43440,   1536,   2365,   1403,   1403,  38050,   2314,   1278,  10601,\n",
            "           1321,   8617,   7560,   1261,  38576,  12522, 106101,   1505,   4514,\n",
            "          33289,   3823,   5316,   3879,  10431,   1261,   1875,  58792,   1505,\n",
            "           2258,   2832,   1338,  74677,   1501,   5032,   2534,  18819,   1307,\n",
            "           3403,   1505,   3167,   2782,   1294,   2065,   1321,   1454,   2365,\n",
            "           1403,   1403,  38050,   1338,   4380,  17718,   4133,   5355,   1317,\n",
            "           1261,   5270,  50481,   4206,   1321,  10341,   1402,  10372,   5270,\n",
            "           1338,   5475,   1362,   3204,   1494,   2203,   1261,  14381,   1307,\n",
            "          41530,   1044,   1494,   1395, 125427,   4953,   2224,   1032,   1053,\n",
            "           1048,   1037,   1809,   4853,   3964,   1317,   8744,   4005,   1044,\n",
            "          10005,   6167,  34941,   1307, 113640,   2136,   8686,   1321,   1294,\n",
            "          13793,   2314,   1278,   2658,   1307,  10601,   8807,   1626,   1784,\n",
            "          33226,   2632,   1307,   1877,   1060,  24613,   1062,   1048,   1046,\n",
            "           1053,   1885,  24613,   1062,      2,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-0.2066], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,  12598,   1681,  26812,   1278,   5662,  18106,\n",
            "           1877,   1049,   1046,   1603,  25413,  51595,   3795,   1531,  14146,\n",
            "          14725,   8942,  96930,   1505,   1429,   1071,   5988,   1951,   1034,\n",
            "           1319,  93066,   2283,   1261,   5289,  46425,  10788,   9648,   6904,\n",
            "           4342,   1050,   1046,   1603,  12508, 114040,   3795,   4159,   2607,\n",
            "           2405,   7693,   2034,   3145,  11328,  58792,   9576,   1044,  35499,\n",
            "           1302,   2034,   5972,   1394,   6904,   1626,   1051,   1046,   1603,\n",
            "           3877, 112194,   1505,  90771,   1279,   2034,   3145,  10601,   4777,\n",
            "           3795,   1531,   2937,   6122,   1044,   2156,   1395,   1836,  17686,\n",
            "           2127,   2840,  58238,  16278,   1044,   7293,   4777,   1394,  18034,\n",
            "          88099,   1319,   1115,  52512,   1302,  87409,   9576,   4342,   1052,\n",
            "           1046,   1603,   1068,  40501,  88872,   3795,   3730,   1584,  28507,\n",
            "           3844,   1058, 112641,   1408,  34932,   1044, 129184,   1294,  33391,\n",
            "          58376,   1513,   1349,   1804,   1120,   1524,  95366,   2118,  14096,\n",
            "           8223,   1836,  10098, 117424,   1046,   3730,   1395,   5711,   3101,\n",
            "           3643,   9576,   1046,   2259,  74045,   3318,   1060,  24613,   1062,\n",
            "           1048,   1046,   1050,   1053,   1885,  24613,   1062,      2,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5730], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 12598,   1681,  20189,   1278,  18106,   2396,   6585,   1321,   1278,\n",
            "          14146,   2100,   1045,   1603,  29212,  24468,  32868,   1058, 106604,\n",
            "           1438,   1395, 117100,   1317,   6904,   1853,   5305,   1626,   1045,\n",
            "           1603,  51414,   1058,  16566,   2391,   1394,  52546,  12460,  82119,\n",
            "           2591,   1045,   4973,  25079,   2782,   1321,  33673,   1934,   2151,\n",
            "          35801,   1809,   9576,   2479,  85410,   1044,  10126,  28263,   1321,\n",
            "          19024,   1065,   2019,  11117,   1722,  76382,   1338,   4072,   1603,\n",
            "          74677,   1501,  35821,  80143, 120430,  84596,  79103,   1115,   1317,\n",
            "          24185,   1009,   1043,  11549,   1501,  29694,   4139,   6983,  27421,\n",
            "          81743,   1505,  29542,  52257,   1338,   5286,   6186,   1319,  13148,\n",
            "           3205,  25079,   2782,   1321, 119287,  20490,   4127,   2479,  19427,\n",
            "           6218,   9576,   9576,   1456,  11745,   1395,   1261,   4171,   5972,\n",
            "           1394,  55054,   1302,   2576,   9576,   3147,   2127,   1722,  31073,\n",
            "           1261,   4510,   5510,   8265,   1046,  10638,   2801,   5705,   4139,\n",
            "           7529,   2925,   1799,   7560,   1317,   6130,  41562,   1877,   1049,\n",
            "           1046,   1603, 117540,   1294,  19364,  31936,   1438,   2274,   4139,\n",
            "           1402,  18747,   6370,   1317,   6904,   3778,   1661,   1307,   1261,\n",
            "           6410,   1294,   6856,   1307,   2142,   1321,  15021,   1319,  31346,\n",
            "          17959,   6309,   4265,   1875,  98283,   1574,   1294,   1799,   2937,\n",
            "           1494,   4139,   1402,   1261,   8516,   1799,   1395,  49063,   1294,\n",
            "           1799,   2937,   6705,  15021,   4139,   1402,   7960,   1513,   5785,\n",
            "           1462,   1799,  24277,  76137,  15021,   1321,  32795,   5178,   1408,\n",
            "         107494,   5305,   6904,   1562,   5150,  24468,   1626,   1050,   1046,\n",
            "           1603,  70158,   6309,  29949,   1452,  17939,  20974,   1438,  11696,\n",
            "           1799,   1710,   3820,   1394,  36840,   9576,  69785,   4242,   2487,\n",
            "          14715,   1321,   7195,   1317,  21294,   3184,   5510,   1505,  13411,\n",
            "          13955,   1317,  10616,  17183,  47525,   1741,  80691,  29447,   1875,\n",
            "          41530,  29694,   1435,   9700,  32113,   3820,   2203,   2034,   4510,\n",
            "           3992,  45698,   1044,   1809,   4382,  18749,   1319,  92860,   5449,\n",
            "           8091,   1710,  18052,  27825,  28284,   2519,  21464,   4501,   3214,\n",
            "           1435,   5956,   2862,   3314,   5353,   1408,   6705,  15021,   6793,\n",
            "          10477,  73424,   2632,  64983,   1584,   3214,   8617,   1317,  10477,\n",
            "          47036,  58376,   1046,   3964,   1317,   2534,   1394,   7481,   4798,\n",
            "          41562,   1536,  12388,   1307,  15699,   1045,   7299,   5481,   3897,\n",
            "          16574,  15839,  41530,  19004,   1626,  74677,   1501,   5032,   7529,\n",
            "          14025,   1317,   3780,   2576,   2081,  92810,   1044,   1809,  13173,\n",
            "           3148,   1294,  97713,   1395,  28088,   1944,   4171,   1032,   1057,\n",
            "           1053,   1037,  14381,   1046,  56009,   1261,  16094,  26792,  23099,\n",
            "          11551,   1454,   1261,  10616,   6373,   1338,   1785,   1278,   2937,\n",
            "           2478,   1278,   9576,   4139,   1402,  14078,   1317,  10616,  12220,\n",
            "          41530,  20100,   1044,  27923,  10749,  26158,  12270,   1063,   2157,\n",
            "          13536,   1317,  13218,   9576,   2081,  14420,   4688,  26300,   1044,\n",
            "           2878,   1681,  28714,   1454,   1278,   3148,   1044,  39374,  41530,\n",
            "           5965,   1044,   1261,  22868,   1044,   1261,  41530,   9519,   1046,\n",
            "           7295,  49250,   2077,   1062,  25413,  16264,  13709,   1435,   6170,\n",
            "           2520,   2534,   2478,   1059, 118808,  45281,   1450, 109228,   1619,\n",
            "          41562,  27094,   1044,  52990,   9576,   2229,  68082,  66432,  58376,\n",
            "          40052,  41530,  27825,  33630,   1261,  41530,  42302,   1302,   5702,\n",
            "           1046,   1531,  17631,  48830,  38407,  23303,   1086,  11364,   5553,\n",
            "           1307,  32269,   1302,   1261,  16094,  60069,   1321,   3687,   3644,\n",
            "           1317,   3844,  41530,   1429,  27970,   1034,   6906,   1317,   7277,\n",
            "           2269,   5186,   1307,   5965,  37487,   1435,   4171,   1032,   1054,\n",
            "           1048,   1037,  78260,  14381,  15342,  74045,   1561,   1060,  24613,\n",
            "           1062,   1048,   1046,   1054,   1885,  24613,   1062,      2]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1]], device='cuda:0'), 'advantages': tensor([0.3547], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 1060, 74045,  3318,  1784, 14146,  8164,  1455,  2127,  2933,  1317,\n",
            "          6904,  5305,  1317,  1420, 64226,  1321, 60270, 34932,  1435,  2034,\n",
            "         15231, 10284,  1046,  1531, 14146, 23880,  5178, 24244,  1408, 34932,\n",
            "          4275, 27533,  1626,  9076,  1593,  2481,  1402,  1261, 46952, 21823,\n",
            "          1394,  6187,  1261, 18034, 58792,  1044, 34932, 52875,  1710,  1402,\n",
            "          2434,  1435,  1261,  4938,  1536, 41530, 29694,  2274,  4069, 12772,\n",
            "          1307,  1278, 19102,  6904, 29708,  1338, 23811,  6904,  2481,  1402,\n",
            "          1805,  1307,  6983,  1317, 19588,  2034, 32113,  1294,  3542,  1317,\n",
            "         10035, 11093,  1046, 12431,  1044, 58792,  1261, 18034,  1394,  1278,\n",
            "          6960,  3823,  1307,  6904,  2168,  1605,  3180,  3315,  7453,  1693,\n",
            "          1278,  7293, 18034, 30191,  4362,  1584, 11118,  1338, 53093,  1044,\n",
            "         14146, 51622,  1394, 13828,  5702,  2158,  1408,  2034,  7357,  5449,\n",
            "          1317,  9086,  1278, 23582,  1046,  3886,  1044,  1294,  1593,  2937,\n",
            "          1044,  1278,  4597,  6904,  1395, 22528,  2453, 91989,  1420, 11914,\n",
            "          5702,  6123,  1044,  1799, 84083,  1278,  2965,  1394,  4607,  2058,\n",
            "          1325,  1046, 18011,  1044,  1278, 41530,  5032,  2095, 70440, 49241,\n",
            "          6904,  4546,  1394,  2903, 28253, 64226, 34932,  1338,  4380,  1395,\n",
            "          2095,  1307,  4878,  8482,  1536, 41530, 29694,  2478, 46952, 18267,\n",
            "         12663,  1321,  9517,  7091,  1317, 38320, 26907, 97016,  1101,  1626,\n",
            "          1885, 74045,  3318,  1060, 24613,  1062,  1048,  1046,  1055,  1053,\n",
            "          1885, 24613,  1062,     2,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.2612], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 69957,   1044,   3226,   1681,   2036,  38528,   2832,   1394,   1593,\n",
            "          16023,  18106,   2100,  49250,   2077,   3318,   4268,   2534,   1317,\n",
            "           6391,   5627, 106604,   1319,   1288,   1651,   1278,  14146,   3831,\n",
            "          12334,   6585,   1321, 106604,  14282,  10910,   1041,   1395,   1261,\n",
            "          44761,  14146,   1505,   7442,   1261,  41530,   5032,   1338,  10107,\n",
            "           1405,   1044,   4057,   1408,   1278,  16023,  18106,   1877,   1049,\n",
            "           1046,   4159,   2210,   1278,  18348,   2832,   1307,  54348,   2283,\n",
            "           1278,  14146,  44214,   7504,  12598,   1639,  21294,   3804,   3946,\n",
            "          35515,   1044,  81743,   1044,  29542,   1044,   1321,   8686,  11499,\n",
            "           1799,   1395,   1420,  10923,   8482,   1626,   1050,   1046, 106604,\n",
            "           1044,   1294,   4005,   1317,   2576,  18119,  41562,   9578,   1044,\n",
            "           8942,   1853,   8686,   5751,   1435,  12581,   1294,  22506,   3581,\n",
            "           1049,   1056,   1054,   1055,   1064,  22498,   4795,   2354,   1626,\n",
            "           4072,   6585,  19877,   1317,   1278,   6255,  41562,   8686,   5751,\n",
            "          10249,  15421,   9985,   1278,  17718,   1317,   1402,  11110,  94903,\n",
            "           1060,   1044,   1278,  18106,  19877,   1317,   1402,   4352,   1321,\n",
            "          15421,  11688,   1584,   4265,   3816,   4514,  41530,  16591,   1046,\n",
            "           4634,   1653,   1605,   6274,   1317,  23808,   1435,   5965,   1307,\n",
            "          41530,  35821,   2019,  11117,   1267,   8032,   1044,   2878,   2190,\n",
            "           4832,   1536,  11735,   1261,  14381,   2100,   1032,   1032,   1049,\n",
            "           1046,  32955,  41562,   1058,  30460,   1286,  21043,  46004,  62693,\n",
            "           3804,   3946,  48044,   2383,   1398,   9184,  84498,   1321,  33673,\n",
            "           1414,   2519,   1885,  74045,   1561,   1060,  24613,   1062,   1048,\n",
            "           1046,   1050,   1053,   1885,  24613,   1062,      2,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5730], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 1975,  1060, 74045,  1062, 35957,  1408,  1278,  5315,  5662,  1044,\n",
            "          2878,  1681,  5972,  1877,  6958,  1395,  1261,  1032,  1049,  1053,\n",
            "          7133,  6904, 29255,  1044, 14655,  1261, 22870,  1046, 11549,  1501,\n",
            "         29694,  5153, 44765, 99033,  1321,  8031, 11328, 14980,  1394,  7357,\n",
            "         12542,  1044,  1799,  4139, 24441,  6245, 24244, 56355,  1505, 58792,\n",
            "         24244,  2903,  2453,  2034, 18102, 10601,  1046,  9380,  1044,  1278,\n",
            "         14146,  8164,  2127,  7455,  1261,  4811,  5451,  1044, 10138,  5289,\n",
            "         58792,  2903, 17277,  1307,  6186, 29751,  1046,  1032,  4159,  8164,\n",
            "          4433, 30102,  1506, 49208, 60571,  1317,  4978,  9012,  1394,  1457,\n",
            "         63947,  1046, 43888,  4510,  1349,  5180,  1088,  2188,  1736, 14246,\n",
            "          1562, 56220,  1302,  2396,  1278,  2147,  6580, 15249, 33075,  1307,\n",
            "          2142,  1317,  2210, 14146, 52449,  5305,  1046,  2409,  2142,  7404,\n",
            "         35714,  4139, 36840,  1394, 14146,  8198,  2424,  5275, 12772,  1338,\n",
            "          6958,  1395,  1420, 20726, 32795,  1513,  1032,  1049,  1053,  1037,\n",
            "          1394, 52875,  1317, 34932,  1799, 25640, 16581,  1294,  1593,  5526,\n",
            "          1338,  6958,  1395, 20726,  6904, 29255, 34345, 14146, 44763, 41530,\n",
            "          4266,  1317,  3180, 19599, 28507,  2259, 74045,  1561,  1060, 24613,\n",
            "          1062,  1048,  1046,  1055,  1053,  1885, 24613,  1062,  1975,     2,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.2612], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[1975,    2,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-2.3894], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}]\n",
            "[2025-10-28 07:26:59 IST] inputs are , {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 1975,  1060, 74045,  1062, 35957,  1408,  1278,  5315,  5662,  1044,\n",
            "          2878,  1681,  5972,  1877,  6958,  1395,  1261,  1032,  1049,  1053,\n",
            "          7133,  6904, 29255,  1044, 14655,  1261, 22870,  1046, 11549,  1501,\n",
            "         29694,  5153, 44765, 99033,  1321,  8031, 11328, 14980,  1394,  7357,\n",
            "         12542,  1044,  1799,  4139, 24441,  6245, 24244, 56355,  1505, 58792,\n",
            "         24244,  2903,  2453,  2034, 18102, 10601,  1046,  9380,  1044,  1278,\n",
            "         14146,  8164,  2127,  7455,  1261,  4811,  5451,  1044, 10138,  5289,\n",
            "         58792,  2903, 17277,  1307,  6186, 29751,  1046,  1032,  4159,  8164,\n",
            "          4433, 30102,  1506, 49208, 60571,  1317,  4978,  9012,  1394,  1457,\n",
            "         63947,  1046, 43888,  4510,  1349,  5180,  1088,  2188,  1736, 14246,\n",
            "          1562, 56220,  1302,  2396,  1278,  2147,  6580, 15249, 33075,  1307,\n",
            "          2142,  1317,  2210, 14146, 52449,  5305,  1046,  2409,  2142,  7404,\n",
            "         35714,  4139, 36840,  1394, 14146,  8198,  2424,  5275, 12772,  1338,\n",
            "          6958,  1395,  1420, 20726, 32795,  1513,  1032,  1049,  1053,  1037,\n",
            "          1394, 52875,  1317, 34932,  1799, 25640, 16581,  1294,  1593,  5526,\n",
            "          1338,  6958,  1395, 20726,  6904, 29255, 34345, 14146, 44763, 41530,\n",
            "          4266,  1317,  3180, 19599, 28507,  2259, 74045,  1561,  1060, 24613,\n",
            "          1062,  1048,  1046,  1055,  1053,  1885, 24613,  1062,  1975,     2,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.2612], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}\n",
            "[2025-10-28 07:26:59 IST] END _prepare_inputs, keys=['prompt_ids', 'prompt_mask', 'completion_ids', 'completion_mask', 'advantages', 'num_items_in_batch'], prompt_ids.shape=(1, 646), completion_ids.shape=(1, 485)\n",
            "[2025-10-28 07:26:59 IST] ENTER compute_loss, use_liger_loss=False\n",
            "[2025-10-28 07:26:59 IST] ENTER _compute_loss, prompt_ids.shape=(1, 646), completion_ids.shape=(1, 485), loss_type=dapo, beta=0.0, importance_sampling_level=token\n",
            "[2025-10-28 07:26:59 IST] ENTER _get_per_token_logps_and_entropies, input_ids.shape=(1, 1131), attention_mask.shape=(1, 1131), logits_to_keep=485, batch_size=None, compute_entropy=True\n",
            "[2025-10-28 07:26:59 IST] END _get_per_token_logps_and_entropies, logps.shape=(1, 485), entropies=(1, 485)\n",
            "[2025-10-28 07:27:00 IST] END _compute_loss, loss=-0.025814708322286606\n",
            "[2025-10-28 07:27:00 IST] END compute_loss (standard)\n",
            "[2025-10-28 07:27:00 IST] ENTER _prepare_inputs, training=True, _step=7, len_batch=n/a, si_2\n",
            "[2025-10-28 07:27:00 IST] mode is , train\n",
            "[2025-10-28 07:27:00 IST] generate_every 8 = self.args.steps_per_generation 8 * self.num_iterations 1\n",
            "[2025-10-28 07:27:00 IST] self._step is , 7\n",
            "[2025-10-28 07:27:00 IST] self._buffered_inputs , [{'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[  1060,  74045,   1062,   1785,   1278,   8516,   5055,   1044,   1278,\n",
            "           3330,   7444,   1317,   5100,   1261,   1461,   6278,   1519,  11551,\n",
            "           1046,   9380,   1395,   1278,  38528,   2100,   1049,   1046,   1531,\n",
            "           3330,   1395,   5700,   3923,   5124,   1317,   9662,   1557,   1261,\n",
            "           4036,   1455,   1681,   4963,   1454,   1420,  64226,   1626,   1050,\n",
            "           1046,   3730,   1395,   1836,   5647,   1307,   2258,  52819,   6727,\n",
            "          40294,   1317,   8132,   2203,   2778,  27528,  26684,   1626,   1051,\n",
            "           1046,  34932,   6904, 120368,  14047,   1278,  18817,  11157,   1317,\n",
            "           1420,  20726,   8516,  25077,   2158,  32418,  19803,   1302,   1261,\n",
            "         102835,  30481,   1454,  26873,  18034,  23582,   1626,   1052,   1046,\n",
            "          31205,   1672,   1536,  34081,   1073,   1263,   1321, 128977,   1394,\n",
            "           4514,  12181,   7219,  27528,   1408,   1278,   2147,   4014,   1010,\n",
            "           1053,   1046,  45074,  11549,   1501,  11093,   5033,   1032,  24300,\n",
            "           1294,   5150,  24468,   5510,  18964,  12319,  66505,   3421,   1599,\n",
            "           7655, 118672,   1536,  27976,  44761,  67650,   2779,  10636,   1338,\n",
            "           2596,  20465,   1261,  13864,  32595,   2862,   1044,   1494,  49498,\n",
            "          19685,   1408,   1278,   4319,   6153,   3435,  12276,  49230,   2203,\n",
            "          80046,  13991,   1294,  18847,   1505,  15831,   1279, 130816,   1046,\n",
            "         114210,   1638,   1058,  44250,   7591,  10045,   2405,   1261,  15851,\n",
            "           6706,   1307,  10636,   1294,   2643, 116050,   1532,   2259,  74045,\n",
            "           3318,   1060,  24613,   1062,   1048,   1046,   1050,   1053,   1885,\n",
            "          24613,   1062,      2,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5730], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,  11745,   1584,   1278,   2830,   5305,   1455,\n",
            "           1362,   1855,   4670,   1317,   1974,   2136,   2100,   1049,   1046,\n",
            "           1603,  25413,  18244,   5450,   1531,  14146,   1395,  64897,   7791,\n",
            "           2314,  63536,   1349,   1804,   1120,   5305,   1338,   1050,   1046,\n",
            "           1603,  86626,   1307,  11549,   1501,   5450,   1656,   1278,   3145,\n",
            "           2142,  18106,   1044,   2127,  14404,   1455,   1317,   6904,   5305,\n",
            "           2127,   2534,   1317,   2210,   2034,   2118,   1321,   8160,   1261,\n",
            "          17898,  17959,  25354,   1046,   3060,  10597,  12319,   1536,  23288,\n",
            "           2034,  38576,   1317,   1278,   1349,   1804,   1120,   2118,   1681,\n",
            "          21666,  62183,   1338,   1293,  17475,  10078,  58843,  25787,   8867,\n",
            "         115321,   1058,   1032,   1010,   1293,   1462,  12953,   1710,   4237,\n",
            "           2314,   1278,  10469,   1307,  63536,   5305,   1505,   1402,   8462,\n",
            "           3964,   1317,   4503,   3880,   1267,   1260,   1462,   1531,   2108,\n",
            "           1307,   1429,   1393,   2066,   1302,   1034,  21905, 106714,   7807,\n",
            "           2314,   1278,   5355,   1307,  63536,   1338,   1369,  27923,   7560,\n",
            "           7042,   7807,   1317,   7442,   4069,   2258,   4514,   5966,   1338,\n",
            "           1051,   1046,   1603,  34932,  44250,  87562,   5450,   1531,  14146,\n",
            "           2095,   6136,   2314,  34932,   1681,  19102,  99646,  15021,   5178,\n",
            "           1317,   2424,   1046,   5930,   3686,   1799,   1395,   9210,  77846,\n",
            "           1297,   1505,  77846,   3929,  47210,   2314,   1261,  24149,   4920,\n",
            "           1294,   1278,   8673,   1420,  11083,  17959,   6904,   1562,   1349,\n",
            "           1804,   1120,   1338,   1052,   1046,   1603,  69567,   1307,  18244,\n",
            "          27505,   5450,   1531,   4546,   8688,   5662,  24130,   3629,   3686,\n",
            "           1877,   1293,   1462,  34932,  87562,   1010,   1293,   1462,   8936,\n",
            "          26649,   1058,   8956,   1278,   4275,   3950,   1520,   1293,  14226,\n",
            "           1278,  39373,   2663,   1307,  14381,   1058,   1032,   1051,   1048,\n",
            "           1037,  52211,   1941,   2590,   8123,   1302,  70401,   8911,   1010,\n",
            "           1293,   2157,   1710,   4362,  12957,   1435,   2903,   1435,   8137,\n",
            "          13782,   1338,  25280, 127464,   1278,   8516,   1294,   9576,   2100,\n",
            "           1293,   1656,  11774,   1307,   5443,   1044,   3145,  17365,   1584,\n",
            "          43440,   1536,   2365,   1403,   1403,  38050,   2314,   1278,  10601,\n",
            "           1321,   8617,   7560,   1261,  38576,  12522, 106101,   1505,   4514,\n",
            "          33289,   3823,   5316,   3879,  10431,   1261,   1875,  58792,   1505,\n",
            "           2258,   2832,   1338,  74677,   1501,   5032,   2534,  18819,   1307,\n",
            "           3403,   1505,   3167,   2782,   1294,   2065,   1321,   1454,   2365,\n",
            "           1403,   1403,  38050,   1338,   4380,  17718,   4133,   5355,   1317,\n",
            "           1261,   5270,  50481,   4206,   1321,  10341,   1402,  10372,   5270,\n",
            "           1338,   5475,   1362,   3204,   1494,   2203,   1261,  14381,   1307,\n",
            "          41530,   1044,   1494,   1395, 125427,   4953,   2224,   1032,   1053,\n",
            "           1048,   1037,   1809,   4853,   3964,   1317,   8744,   4005,   1044,\n",
            "          10005,   6167,  34941,   1307, 113640,   2136,   8686,   1321,   1294,\n",
            "          13793,   2314,   1278,   2658,   1307,  10601,   8807,   1626,   1784,\n",
            "          33226,   2632,   1307,   1877,   1060,  24613,   1062,   1048,   1046,\n",
            "           1053,   1885,  24613,   1062,      2,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-0.2066], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,  12598,   1681,  26812,   1278,   5662,  18106,\n",
            "           1877,   1049,   1046,   1603,  25413,  51595,   3795,   1531,  14146,\n",
            "          14725,   8942,  96930,   1505,   1429,   1071,   5988,   1951,   1034,\n",
            "           1319,  93066,   2283,   1261,   5289,  46425,  10788,   9648,   6904,\n",
            "           4342,   1050,   1046,   1603,  12508, 114040,   3795,   4159,   2607,\n",
            "           2405,   7693,   2034,   3145,  11328,  58792,   9576,   1044,  35499,\n",
            "           1302,   2034,   5972,   1394,   6904,   1626,   1051,   1046,   1603,\n",
            "           3877, 112194,   1505,  90771,   1279,   2034,   3145,  10601,   4777,\n",
            "           3795,   1531,   2937,   6122,   1044,   2156,   1395,   1836,  17686,\n",
            "           2127,   2840,  58238,  16278,   1044,   7293,   4777,   1394,  18034,\n",
            "          88099,   1319,   1115,  52512,   1302,  87409,   9576,   4342,   1052,\n",
            "           1046,   1603,   1068,  40501,  88872,   3795,   3730,   1584,  28507,\n",
            "           3844,   1058, 112641,   1408,  34932,   1044, 129184,   1294,  33391,\n",
            "          58376,   1513,   1349,   1804,   1120,   1524,  95366,   2118,  14096,\n",
            "           8223,   1836,  10098, 117424,   1046,   3730,   1395,   5711,   3101,\n",
            "           3643,   9576,   1046,   2259,  74045,   3318,   1060,  24613,   1062,\n",
            "           1048,   1046,   1050,   1053,   1885,  24613,   1062,      2,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5730], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 12598,   1681,  20189,   1278,  18106,   2396,   6585,   1321,   1278,\n",
            "          14146,   2100,   1045,   1603,  29212,  24468,  32868,   1058, 106604,\n",
            "           1438,   1395, 117100,   1317,   6904,   1853,   5305,   1626,   1045,\n",
            "           1603,  51414,   1058,  16566,   2391,   1394,  52546,  12460,  82119,\n",
            "           2591,   1045,   4973,  25079,   2782,   1321,  33673,   1934,   2151,\n",
            "          35801,   1809,   9576,   2479,  85410,   1044,  10126,  28263,   1321,\n",
            "          19024,   1065,   2019,  11117,   1722,  76382,   1338,   4072,   1603,\n",
            "          74677,   1501,  35821,  80143, 120430,  84596,  79103,   1115,   1317,\n",
            "          24185,   1009,   1043,  11549,   1501,  29694,   4139,   6983,  27421,\n",
            "          81743,   1505,  29542,  52257,   1338,   5286,   6186,   1319,  13148,\n",
            "           3205,  25079,   2782,   1321, 119287,  20490,   4127,   2479,  19427,\n",
            "           6218,   9576,   9576,   1456,  11745,   1395,   1261,   4171,   5972,\n",
            "           1394,  55054,   1302,   2576,   9576,   3147,   2127,   1722,  31073,\n",
            "           1261,   4510,   5510,   8265,   1046,  10638,   2801,   5705,   4139,\n",
            "           7529,   2925,   1799,   7560,   1317,   6130,  41562,   1877,   1049,\n",
            "           1046,   1603, 117540,   1294,  19364,  31936,   1438,   2274,   4139,\n",
            "           1402,  18747,   6370,   1317,   6904,   3778,   1661,   1307,   1261,\n",
            "           6410,   1294,   6856,   1307,   2142,   1321,  15021,   1319,  31346,\n",
            "          17959,   6309,   4265,   1875,  98283,   1574,   1294,   1799,   2937,\n",
            "           1494,   4139,   1402,   1261,   8516,   1799,   1395,  49063,   1294,\n",
            "           1799,   2937,   6705,  15021,   4139,   1402,   7960,   1513,   5785,\n",
            "           1462,   1799,  24277,  76137,  15021,   1321,  32795,   5178,   1408,\n",
            "         107494,   5305,   6904,   1562,   5150,  24468,   1626,   1050,   1046,\n",
            "           1603,  70158,   6309,  29949,   1452,  17939,  20974,   1438,  11696,\n",
            "           1799,   1710,   3820,   1394,  36840,   9576,  69785,   4242,   2487,\n",
            "          14715,   1321,   7195,   1317,  21294,   3184,   5510,   1505,  13411,\n",
            "          13955,   1317,  10616,  17183,  47525,   1741,  80691,  29447,   1875,\n",
            "          41530,  29694,   1435,   9700,  32113,   3820,   2203,   2034,   4510,\n",
            "           3992,  45698,   1044,   1809,   4382,  18749,   1319,  92860,   5449,\n",
            "           8091,   1710,  18052,  27825,  28284,   2519,  21464,   4501,   3214,\n",
            "           1435,   5956,   2862,   3314,   5353,   1408,   6705,  15021,   6793,\n",
            "          10477,  73424,   2632,  64983,   1584,   3214,   8617,   1317,  10477,\n",
            "          47036,  58376,   1046,   3964,   1317,   2534,   1394,   7481,   4798,\n",
            "          41562,   1536,  12388,   1307,  15699,   1045,   7299,   5481,   3897,\n",
            "          16574,  15839,  41530,  19004,   1626,  74677,   1501,   5032,   7529,\n",
            "          14025,   1317,   3780,   2576,   2081,  92810,   1044,   1809,  13173,\n",
            "           3148,   1294,  97713,   1395,  28088,   1944,   4171,   1032,   1057,\n",
            "           1053,   1037,  14381,   1046,  56009,   1261,  16094,  26792,  23099,\n",
            "          11551,   1454,   1261,  10616,   6373,   1338,   1785,   1278,   2937,\n",
            "           2478,   1278,   9576,   4139,   1402,  14078,   1317,  10616,  12220,\n",
            "          41530,  20100,   1044,  27923,  10749,  26158,  12270,   1063,   2157,\n",
            "          13536,   1317,  13218,   9576,   2081,  14420,   4688,  26300,   1044,\n",
            "           2878,   1681,  28714,   1454,   1278,   3148,   1044,  39374,  41530,\n",
            "           5965,   1044,   1261,  22868,   1044,   1261,  41530,   9519,   1046,\n",
            "           7295,  49250,   2077,   1062,  25413,  16264,  13709,   1435,   6170,\n",
            "           2520,   2534,   2478,   1059, 118808,  45281,   1450, 109228,   1619,\n",
            "          41562,  27094,   1044,  52990,   9576,   2229,  68082,  66432,  58376,\n",
            "          40052,  41530,  27825,  33630,   1261,  41530,  42302,   1302,   5702,\n",
            "           1046,   1531,  17631,  48830,  38407,  23303,   1086,  11364,   5553,\n",
            "           1307,  32269,   1302,   1261,  16094,  60069,   1321,   3687,   3644,\n",
            "           1317,   3844,  41530,   1429,  27970,   1034,   6906,   1317,   7277,\n",
            "           2269,   5186,   1307,   5965,  37487,   1435,   4171,   1032,   1054,\n",
            "           1048,   1037,  78260,  14381,  15342,  74045,   1561,   1060,  24613,\n",
            "           1062,   1048,   1046,   1054,   1885,  24613,   1062,      2]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1]], device='cuda:0'), 'advantages': tensor([0.3547], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 1060, 74045,  3318,  1784, 14146,  8164,  1455,  2127,  2933,  1317,\n",
            "          6904,  5305,  1317,  1420, 64226,  1321, 60270, 34932,  1435,  2034,\n",
            "         15231, 10284,  1046,  1531, 14146, 23880,  5178, 24244,  1408, 34932,\n",
            "          4275, 27533,  1626,  9076,  1593,  2481,  1402,  1261, 46952, 21823,\n",
            "          1394,  6187,  1261, 18034, 58792,  1044, 34932, 52875,  1710,  1402,\n",
            "          2434,  1435,  1261,  4938,  1536, 41530, 29694,  2274,  4069, 12772,\n",
            "          1307,  1278, 19102,  6904, 29708,  1338, 23811,  6904,  2481,  1402,\n",
            "          1805,  1307,  6983,  1317, 19588,  2034, 32113,  1294,  3542,  1317,\n",
            "         10035, 11093,  1046, 12431,  1044, 58792,  1261, 18034,  1394,  1278,\n",
            "          6960,  3823,  1307,  6904,  2168,  1605,  3180,  3315,  7453,  1693,\n",
            "          1278,  7293, 18034, 30191,  4362,  1584, 11118,  1338, 53093,  1044,\n",
            "         14146, 51622,  1394, 13828,  5702,  2158,  1408,  2034,  7357,  5449,\n",
            "          1317,  9086,  1278, 23582,  1046,  3886,  1044,  1294,  1593,  2937,\n",
            "          1044,  1278,  4597,  6904,  1395, 22528,  2453, 91989,  1420, 11914,\n",
            "          5702,  6123,  1044,  1799, 84083,  1278,  2965,  1394,  4607,  2058,\n",
            "          1325,  1046, 18011,  1044,  1278, 41530,  5032,  2095, 70440, 49241,\n",
            "          6904,  4546,  1394,  2903, 28253, 64226, 34932,  1338,  4380,  1395,\n",
            "          2095,  1307,  4878,  8482,  1536, 41530, 29694,  2478, 46952, 18267,\n",
            "         12663,  1321,  9517,  7091,  1317, 38320, 26907, 97016,  1101,  1626,\n",
            "          1885, 74045,  3318,  1060, 24613,  1062,  1048,  1046,  1055,  1053,\n",
            "          1885, 24613,  1062,     2,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.2612], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 69957,   1044,   3226,   1681,   2036,  38528,   2832,   1394,   1593,\n",
            "          16023,  18106,   2100,  49250,   2077,   3318,   4268,   2534,   1317,\n",
            "           6391,   5627, 106604,   1319,   1288,   1651,   1278,  14146,   3831,\n",
            "          12334,   6585,   1321, 106604,  14282,  10910,   1041,   1395,   1261,\n",
            "          44761,  14146,   1505,   7442,   1261,  41530,   5032,   1338,  10107,\n",
            "           1405,   1044,   4057,   1408,   1278,  16023,  18106,   1877,   1049,\n",
            "           1046,   4159,   2210,   1278,  18348,   2832,   1307,  54348,   2283,\n",
            "           1278,  14146,  44214,   7504,  12598,   1639,  21294,   3804,   3946,\n",
            "          35515,   1044,  81743,   1044,  29542,   1044,   1321,   8686,  11499,\n",
            "           1799,   1395,   1420,  10923,   8482,   1626,   1050,   1046, 106604,\n",
            "           1044,   1294,   4005,   1317,   2576,  18119,  41562,   9578,   1044,\n",
            "           8942,   1853,   8686,   5751,   1435,  12581,   1294,  22506,   3581,\n",
            "           1049,   1056,   1054,   1055,   1064,  22498,   4795,   2354,   1626,\n",
            "           4072,   6585,  19877,   1317,   1278,   6255,  41562,   8686,   5751,\n",
            "          10249,  15421,   9985,   1278,  17718,   1317,   1402,  11110,  94903,\n",
            "           1060,   1044,   1278,  18106,  19877,   1317,   1402,   4352,   1321,\n",
            "          15421,  11688,   1584,   4265,   3816,   4514,  41530,  16591,   1046,\n",
            "           4634,   1653,   1605,   6274,   1317,  23808,   1435,   5965,   1307,\n",
            "          41530,  35821,   2019,  11117,   1267,   8032,   1044,   2878,   2190,\n",
            "           4832,   1536,  11735,   1261,  14381,   2100,   1032,   1032,   1049,\n",
            "           1046,  32955,  41562,   1058,  30460,   1286,  21043,  46004,  62693,\n",
            "           3804,   3946,  48044,   2383,   1398,   9184,  84498,   1321,  33673,\n",
            "           1414,   2519,   1885,  74045,   1561,   1060,  24613,   1062,   1048,\n",
            "           1046,   1050,   1053,   1885,  24613,   1062,      2,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5730], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 1975,  1060, 74045,  1062, 35957,  1408,  1278,  5315,  5662,  1044,\n",
            "          2878,  1681,  5972,  1877,  6958,  1395,  1261,  1032,  1049,  1053,\n",
            "          7133,  6904, 29255,  1044, 14655,  1261, 22870,  1046, 11549,  1501,\n",
            "         29694,  5153, 44765, 99033,  1321,  8031, 11328, 14980,  1394,  7357,\n",
            "         12542,  1044,  1799,  4139, 24441,  6245, 24244, 56355,  1505, 58792,\n",
            "         24244,  2903,  2453,  2034, 18102, 10601,  1046,  9380,  1044,  1278,\n",
            "         14146,  8164,  2127,  7455,  1261,  4811,  5451,  1044, 10138,  5289,\n",
            "         58792,  2903, 17277,  1307,  6186, 29751,  1046,  1032,  4159,  8164,\n",
            "          4433, 30102,  1506, 49208, 60571,  1317,  4978,  9012,  1394,  1457,\n",
            "         63947,  1046, 43888,  4510,  1349,  5180,  1088,  2188,  1736, 14246,\n",
            "          1562, 56220,  1302,  2396,  1278,  2147,  6580, 15249, 33075,  1307,\n",
            "          2142,  1317,  2210, 14146, 52449,  5305,  1046,  2409,  2142,  7404,\n",
            "         35714,  4139, 36840,  1394, 14146,  8198,  2424,  5275, 12772,  1338,\n",
            "          6958,  1395,  1420, 20726, 32795,  1513,  1032,  1049,  1053,  1037,\n",
            "          1394, 52875,  1317, 34932,  1799, 25640, 16581,  1294,  1593,  5526,\n",
            "          1338,  6958,  1395, 20726,  6904, 29255, 34345, 14146, 44763, 41530,\n",
            "          4266,  1317,  3180, 19599, 28507,  2259, 74045,  1561,  1060, 24613,\n",
            "          1062,  1048,  1046,  1055,  1053,  1885, 24613,  1062,  1975,     2,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.2612], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[1975,    2,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-2.3894], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}]\n",
            "[2025-10-28 07:27:00 IST] inputs are , {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "         103733,   1871,   4969,   1044,   1593,   1395,   6585,   1046,  24665,\n",
            "           6585,   1044, 106604,  14282,   3226,   1046,   1362,   4525,  15148,\n",
            "           1261,  18363,  17336,   1321,   2933,   1317,   6904,   5305,   1317,\n",
            "           1420,  64226,   1046,  51045,   1317,   3508,   1044, 106604,   1046,\n",
            "           9246,   1639,  21294,   3804,   3946,  35515,   1044,  81743,   1044,\n",
            "          29542,   1044,   1321,   8686,   1046,  16611,   7771,   1044,   1925,\n",
            "          29542,   1044,   1925,   6981,   1044,   1321,   1362,   4525,   2586,\n",
            "           3300,   1046,  33673, 103151,  18985,  23715,   1721,   1642,   4795,\n",
            "           2354,   1046,  10448,   1044,  35801,   1046,      4]],\n",
            "       device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[1975,    2,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
            "           11,   11,   11,   11,   11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-2.3894], device='cuda:0'), 'num_items_in_batch': tensor(1821, device='cuda:0')}\n",
            "[2025-10-28 07:27:00 IST] END _prepare_inputs, keys=['prompt_ids', 'prompt_mask', 'completion_ids', 'completion_mask', 'advantages', 'num_items_in_batch'], prompt_ids.shape=(1, 646), completion_ids.shape=(1, 485)\n",
            "[2025-10-28 07:27:00 IST] ENTER compute_loss, use_liger_loss=False\n",
            "[2025-10-28 07:27:00 IST] ENTER _compute_loss, prompt_ids.shape=(1, 646), completion_ids.shape=(1, 485), loss_type=dapo, beta=0.0, importance_sampling_level=token\n",
            "[2025-10-28 07:27:00 IST] ENTER _get_per_token_logps_and_entropies, input_ids.shape=(1, 1131), attention_mask.shape=(1, 1131), logits_to_keep=485, batch_size=None, compute_entropy=True\n",
            "[2025-10-28 07:27:01 IST] END _get_per_token_logps_and_entropies, logps.shape=(1, 485), entropies=(1, 485)\n",
            "[2025-10-28 07:27:01 IST] END _compute_loss, loss=0.002624280983582139\n",
            "[2025-10-28 07:27:01 IST] END compute_loss (standard)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='89' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 89/245 1:13:54 < 2:12:32, 0.02 it/s, Epoch 1.80/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>-0.278000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>-0.029100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>-0.051600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.055900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>-0.012000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>-0.035400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.237200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.056600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.414900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.254900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>-0.107800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.121900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>-0.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.073100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>-0.145300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.222400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>-0.194800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>-0.185500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.247200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.024000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.090300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.288200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.210800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.801800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>-0.266800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>-0.028300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.011200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>-0.150800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.645100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>-0.020300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>-0.153000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>-0.368200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.065900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>-0.017200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.071500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.074100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.635600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>-0.059100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.191800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>-0.025300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.060300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.295200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>-0.135600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>-0.029000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.157200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.184000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>-0.030300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>-0.135700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.069700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.196300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>-0.148800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.259400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>-0.260100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.186000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.068800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.137700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>-0.139100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.137300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.378800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.023500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.466200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>-0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.032300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.162000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.087000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.316300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>-0.163000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.121200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>-0.022900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.112100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.101200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.182900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.369600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>-0.061000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.097300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>-0.011600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.138600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>-0.231200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>-0.051400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.169400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.016700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.277400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.111800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.756000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.063600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.177000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.070700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "           6026,   9576,   1321,  12285,   2405,   3894,   3686,  23288,   1584,\n",
            "           4804,  28061,   1394,  41530,   1046, 106299,   1101,   2095,   1934,\n",
            "           1317,   1576,   1264,   4526,   1419,   1039,   1799,   8806,   2342,\n",
            "          16581,   2200,  17365,   6560,   1402,  35801,   1435,   2156,   1395,\n",
            "           1261,   2534,   1317,  42668,   1261,  22725,  14146,   1046,  22112,\n",
            "          12738,   1394,  75114,   3475,  23288,   2168,   1402,  72010,   4477,\n",
            "           1809,   3226,   1044,   2156,   1681,   1420,   7481,   3686,  52820,\n",
            "          21450,   2016,   1454, 115948,   1278,   3690,   1428,   1039,   9916,\n",
            "           2782,   1681,  24722,  35515,   1321,  75114,   1317,  10500,   1494,\n",
            "           4675,   1348,   1302,   4514, 123170,   1338,  74007,   1681,  24468,\n",
            "           1653,   1605,   9730,  14146,  22777,   1693,   1605,  55188,   1435,\n",
            "           1261,  44761,  14146,   4629,   1562,   7110,  11958,   1626,   1885,\n",
            "          74045,   3318,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   1062,      2,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[  1060,  74045,   1561,  35957,   1408,   1278,  18106,  48787,   5662,\n",
            "           1044,   1278,  14146,  72426,   1317,   9730,   1278,  41562,   3475,\n",
            "           1505,   2258,   2147,  17340,   3686,   1044,   6302,  16350,   1317,\n",
            "           6026,   1278,  41530,  18284,   2645,   2269,   2147,   9129,   1046,\n",
            "           4159,   2095,  33648,   1317,   9730,   2258,   7357,   1505,   6026,\n",
            "           9576,   1307,   1278,   6309,  10594,   1046,   4634,  57721,  26187,\n",
            "           2481,  18191,  10982,   1455,   1278,   2965,   4139,   1402,   6370,\n",
            "           1317,   3940,   1993,  41562,   1505,  41562,  19004,   1046,   5930,\n",
            "           1593,   5315,   1044,   1494,   1395,   4171,   1317,  14649,   1455,\n",
            "           1278,   5315,  29443,   1261,   3435,   2738,  14381,   1435,   1651,\n",
            "           1278,   4145,   1307,  11865,   3686,  13591,   1044,  35801,   1536,\n",
            "          41562,   9129,  24969,   1044,   1321,  10606,   1290,   3686,   7278,\n",
            "           8673,  24465,  77993,  27915,   1626,  75231,   1115,   7540,   1294,\n",
            "          41530,  35821,   5177,   2989,   1501,   1944,   5687,   1278,  14146,\n",
            "           6309,  10594,   1294,  14146,   1045,  37701,   1505,   2767,  50177,\n",
            "           1626,  62477,   1044,   1729,  15646,   1278,  10304,   5163,   5069,\n",
            "           1279,   4014,  45227,   5283,   1321,   1278,   2725,  16805,  17984,\n",
            "           1455,   7389,   1408,  37846,  23668,  84931,  13123,  38666,   1626,\n",
            "         111436,   1278,   3178,   1307,  52819,   1294,  13435,  26187,   1044,\n",
            "           1729,   8497,   1317,  10035,  10960,   3427,  41530,   5032,  48136,\n",
            "          40933,  24613,   1062,   1049,   1885,  24613,   4468,  74045,   1062,\n",
            "              2,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([1.8996], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 20711,   4812,  74045,   1062,   3606,   1605,  11495,   2258,   2081,\n",
            "           4811,   9576,   2314,   1278,   5449,   5677,   1044,  25330,   1278,\n",
            "          14146,   1536,  55890,   4811,   9576,   1799,   1584,  23672,   1317,\n",
            "           1402,  11530,   1319,  10683,   1278,   9916,   2782,  23419,   1294,\n",
            "           1032,   1052,   1050,   1041,   1321, 114813,   1455,   1278,   3804,\n",
            "           2295,  35515,   1307,   1278,   3475,   1402,  11865,   3066,   2258,\n",
            "           4514,   9576,   1584,  11530,  12529,   4116,   1386,   1494,  18267,\n",
            "          15591,   1121,   1046,   8494,   1593,  13578,   4546,   1394,   4514,\n",
            "           3686,   1319,  11018,   2481,  12494,   1402,   9576,   2479,   1278,\n",
            "           4811,   6309,   2782,   1505,   1278,   5275,  74254,   1505,   3804,\n",
            "           1032,   1052,  35515,   1307,   1278,   9916,   2782,   1041,  18267,\n",
            "           1261,   5659,   2081,  19577,   1046,   3797,   2576,   2481,  18191,\n",
            "           3820,   1317,  26943,   2283,   1278,   2937,   1044,   1799,   1486,\n",
            "           5595,   3226,   7423,   1044,   1799,   7510,   1494,   7759,   1261,\n",
            "           5659,   2479,   1261,   5289,  13035,   1046,   9380,   1681,   1925,\n",
            "           4171,  21823,   1044,   2878,   1650,   3369,   1278,   3629,   5305,\n",
            "          23779,   1112,   3318,  54255,   1561,  24187,   1062,  28149,  15776,\n",
            "           5662,   1536,   5150,  24468,   1319,   3265,   6309,  81853,   2653,\n",
            "          16692,   1041,   1435,   1729,   8806,   1653,   1605,   9730,   2516,\n",
            "           3686,   1454,   5888,  14027,  16574,  55890,   1593,  94114,   7091,\n",
            "          15342,   1978,   1561,  24187,   1062,  96436,   1317,   3346,   1278,\n",
            "           3711,   3643, 112910,   1693,   5662,   1317,   1457,  10028,   1278,\n",
            "           5449,   5203,   1885,   1978,   1561,  24187,   1062,  87211,  44384,\n",
            "           3686,   1394,  41562,   3816,  38576,   1307,   1278,  52546,  12460,\n",
            "          22470,  16692,   1486,   3214,  16624,   1307,   2424,   1394,   2948,\n",
            "          12216,  15342,   1978,   1561,  24187,   1062, 124566,   1570,  44016,\n",
            "          86055,  11099,  38791,   5279,   2104,   7928,  15342,   1978,   1561,\n",
            "          24187,   1062,   1784,   3804,   7791,   5662,   1394,   6026,   9576,\n",
            "           1584,  20234,   1420,  54030,   1317,   1278,  24527,  16350,   1455,\n",
            "           2505,   5888,  24926,   1564,   1394,  41562,   2168,   1402, 117467,\n",
            "          15342,   1978,   1561,   1885,   1366,   3318,  47746,   1729,  10500,\n",
            "           1278,  13968,   5662,   1394,   1278,  59128,  18894,   1044,   1536,\n",
            "           4514,  28524,   2203,   1278,   8122,   1338,  20711,   4812,  74045,\n",
            "           1062,   3761,   8110,   1454,  11549,   1501,  59128,   1710,   1402,\n",
            "          79644,  15342,   1112,   1561,  83569,   2516,  19599,   4771,  10098,\n",
            "          11778,   1321,   7185, 111191,   1046,   5930,   1455,   1294,   5759,\n",
            "           1044,   3147,  41530,  29694,   5153,   1736,   2801,  58063,   1319,\n",
            "          46370,   1286,   1408,   3686,  94904,   1321,  24821,  31892,   1317,\n",
            "           4514,  10328,  31901,   1574,   1261,   5659,   1307,   1261,   1429,\n",
            "           1114,   3038,   1034,   8070,  40052,   1429,  73949,   5109,   5370,\n",
            "           3686,   1034,   9896,   2203,   3354,   3226,   1046,   5930,   1836,\n",
            "          41562,   1307,   1278,   3475,   1321,  10718,   1044,   1593,   5966,\n",
            "          18267,   1261,   5659,  15591,   1121,   1044,   1317,   4283,   1494,\n",
            "          63780,   4004,   1338,   1885,  74045,   4468,   1112,   3318,   1060,\n",
            "          24613,   1062,   1048,   1046,   1055,   1053,   1885,  24613,   1062,\n",
            "              2]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}]\n",
            "[2025-10-28 08:41:35 IST] inputs are , {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[49250,  2077,  1561,  1784,  3629,  6763, 10982,  1455,  1278, 14146,\n",
            "          4139,  1402,  1261, 41530,  5032,  1562,  1278, 18106,  5662,  1877,\n",
            "          1049,  1046,  1429,  9476,  1605,  6026,  2424,  1046,  7490, 10500,\n",
            "          1278,  3804,  2295, 35515,  1307,  1278,  3475,  2613,  1462,  2409,\n",
            "          7444,  4382, 33144,  1394,  1261,  5270,  3690,  1321, 12551,  1278,\n",
            "          2965,  4139,  1402,  2425,  2300,  1423,  1317, 10500,  1261,  3475,\n",
            "          1435,  1261,  2070, 12754,  1626,  1050,  1046,  1429,  1073,  4552,\n",
            "          2405, 85763,  2258,  7575,  1307,  1261,  2764,  6154,  1034,  1462,\n",
            "          2409, 16054,  2577,  1562,  1278,  5270,  8482,  1307, 11495,  1261,\n",
            "          2764,  6154,  7655,  1626,  1051,  1046,  1429,  1073,  1710,  2405,\n",
            "          9730,  6026,  9576,  1034,  1462,  2409, 29025,  8033, 12551,  1278,\n",
            "         14146,  3120,  1605,  2933,  1317,  9730,  6026,  3686,  1454,  5888,\n",
            "         49209, 11105, 10317,  1626,  1051,  1046,  1531, 55552, 16964, 38576,\n",
            "          2314,  2034,  9916,  2782, 15202,  1294,  1032,  1052,  1050,  1435,\n",
            "          7259,  1307, 11530, 30269,  1044,  1799,  1395,  1420, 29025, 12705,\n",
            "          1317,  1402, 64897,  1626, 16124,  1317,  7061,  1321,  1593,  4369,\n",
            "         18106,  1681,  5965,  1044,  1261, 41530,  5032,  1505,  5888, 49209,\n",
            "         34487,  1317,  4237, 60672,  8352,  1321,  2607,  2405, 85763,  2034,\n",
            "         13006, 11904,  1626, 12598,  2190,  7137,  1278, 29881,  4057,  1408,\n",
            "          2576, 17811,  1261, 14381,  1307, 22240,  1294,  2396,  1046,  1534,\n",
            "          1274,  1561,  1885, 74045,  1561,  1060, 24613,  1561,  1048,  1046,\n",
            "          1055,  1053,  1010,  1885, 24613,  1062,     2,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}\n",
            "[2025-10-28 08:41:35 IST] END _prepare_inputs, keys=['prompt_ids', 'prompt_mask', 'completion_ids', 'completion_mask', 'advantages', 'num_items_in_batch'], prompt_ids.shape=(1, 670), completion_ids.shape=(1, 406)\n",
            "[2025-10-28 08:41:35 IST] ENTER compute_loss, use_liger_loss=False\n",
            "[2025-10-28 08:41:35 IST] ENTER _compute_loss, prompt_ids.shape=(1, 670), completion_ids.shape=(1, 406), loss_type=dapo, beta=0.0, importance_sampling_level=token\n",
            "[2025-10-28 08:41:35 IST] ENTER _get_per_token_logps_and_entropies, input_ids.shape=(1, 1076), attention_mask.shape=(1, 1076), logits_to_keep=406, batch_size=None, compute_entropy=True\n",
            "[2025-10-28 08:41:35 IST] END _get_per_token_logps_and_entropies, logps.shape=(1, 406), entropies=(1, 406)\n",
            "[2025-10-28 08:41:35 IST] END _compute_loss, loss=-0.004620393272489309\n",
            "[2025-10-28 08:41:35 IST] END compute_loss (standard)\n",
            "[2025-10-28 08:41:36 IST] ENTER _prepare_inputs, training=True, _step=709, len_batch=n/a, si_2\n",
            "[2025-10-28 08:41:36 IST] mode is , train\n",
            "[2025-10-28 08:41:36 IST] generate_every 8 = self.args.steps_per_generation 8 * self.num_iterations 1\n",
            "[2025-10-28 08:41:36 IST] self._step is , 709\n",
            "[2025-10-28 08:41:36 IST] self._buffered_inputs , [{'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1062,  11745,   1681,   1278,  38528,   7435,   1278,\n",
            "          14381,  14013,   2100,   1049,   1046,   1603,  20198,  15696,  28196,\n",
            "          30123,   5450,   7506,  46952,  18753,   4139,   1736,   2034,   6026,\n",
            "           9576,  44310,   1420,   6726,   1044,   1809,  12837,   1044,   1278,\n",
            "          34856,   4279,   6354,   2405,  16808,   1317,   1261,  23133,   1457,\n",
            "          63947,   3964,   1317,   1799,   1278,   6309,  10594,   1454,  41530,\n",
            "         122847,   4139,   1402,  25341,  35368,   3686,  23288,  16773,   1338,\n",
            "           1050,   1046,   1603,   3877, 112194,  18244,   5450,   1531,  14146,\n",
            "           6136,   1317,  10500,   1278,   3804,   2295,  35515,   1307,   1261,\n",
            "           4265,   3475,   1321,   1317,  10500,   2034,   9916,   2782,   1809,\n",
            "           4814,   2405,  85763,   1278,   2764,   6154,   1505,   9730,  15115,\n",
            "           6026,   3686,   1046,   2409,   2481,  10982,  86994,   8033,   1338,\n",
            "           1051,   1046,   1603,  99090,  16964,   5450,  11549,   1501,  29694,\n",
            "           5153,   9300,  38291,   1556,   9576,   1046,  23627,   1278, 113361,\n",
            "           8862,  22656,   1294,   1593,  18106,   1044,  46952,  44017,   1505,\n",
            "           5711,  64967,   2481,   1402,   1513,   3354,   1338,   1052,   1046,\n",
            "           1603,   2596, 129571,  14146,  19306,   5450,   2409,   2481,   2095,\n",
            "           3180,   6906,   1455,   1593,   4597,   1934,  46952,  12738,   1317,\n",
            "          21294,   2034,   3475,   1338,  41101,   1455,   3199,   4455,  29025,\n",
            "          16964,   1729,   3081,  77649,   9200,  47210,  18753,   1394,   6309,\n",
            "          31997,   1044,   1809,   1294,   2937,   1307,   4455,  16964,   1044,\n",
            "           1278,  18106,  18267,  23755,  30026,   1321,   2143,   3468,   1307,\n",
            "          13006,   1736,   2738,   5735,   1338,   1062,  34976,   1278,  14381,\n",
            "           1455,   1593,  14146,   1395,   1261,  41530,   5032,   1395,   2100,\n",
            "           1885,  74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,\n",
            "           1053,   1885,  24613,   1062,      2,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,  44296,  20505,  13151,  20505,  13151,  20505,\n",
            "          13151,   1059,  11745,   1395,   1278,   5315,   1307,   1278,   4265,\n",
            "          18106,   1321,   6334,  18106,   6422,  44296,  20505,  13151,  20505,\n",
            "          13151,  20505,  13151,   1059,   1784,   5150,  24468,  18106,   1877,\n",
            "          44296,  20505,  13151,  20505,  13151,  20505,  13151,  20505,  13151,\n",
            "          20505,  13151,   1059,   1045,  16896,   1536,  16798,   1278,   2965,\n",
            "          31912,   1278,   8516,   1317,   5234,  14146,  22777,   1317,   1261,\n",
            "           5888,  49209,  11105,   1394,   8549,  92436,  34493,   1302,   1044,\n",
            "           1799,   7444,  29025,   1321,  35499,   1115,  18119,  10098,  15999,\n",
            "           1319,   1101,   3596,   3109,  41562,  87765,   1584,   7754,   5753,\n",
            "           3214,   5059,   9916,   1505,  79350,   1535,   8426,  11696,   1455,\n",
            "           4771,   1261,   8877,   5449,   4731,   9077,   7265,   8686,   1044,\n",
            "          11396,   9916,  26439,   3475,   1044,   4346,  10098,   2782,   1505,\n",
            "           1395,   3214,   2015,   1307,  35006,   1271,  29398,   1321,  35006,\n",
            "           1401,   3083,   1319,   1982,   1317,   1032,   1050,   1053,  11084,\n",
            "           1294,   9960,  14953,   1041,   4811,   1317,   1455,  17718,   2658,\n",
            "           1046,   1766,   1065,   7537,  10011,   2715,   1402,   3214,   1408,\n",
            "           2606,   2744,   1307,   1278,  29481,   1584,  23834,   5823,   1046,\n",
            "           2820,  44296,  20505,  13151,  20505,  13151,  20505,  13151,  20505,\n",
            "          13151,  20505,  13151,   1059,   1045,  13921,   1455,   1278,  24628,\n",
            "           1934,   1278,  10485,   1307,  30407,   2034,   5449,   1693,  22777,\n",
            "           2607,   2405,   8132,   2424,   1044,   6187,   1593,   7685,   2081,\n",
            "          20702,   1748,  78659,   9500,   1278,   7453,   1307,   1261,  25988,\n",
            "           5449,   1429,  10559,   1660,   1034,   2251,   1010,  44296,  20505,\n",
            "          13151,  20505,  13151,  20505,  13151,  20505,  13151,  20505,  13151,\n",
            "           1059,   1045,  18244,   1115,   1278,  14146,   1317,  21294,   1261,\n",
            "           3475,   1321,   1429,   3715,  85763,   1278,   6960,   2764,   6154,\n",
            "           1897,   1799,   4139,  10982,   1261,   2801,   8967,   1044,   1605,\n",
            "           7655,  67122,   1454,   1278,  11105,   4139,   1402,   6370,   1317,\n",
            "           4731,  11820,   2127,  24598,   2405,  19486,  44296,  20505,  13151,\n",
            "          20505,  13151,  20505,  13151,   1059,   1784,  29049,   1612,   2395,\n",
            "          18106,   1877,  44296,  20505,  13151,  20505,  13151,  20505,  13151,\n",
            "          20505,  13151,  20505,  13151,   1059,   1045,   3316,  16533,   2200,\n",
            "           1278,  14146,  25747,   2314,   1278,   2782,   3144,   6878,   3746,\n",
            "           1420,  29025,   8174,   1321,  40052,   3236,   2965,   6026,   1321,\n",
            "          35801,  11530,   9576,   2251,   1010,  44296,  20505,  13151,  20505,\n",
            "          13151,  20505,  13151,  20505,  13151,  20505,  13151,   1059,   1045,\n",
            "          77291,   2283,  14146,   9452,   9576,   2516,   1435,  14593,   1115,\n",
            "           3508,   1114,   1338,  44296,  20505,  13151,  20505,  13151,  20505,\n",
            "          13151,   1059,  35957,   1408,   1278,  31215,   4455,   1321,   5735,\n",
            "           7981,   1536,   3629,  39945,   1051,   3175,   1486,  12636,   4455,\n",
            "           1044,   1593,  10637,   1010,  10683,   1261,   2937,   1307,   1261,\n",
            "          41530,  35821,   3690,  10119,   1562,   1261,   1010, 111778,  62929,\n",
            "           8967,   1626,   1885,  74045,   3318,   1060,  24613,   1062,   1048,\n",
            "           1046,   1055,   1053,   1885,  24613,   1062,      2,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1062,   1784,  10613,  19263,   1278,  18028,   1307,\n",
            "           1261,  14146,   1681,  13006,   1809,   2156,   1584,   2269,  96580,\n",
            "           1321,   2767,  71348,  15999,   1455,   1653,   1605,  11701,   1454,\n",
            "          15421,  14146,   3471,  15727,   1338,   1049,   1046,   1603,  34126,\n",
            "           1302,   1278,  16544,  10638,  35515,   1307,   1278,  13968,   1438,\n",
            "           1737,   2409,   1395,   9210,  29025,   1046,  57454,   1044,  14146,\n",
            "           3471,   2168,   4772,   4237,   1394,   1278,   6960,   9377,   1505,\n",
            "           3475,   1046,  17934,   1044,   2127,   4139,   4237,   1394,  10098,\n",
            "           8352,   1505,   1535,   8426,  22777,   1435,   1805,   1307,  41562,\n",
            "          40933,   3285,   1561,   1050,   1046,   1603,   1065,   4746,   1302,\n",
            "          15322,   6154,   8867,  17844,   1438,   1737,   1531,  14146, 105562,\n",
            "           8164,   1044,   1429,   1073,   4552,   2405,  85763,   2258,   7575,\n",
            "           1307,   1261,   2764,   6154,   2613,  27923,  13709,  15851,  10098,\n",
            "          11778,   3144,  57010,   1536,   1278,  14146,  40933,   3285,   1561,\n",
            "           1051,   1046,   1603,  83665,   1302,   1394,  29915,  33537,   1438,\n",
            "           1737,   1531,   4546,   1429,  35628,   2034,   9916,   2782,  15202,\n",
            "           1294,   1032,   1052,   1050,   1034,  18267,  57721,   3147,   9916,\n",
            "           8091,   1584,  12837,   5132,   1099,  12341,   1321,   3744,   1046,\n",
            "           3203,   2319,   2487,   6307,  26840,   1505,   5266,   1584,   4289,\n",
            "           6906,  15388,  41530,  35821,   3590,  17859,  24468,   1321,  39393,\n",
            "          94796,  14574,   1099,   3850,   1656,   1046,   1362,   3648,   1278,\n",
            "          18106,   3897, 106299,   1101,   5150,   5700,   3897,  18267,  44761,\n",
            "           1044,   1809,   1278,  15727,  18230,  88087,   5449,  90498,   1044,\n",
            "           2409,  12551,   1278,  10613,   2188,   1605,   1402,  17262,  54348,\n",
            "           1319,  11018,   3120,   1605,  20594,   4204,   1278,   5449,   2782,\n",
            "          10808,   9916,   9576,   1044, 111078,   3686,   3147,  41530,   5032,\n",
            "           1710,  17470,  35420,   5270,  41562,  40933,   3285,   1561,   1052,\n",
            "           1046,   1603, 105801,   2136,   1278,  53247,   1307,  29915,   9837,\n",
            "           1438,   1294,   1534, 100820,  18239,   3085,   1370,   1062,   1729,\n",
            "           9134,   1455,   1278,   3519,  10613,  26723,  57721,   1562,   1261,\n",
            "           9454,   2862,   1307,   3719,   1338,  36296,  15421,  14146,   4810,\n",
            "          16964,   1584,   1605,  21491,   1513,   1265,  31331,  33182,   7357,\n",
            "           9576,   1809,  55890,   2424,   1046,  39321,   5283,   1307,  52819,\n",
            "          10982,   1593,  10613,   2188,   1402,   1805,   1307,   8462,   3846,\n",
            "           1302,   1505,   1513,   3560,   1044,   1261,   2058,   1325,   1338,\n",
            "          93277,   1044,  11735,   1420,  48602,   1032,   2259,  74045,   4812,\n",
            "          24613,   1062,   1048,   1046,   1055,   1885,  14540,  17959,   1736,\n",
            "           2151,   9946,   2754,  40933,   3285,   1561,   1885,  24613,   1062,\n",
            "              2,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([-0.3243], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[  1975,   4754,   1010,  49250,   2077,   1062,   1785,   1593,  18106,\n",
            "           1044,   1729,   3219,   1261,  14146,  64897,  18028,   1307,  22777,\n",
            "           6307,   1046,   3264,  44853,   1455,   2165,   4552,   2405,   9730,\n",
            "           1261,   5275,   2764,   6154,   1505,  14146,   3686,   1046,   1349,\n",
            "           4546,   1455,  15202,   1454,   3946,   8091,   1395,   4878,   1294,\n",
            "           5443,   1454,   5558,  24198,  14976,   1505,   1394,   5751,   5266,\n",
            "           1046,   3886,   1044,   1593,  14146,   2095, 128736,  11495,   2258,\n",
            "           6026,   9576,   1044,   1799,   1395,  29025,   1046,  57454,  14146,\n",
            "           3831,  17942,   7782,   2576,  22482,   1536,  26943,   2283,   1454,\n",
            "          23288,   6026,   1321,   2147,  14146,   9576,   1394,  41562,   1046,\n",
            "           3249,   4546,   1044,   2165,  24372,   1317,   5234,   1278,   3804,\n",
            "           1032,   1050,  35515,   1307,   1278,   3475,   1319,  11018,   4139,\n",
            "           1402,   1261,   4878,   8482,   1809,  35499,   1302,   1577,   9840,\n",
            "           1044,   2156,   1395,   1261,   7693,   1307,   1261,   6309,   2782,\n",
            "          23419,   1294,   1032,   1052,   1050,   1044,   1799,   6122,  38339,\n",
            "           1307,   2269,   5186,   1307, 108681,   1505,  41530,  35821,   5177,\n",
            "           5452,   9734,  12482,   1435,  44761,   1046,   8055,   1044,   4265,\n",
            "           1455,   3686,   2948,  16251,  55705,  12522,  41530,   5032,  14541,\n",
            "          15342,  74045,   1561,   1060,  24613,   1062,   1048,   1046,   1053,\n",
            "           1885,  24613,   1561,   1975,      2,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([-1.8070], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[49250,  2077,  1561,  1784,  3629,  6763, 10982,  1455,  1278, 14146,\n",
            "          4139,  1402,  1261, 41530,  5032,  1562,  1278, 18106,  5662,  1877,\n",
            "          1049,  1046,  1429,  9476,  1605,  6026,  2424,  1046,  7490, 10500,\n",
            "          1278,  3804,  2295, 35515,  1307,  1278,  3475,  2613,  1462,  2409,\n",
            "          7444,  4382, 33144,  1394,  1261,  5270,  3690,  1321, 12551,  1278,\n",
            "          2965,  4139,  1402,  2425,  2300,  1423,  1317, 10500,  1261,  3475,\n",
            "          1435,  1261,  2070, 12754,  1626,  1050,  1046,  1429,  1073,  4552,\n",
            "          2405, 85763,  2258,  7575,  1307,  1261,  2764,  6154,  1034,  1462,\n",
            "          2409, 16054,  2577,  1562,  1278,  5270,  8482,  1307, 11495,  1261,\n",
            "          2764,  6154,  7655,  1626,  1051,  1046,  1429,  1073,  1710,  2405,\n",
            "          9730,  6026,  9576,  1034,  1462,  2409, 29025,  8033, 12551,  1278,\n",
            "         14146,  3120,  1605,  2933,  1317,  9730,  6026,  3686,  1454,  5888,\n",
            "         49209, 11105, 10317,  1626,  1051,  1046,  1531, 55552, 16964, 38576,\n",
            "          2314,  2034,  9916,  2782, 15202,  1294,  1032,  1052,  1050,  1435,\n",
            "          7259,  1307, 11530, 30269,  1044,  1799,  1395,  1420, 29025, 12705,\n",
            "          1317,  1402, 64897,  1626, 16124,  1317,  7061,  1321,  1593,  4369,\n",
            "         18106,  1681,  5965,  1044,  1261, 41530,  5032,  1505,  5888, 49209,\n",
            "         34487,  1317,  4237, 60672,  8352,  1321,  2607,  2405, 85763,  2034,\n",
            "         13006, 11904,  1626, 12598,  2190,  7137,  1278, 29881,  4057,  1408,\n",
            "          2576, 17811,  1261, 14381,  1307, 22240,  1294,  2396,  1046,  1534,\n",
            "          1274,  1561,  1885, 74045,  1561,  1060, 24613,  1561,  1048,  1046,\n",
            "          1055,  1053,  1010,  1885, 24613,  1062,     2,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   3318,   1785,   1278,  16023,  18106,   5662,   1044,\n",
            "           1278,  14146,  13921,   1429,   1073,   4552,   2405,  85763,   2258,\n",
            "           7575,   1307,   1261,   2764,   6154,   2613,   1321,   1429,   1073,\n",
            "           1710,   2405,   9730,   6026,   9576,  27170,   2409,   1395,  48602,\n",
            "           1307,   1261,  57721,  14146,   2274,  10249,   1317,   2121,   1121,\n",
            "          41562,   1536,  35329,   1263,   1372,   1405,  62762,  41562,   9578,\n",
            "          12837,   7125,   1536,  44761,   8616,   2274,   2534,   3508,   1457,\n",
            "           1571,   5130,   6949,   1046,  11796,   1307,   1593,  38530,   6896,\n",
            "           8094,   2405,   1261,   5990,  14146,   8033,   1046,  18244,   1302,\n",
            "          41562,  22777,   2200,  35801,   5449,  75128,  12285,   2405,   9730,\n",
            "           6026,   9576,   1321,  12285,   2405,   3894,   3686,  23288,   1584,\n",
            "           4804,  28061,   1394,  41530,   1046, 106299,   1101,   2095,   1934,\n",
            "           1317,   1576,   1264,   4526,   1419,   1039,   1799,   8806,   2342,\n",
            "          16581,   2200,  17365,   6560,   1402,  35801,   1435,   2156,   1395,\n",
            "           1261,   2534,   1317,  42668,   1261,  22725,  14146,   1046,  22112,\n",
            "          12738,   1394,  75114,   3475,  23288,   2168,   1402,  72010,   4477,\n",
            "           1809,   3226,   1044,   2156,   1681,   1420,   7481,   3686,  52820,\n",
            "          21450,   2016,   1454, 115948,   1278,   3690,   1428,   1039,   9916,\n",
            "           2782,   1681,  24722,  35515,   1321,  75114,   1317,  10500,   1494,\n",
            "           4675,   1348,   1302,   4514, 123170,   1338,  74007,   1681,  24468,\n",
            "           1653,   1605,   9730,  14146,  22777,   1693,   1605,  55188,   1435,\n",
            "           1261,  44761,  14146,   4629,   1562,   7110,  11958,   1626,   1885,\n",
            "          74045,   3318,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   1062,      2,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[  1060,  74045,   1561,  35957,   1408,   1278,  18106,  48787,   5662,\n",
            "           1044,   1278,  14146,  72426,   1317,   9730,   1278,  41562,   3475,\n",
            "           1505,   2258,   2147,  17340,   3686,   1044,   6302,  16350,   1317,\n",
            "           6026,   1278,  41530,  18284,   2645,   2269,   2147,   9129,   1046,\n",
            "           4159,   2095,  33648,   1317,   9730,   2258,   7357,   1505,   6026,\n",
            "           9576,   1307,   1278,   6309,  10594,   1046,   4634,  57721,  26187,\n",
            "           2481,  18191,  10982,   1455,   1278,   2965,   4139,   1402,   6370,\n",
            "           1317,   3940,   1993,  41562,   1505,  41562,  19004,   1046,   5930,\n",
            "           1593,   5315,   1044,   1494,   1395,   4171,   1317,  14649,   1455,\n",
            "           1278,   5315,  29443,   1261,   3435,   2738,  14381,   1435,   1651,\n",
            "           1278,   4145,   1307,  11865,   3686,  13591,   1044,  35801,   1536,\n",
            "          41562,   9129,  24969,   1044,   1321,  10606,   1290,   3686,   7278,\n",
            "           8673,  24465,  77993,  27915,   1626,  75231,   1115,   7540,   1294,\n",
            "          41530,  35821,   5177,   2989,   1501,   1944,   5687,   1278,  14146,\n",
            "           6309,  10594,   1294,  14146,   1045,  37701,   1505,   2767,  50177,\n",
            "           1626,  62477,   1044,   1729,  15646,   1278,  10304,   5163,   5069,\n",
            "           1279,   4014,  45227,   5283,   1321,   1278,   2725,  16805,  17984,\n",
            "           1455,   7389,   1408,  37846,  23668,  84931,  13123,  38666,   1626,\n",
            "         111436,   1278,   3178,   1307,  52819,   1294,  13435,  26187,   1044,\n",
            "           1729,   8497,   1317,  10035,  10960,   3427,  41530,   5032,  48136,\n",
            "          40933,  24613,   1062,   1049,   1885,  24613,   4468,  74045,   1062,\n",
            "              2,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([1.8996], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 20711,   4812,  74045,   1062,   3606,   1605,  11495,   2258,   2081,\n",
            "           4811,   9576,   2314,   1278,   5449,   5677,   1044,  25330,   1278,\n",
            "          14146,   1536,  55890,   4811,   9576,   1799,   1584,  23672,   1317,\n",
            "           1402,  11530,   1319,  10683,   1278,   9916,   2782,  23419,   1294,\n",
            "           1032,   1052,   1050,   1041,   1321, 114813,   1455,   1278,   3804,\n",
            "           2295,  35515,   1307,   1278,   3475,   1402,  11865,   3066,   2258,\n",
            "           4514,   9576,   1584,  11530,  12529,   4116,   1386,   1494,  18267,\n",
            "          15591,   1121,   1046,   8494,   1593,  13578,   4546,   1394,   4514,\n",
            "           3686,   1319,  11018,   2481,  12494,   1402,   9576,   2479,   1278,\n",
            "           4811,   6309,   2782,   1505,   1278,   5275,  74254,   1505,   3804,\n",
            "           1032,   1052,  35515,   1307,   1278,   9916,   2782,   1041,  18267,\n",
            "           1261,   5659,   2081,  19577,   1046,   3797,   2576,   2481,  18191,\n",
            "           3820,   1317,  26943,   2283,   1278,   2937,   1044,   1799,   1486,\n",
            "           5595,   3226,   7423,   1044,   1799,   7510,   1494,   7759,   1261,\n",
            "           5659,   2479,   1261,   5289,  13035,   1046,   9380,   1681,   1925,\n",
            "           4171,  21823,   1044,   2878,   1650,   3369,   1278,   3629,   5305,\n",
            "          23779,   1112,   3318,  54255,   1561,  24187,   1062,  28149,  15776,\n",
            "           5662,   1536,   5150,  24468,   1319,   3265,   6309,  81853,   2653,\n",
            "          16692,   1041,   1435,   1729,   8806,   1653,   1605,   9730,   2516,\n",
            "           3686,   1454,   5888,  14027,  16574,  55890,   1593,  94114,   7091,\n",
            "          15342,   1978,   1561,  24187,   1062,  96436,   1317,   3346,   1278,\n",
            "           3711,   3643, 112910,   1693,   5662,   1317,   1457,  10028,   1278,\n",
            "           5449,   5203,   1885,   1978,   1561,  24187,   1062,  87211,  44384,\n",
            "           3686,   1394,  41562,   3816,  38576,   1307,   1278,  52546,  12460,\n",
            "          22470,  16692,   1486,   3214,  16624,   1307,   2424,   1394,   2948,\n",
            "          12216,  15342,   1978,   1561,  24187,   1062, 124566,   1570,  44016,\n",
            "          86055,  11099,  38791,   5279,   2104,   7928,  15342,   1978,   1561,\n",
            "          24187,   1062,   1784,   3804,   7791,   5662,   1394,   6026,   9576,\n",
            "           1584,  20234,   1420,  54030,   1317,   1278,  24527,  16350,   1455,\n",
            "           2505,   5888,  24926,   1564,   1394,  41562,   2168,   1402, 117467,\n",
            "          15342,   1978,   1561,   1885,   1366,   3318,  47746,   1729,  10500,\n",
            "           1278,  13968,   5662,   1394,   1278,  59128,  18894,   1044,   1536,\n",
            "           4514,  28524,   2203,   1278,   8122,   1338,  20711,   4812,  74045,\n",
            "           1062,   3761,   8110,   1454,  11549,   1501,  59128,   1710,   1402,\n",
            "          79644,  15342,   1112,   1561,  83569,   2516,  19599,   4771,  10098,\n",
            "          11778,   1321,   7185, 111191,   1046,   5930,   1455,   1294,   5759,\n",
            "           1044,   3147,  41530,  29694,   5153,   1736,   2801,  58063,   1319,\n",
            "          46370,   1286,   1408,   3686,  94904,   1321,  24821,  31892,   1317,\n",
            "           4514,  10328,  31901,   1574,   1261,   5659,   1307,   1261,   1429,\n",
            "           1114,   3038,   1034,   8070,  40052,   1429,  73949,   5109,   5370,\n",
            "           3686,   1034,   9896,   2203,   3354,   3226,   1046,   5930,   1836,\n",
            "          41562,   1307,   1278,   3475,   1321,  10718,   1044,   1593,   5966,\n",
            "          18267,   1261,   5659,  15591,   1121,   1044,   1317,   4283,   1494,\n",
            "          63780,   4004,   1338,   1885,  74045,   4468,   1112,   3318,   1060,\n",
            "          24613,   1062,   1048,   1046,   1055,   1053,   1885,  24613,   1062,\n",
            "              2]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}]\n",
            "[2025-10-28 08:41:36 IST] inputs are , {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   3318,   1785,   1278,  16023,  18106,   5662,   1044,\n",
            "           1278,  14146,  13921,   1429,   1073,   4552,   2405,  85763,   2258,\n",
            "           7575,   1307,   1261,   2764,   6154,   2613,   1321,   1429,   1073,\n",
            "           1710,   2405,   9730,   6026,   9576,  27170,   2409,   1395,  48602,\n",
            "           1307,   1261,  57721,  14146,   2274,  10249,   1317,   2121,   1121,\n",
            "          41562,   1536,  35329,   1263,   1372,   1405,  62762,  41562,   9578,\n",
            "          12837,   7125,   1536,  44761,   8616,   2274,   2534,   3508,   1457,\n",
            "           1571,   5130,   6949,   1046,  11796,   1307,   1593,  38530,   6896,\n",
            "           8094,   2405,   1261,   5990,  14146,   8033,   1046,  18244,   1302,\n",
            "          41562,  22777,   2200,  35801,   5449,  75128,  12285,   2405,   9730,\n",
            "           6026,   9576,   1321,  12285,   2405,   3894,   3686,  23288,   1584,\n",
            "           4804,  28061,   1394,  41530,   1046, 106299,   1101,   2095,   1934,\n",
            "           1317,   1576,   1264,   4526,   1419,   1039,   1799,   8806,   2342,\n",
            "          16581,   2200,  17365,   6560,   1402,  35801,   1435,   2156,   1395,\n",
            "           1261,   2534,   1317,  42668,   1261,  22725,  14146,   1046,  22112,\n",
            "          12738,   1394,  75114,   3475,  23288,   2168,   1402,  72010,   4477,\n",
            "           1809,   3226,   1044,   2156,   1681,   1420,   7481,   3686,  52820,\n",
            "          21450,   2016,   1454, 115948,   1278,   3690,   1428,   1039,   9916,\n",
            "           2782,   1681,  24722,  35515,   1321,  75114,   1317,  10500,   1494,\n",
            "           4675,   1348,   1302,   4514, 123170,   1338,  74007,   1681,  24468,\n",
            "           1653,   1605,   9730,  14146,  22777,   1693,   1605,  55188,   1435,\n",
            "           1261,  44761,  14146,   4629,   1562,   7110,  11958,   1626,   1885,\n",
            "          74045,   3318,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   1062,      2,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}\n",
            "[2025-10-28 08:41:36 IST] END _prepare_inputs, keys=['prompt_ids', 'prompt_mask', 'completion_ids', 'completion_mask', 'advantages', 'num_items_in_batch'], prompt_ids.shape=(1, 670), completion_ids.shape=(1, 406)\n",
            "[2025-10-28 08:41:36 IST] ENTER compute_loss, use_liger_loss=False\n",
            "[2025-10-28 08:41:36 IST] ENTER _compute_loss, prompt_ids.shape=(1, 670), completion_ids.shape=(1, 406), loss_type=dapo, beta=0.0, importance_sampling_level=token\n",
            "[2025-10-28 08:41:36 IST] ENTER _get_per_token_logps_and_entropies, input_ids.shape=(1, 1076), attention_mask.shape=(1, 1076), logits_to_keep=406, batch_size=None, compute_entropy=True\n",
            "[2025-10-28 08:41:37 IST] END _get_per_token_logps_and_entropies, logps.shape=(1, 406), entropies=(1, 406)\n",
            "[2025-10-28 08:41:37 IST] END _compute_loss, loss=-0.004492640495300293\n",
            "[2025-10-28 08:41:37 IST] END compute_loss (standard)\n",
            "[2025-10-28 08:41:37 IST] ENTER _prepare_inputs, training=True, _step=710, len_batch=n/a, si_2\n",
            "[2025-10-28 08:41:37 IST] mode is , train\n",
            "[2025-10-28 08:41:37 IST] generate_every 8 = self.args.steps_per_generation 8 * self.num_iterations 1\n",
            "[2025-10-28 08:41:37 IST] self._step is , 710\n",
            "[2025-10-28 08:41:37 IST] self._buffered_inputs , [{'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1062,  11745,   1681,   1278,  38528,   7435,   1278,\n",
            "          14381,  14013,   2100,   1049,   1046,   1603,  20198,  15696,  28196,\n",
            "          30123,   5450,   7506,  46952,  18753,   4139,   1736,   2034,   6026,\n",
            "           9576,  44310,   1420,   6726,   1044,   1809,  12837,   1044,   1278,\n",
            "          34856,   4279,   6354,   2405,  16808,   1317,   1261,  23133,   1457,\n",
            "          63947,   3964,   1317,   1799,   1278,   6309,  10594,   1454,  41530,\n",
            "         122847,   4139,   1402,  25341,  35368,   3686,  23288,  16773,   1338,\n",
            "           1050,   1046,   1603,   3877, 112194,  18244,   5450,   1531,  14146,\n",
            "           6136,   1317,  10500,   1278,   3804,   2295,  35515,   1307,   1261,\n",
            "           4265,   3475,   1321,   1317,  10500,   2034,   9916,   2782,   1809,\n",
            "           4814,   2405,  85763,   1278,   2764,   6154,   1505,   9730,  15115,\n",
            "           6026,   3686,   1046,   2409,   2481,  10982,  86994,   8033,   1338,\n",
            "           1051,   1046,   1603,  99090,  16964,   5450,  11549,   1501,  29694,\n",
            "           5153,   9300,  38291,   1556,   9576,   1046,  23627,   1278, 113361,\n",
            "           8862,  22656,   1294,   1593,  18106,   1044,  46952,  44017,   1505,\n",
            "           5711,  64967,   2481,   1402,   1513,   3354,   1338,   1052,   1046,\n",
            "           1603,   2596, 129571,  14146,  19306,   5450,   2409,   2481,   2095,\n",
            "           3180,   6906,   1455,   1593,   4597,   1934,  46952,  12738,   1317,\n",
            "          21294,   2034,   3475,   1338,  41101,   1455,   3199,   4455,  29025,\n",
            "          16964,   1729,   3081,  77649,   9200,  47210,  18753,   1394,   6309,\n",
            "          31997,   1044,   1809,   1294,   2937,   1307,   4455,  16964,   1044,\n",
            "           1278,  18106,  18267,  23755,  30026,   1321,   2143,   3468,   1307,\n",
            "          13006,   1736,   2738,   5735,   1338,   1062,  34976,   1278,  14381,\n",
            "           1455,   1593,  14146,   1395,   1261,  41530,   5032,   1395,   2100,\n",
            "           1885,  74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,\n",
            "           1053,   1885,  24613,   1062,      2,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,  44296,  20505,  13151,  20505,  13151,  20505,\n",
            "          13151,   1059,  11745,   1395,   1278,   5315,   1307,   1278,   4265,\n",
            "          18106,   1321,   6334,  18106,   6422,  44296,  20505,  13151,  20505,\n",
            "          13151,  20505,  13151,   1059,   1784,   5150,  24468,  18106,   1877,\n",
            "          44296,  20505,  13151,  20505,  13151,  20505,  13151,  20505,  13151,\n",
            "          20505,  13151,   1059,   1045,  16896,   1536,  16798,   1278,   2965,\n",
            "          31912,   1278,   8516,   1317,   5234,  14146,  22777,   1317,   1261,\n",
            "           5888,  49209,  11105,   1394,   8549,  92436,  34493,   1302,   1044,\n",
            "           1799,   7444,  29025,   1321,  35499,   1115,  18119,  10098,  15999,\n",
            "           1319,   1101,   3596,   3109,  41562,  87765,   1584,   7754,   5753,\n",
            "           3214,   5059,   9916,   1505,  79350,   1535,   8426,  11696,   1455,\n",
            "           4771,   1261,   8877,   5449,   4731,   9077,   7265,   8686,   1044,\n",
            "          11396,   9916,  26439,   3475,   1044,   4346,  10098,   2782,   1505,\n",
            "           1395,   3214,   2015,   1307,  35006,   1271,  29398,   1321,  35006,\n",
            "           1401,   3083,   1319,   1982,   1317,   1032,   1050,   1053,  11084,\n",
            "           1294,   9960,  14953,   1041,   4811,   1317,   1455,  17718,   2658,\n",
            "           1046,   1766,   1065,   7537,  10011,   2715,   1402,   3214,   1408,\n",
            "           2606,   2744,   1307,   1278,  29481,   1584,  23834,   5823,   1046,\n",
            "           2820,  44296,  20505,  13151,  20505,  13151,  20505,  13151,  20505,\n",
            "          13151,  20505,  13151,   1059,   1045,  13921,   1455,   1278,  24628,\n",
            "           1934,   1278,  10485,   1307,  30407,   2034,   5449,   1693,  22777,\n",
            "           2607,   2405,   8132,   2424,   1044,   6187,   1593,   7685,   2081,\n",
            "          20702,   1748,  78659,   9500,   1278,   7453,   1307,   1261,  25988,\n",
            "           5449,   1429,  10559,   1660,   1034,   2251,   1010,  44296,  20505,\n",
            "          13151,  20505,  13151,  20505,  13151,  20505,  13151,  20505,  13151,\n",
            "           1059,   1045,  18244,   1115,   1278,  14146,   1317,  21294,   1261,\n",
            "           3475,   1321,   1429,   3715,  85763,   1278,   6960,   2764,   6154,\n",
            "           1897,   1799,   4139,  10982,   1261,   2801,   8967,   1044,   1605,\n",
            "           7655,  67122,   1454,   1278,  11105,   4139,   1402,   6370,   1317,\n",
            "           4731,  11820,   2127,  24598,   2405,  19486,  44296,  20505,  13151,\n",
            "          20505,  13151,  20505,  13151,   1059,   1784,  29049,   1612,   2395,\n",
            "          18106,   1877,  44296,  20505,  13151,  20505,  13151,  20505,  13151,\n",
            "          20505,  13151,  20505,  13151,   1059,   1045,   3316,  16533,   2200,\n",
            "           1278,  14146,  25747,   2314,   1278,   2782,   3144,   6878,   3746,\n",
            "           1420,  29025,   8174,   1321,  40052,   3236,   2965,   6026,   1321,\n",
            "          35801,  11530,   9576,   2251,   1010,  44296,  20505,  13151,  20505,\n",
            "          13151,  20505,  13151,  20505,  13151,  20505,  13151,   1059,   1045,\n",
            "          77291,   2283,  14146,   9452,   9576,   2516,   1435,  14593,   1115,\n",
            "           3508,   1114,   1338,  44296,  20505,  13151,  20505,  13151,  20505,\n",
            "          13151,   1059,  35957,   1408,   1278,  31215,   4455,   1321,   5735,\n",
            "           7981,   1536,   3629,  39945,   1051,   3175,   1486,  12636,   4455,\n",
            "           1044,   1593,  10637,   1010,  10683,   1261,   2937,   1307,   1261,\n",
            "          41530,  35821,   3690,  10119,   1562,   1261,   1010, 111778,  62929,\n",
            "           8967,   1626,   1885,  74045,   3318,   1060,  24613,   1062,   1048,\n",
            "           1046,   1055,   1053,   1885,  24613,   1062,      2,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1062,   1784,  10613,  19263,   1278,  18028,   1307,\n",
            "           1261,  14146,   1681,  13006,   1809,   2156,   1584,   2269,  96580,\n",
            "           1321,   2767,  71348,  15999,   1455,   1653,   1605,  11701,   1454,\n",
            "          15421,  14146,   3471,  15727,   1338,   1049,   1046,   1603,  34126,\n",
            "           1302,   1278,  16544,  10638,  35515,   1307,   1278,  13968,   1438,\n",
            "           1737,   2409,   1395,   9210,  29025,   1046,  57454,   1044,  14146,\n",
            "           3471,   2168,   4772,   4237,   1394,   1278,   6960,   9377,   1505,\n",
            "           3475,   1046,  17934,   1044,   2127,   4139,   4237,   1394,  10098,\n",
            "           8352,   1505,   1535,   8426,  22777,   1435,   1805,   1307,  41562,\n",
            "          40933,   3285,   1561,   1050,   1046,   1603,   1065,   4746,   1302,\n",
            "          15322,   6154,   8867,  17844,   1438,   1737,   1531,  14146, 105562,\n",
            "           8164,   1044,   1429,   1073,   4552,   2405,  85763,   2258,   7575,\n",
            "           1307,   1261,   2764,   6154,   2613,  27923,  13709,  15851,  10098,\n",
            "          11778,   3144,  57010,   1536,   1278,  14146,  40933,   3285,   1561,\n",
            "           1051,   1046,   1603,  83665,   1302,   1394,  29915,  33537,   1438,\n",
            "           1737,   1531,   4546,   1429,  35628,   2034,   9916,   2782,  15202,\n",
            "           1294,   1032,   1052,   1050,   1034,  18267,  57721,   3147,   9916,\n",
            "           8091,   1584,  12837,   5132,   1099,  12341,   1321,   3744,   1046,\n",
            "           3203,   2319,   2487,   6307,  26840,   1505,   5266,   1584,   4289,\n",
            "           6906,  15388,  41530,  35821,   3590,  17859,  24468,   1321,  39393,\n",
            "          94796,  14574,   1099,   3850,   1656,   1046,   1362,   3648,   1278,\n",
            "          18106,   3897, 106299,   1101,   5150,   5700,   3897,  18267,  44761,\n",
            "           1044,   1809,   1278,  15727,  18230,  88087,   5449,  90498,   1044,\n",
            "           2409,  12551,   1278,  10613,   2188,   1605,   1402,  17262,  54348,\n",
            "           1319,  11018,   3120,   1605,  20594,   4204,   1278,   5449,   2782,\n",
            "          10808,   9916,   9576,   1044, 111078,   3686,   3147,  41530,   5032,\n",
            "           1710,  17470,  35420,   5270,  41562,  40933,   3285,   1561,   1052,\n",
            "           1046,   1603, 105801,   2136,   1278,  53247,   1307,  29915,   9837,\n",
            "           1438,   1294,   1534, 100820,  18239,   3085,   1370,   1062,   1729,\n",
            "           9134,   1455,   1278,   3519,  10613,  26723,  57721,   1562,   1261,\n",
            "           9454,   2862,   1307,   3719,   1338,  36296,  15421,  14146,   4810,\n",
            "          16964,   1584,   1605,  21491,   1513,   1265,  31331,  33182,   7357,\n",
            "           9576,   1809,  55890,   2424,   1046,  39321,   5283,   1307,  52819,\n",
            "          10982,   1593,  10613,   2188,   1402,   1805,   1307,   8462,   3846,\n",
            "           1302,   1505,   1513,   3560,   1044,   1261,   2058,   1325,   1338,\n",
            "          93277,   1044,  11735,   1420,  48602,   1032,   2259,  74045,   4812,\n",
            "          24613,   1062,   1048,   1046,   1055,   1885,  14540,  17959,   1736,\n",
            "           2151,   9946,   2754,  40933,   3285,   1561,   1885,  24613,   1062,\n",
            "              2,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([-0.3243], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[  1975,   4754,   1010,  49250,   2077,   1062,   1785,   1593,  18106,\n",
            "           1044,   1729,   3219,   1261,  14146,  64897,  18028,   1307,  22777,\n",
            "           6307,   1046,   3264,  44853,   1455,   2165,   4552,   2405,   9730,\n",
            "           1261,   5275,   2764,   6154,   1505,  14146,   3686,   1046,   1349,\n",
            "           4546,   1455,  15202,   1454,   3946,   8091,   1395,   4878,   1294,\n",
            "           5443,   1454,   5558,  24198,  14976,   1505,   1394,   5751,   5266,\n",
            "           1046,   3886,   1044,   1593,  14146,   2095, 128736,  11495,   2258,\n",
            "           6026,   9576,   1044,   1799,   1395,  29025,   1046,  57454,  14146,\n",
            "           3831,  17942,   7782,   2576,  22482,   1536,  26943,   2283,   1454,\n",
            "          23288,   6026,   1321,   2147,  14146,   9576,   1394,  41562,   1046,\n",
            "           3249,   4546,   1044,   2165,  24372,   1317,   5234,   1278,   3804,\n",
            "           1032,   1050,  35515,   1307,   1278,   3475,   1319,  11018,   4139,\n",
            "           1402,   1261,   4878,   8482,   1809,  35499,   1302,   1577,   9840,\n",
            "           1044,   2156,   1395,   1261,   7693,   1307,   1261,   6309,   2782,\n",
            "          23419,   1294,   1032,   1052,   1050,   1044,   1799,   6122,  38339,\n",
            "           1307,   2269,   5186,   1307, 108681,   1505,  41530,  35821,   5177,\n",
            "           5452,   9734,  12482,   1435,  44761,   1046,   8055,   1044,   4265,\n",
            "           1455,   3686,   2948,  16251,  55705,  12522,  41530,   5032,  14541,\n",
            "          15342,  74045,   1561,   1060,  24613,   1062,   1048,   1046,   1053,\n",
            "           1885,  24613,   1561,   1975,      2,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([-1.8070], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[49250,  2077,  1561,  1784,  3629,  6763, 10982,  1455,  1278, 14146,\n",
            "          4139,  1402,  1261, 41530,  5032,  1562,  1278, 18106,  5662,  1877,\n",
            "          1049,  1046,  1429,  9476,  1605,  6026,  2424,  1046,  7490, 10500,\n",
            "          1278,  3804,  2295, 35515,  1307,  1278,  3475,  2613,  1462,  2409,\n",
            "          7444,  4382, 33144,  1394,  1261,  5270,  3690,  1321, 12551,  1278,\n",
            "          2965,  4139,  1402,  2425,  2300,  1423,  1317, 10500,  1261,  3475,\n",
            "          1435,  1261,  2070, 12754,  1626,  1050,  1046,  1429,  1073,  4552,\n",
            "          2405, 85763,  2258,  7575,  1307,  1261,  2764,  6154,  1034,  1462,\n",
            "          2409, 16054,  2577,  1562,  1278,  5270,  8482,  1307, 11495,  1261,\n",
            "          2764,  6154,  7655,  1626,  1051,  1046,  1429,  1073,  1710,  2405,\n",
            "          9730,  6026,  9576,  1034,  1462,  2409, 29025,  8033, 12551,  1278,\n",
            "         14146,  3120,  1605,  2933,  1317,  9730,  6026,  3686,  1454,  5888,\n",
            "         49209, 11105, 10317,  1626,  1051,  1046,  1531, 55552, 16964, 38576,\n",
            "          2314,  2034,  9916,  2782, 15202,  1294,  1032,  1052,  1050,  1435,\n",
            "          7259,  1307, 11530, 30269,  1044,  1799,  1395,  1420, 29025, 12705,\n",
            "          1317,  1402, 64897,  1626, 16124,  1317,  7061,  1321,  1593,  4369,\n",
            "         18106,  1681,  5965,  1044,  1261, 41530,  5032,  1505,  5888, 49209,\n",
            "         34487,  1317,  4237, 60672,  8352,  1321,  2607,  2405, 85763,  2034,\n",
            "         13006, 11904,  1626, 12598,  2190,  7137,  1278, 29881,  4057,  1408,\n",
            "          2576, 17811,  1261, 14381,  1307, 22240,  1294,  2396,  1046,  1534,\n",
            "          1274,  1561,  1885, 74045,  1561,  1060, 24613,  1561,  1048,  1046,\n",
            "          1055,  1053,  1010,  1885, 24613,  1062,     2,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   3318,   1785,   1278,  16023,  18106,   5662,   1044,\n",
            "           1278,  14146,  13921,   1429,   1073,   4552,   2405,  85763,   2258,\n",
            "           7575,   1307,   1261,   2764,   6154,   2613,   1321,   1429,   1073,\n",
            "           1710,   2405,   9730,   6026,   9576,  27170,   2409,   1395,  48602,\n",
            "           1307,   1261,  57721,  14146,   2274,  10249,   1317,   2121,   1121,\n",
            "          41562,   1536,  35329,   1263,   1372,   1405,  62762,  41562,   9578,\n",
            "          12837,   7125,   1536,  44761,   8616,   2274,   2534,   3508,   1457,\n",
            "           1571,   5130,   6949,   1046,  11796,   1307,   1593,  38530,   6896,\n",
            "           8094,   2405,   1261,   5990,  14146,   8033,   1046,  18244,   1302,\n",
            "          41562,  22777,   2200,  35801,   5449,  75128,  12285,   2405,   9730,\n",
            "           6026,   9576,   1321,  12285,   2405,   3894,   3686,  23288,   1584,\n",
            "           4804,  28061,   1394,  41530,   1046, 106299,   1101,   2095,   1934,\n",
            "           1317,   1576,   1264,   4526,   1419,   1039,   1799,   8806,   2342,\n",
            "          16581,   2200,  17365,   6560,   1402,  35801,   1435,   2156,   1395,\n",
            "           1261,   2534,   1317,  42668,   1261,  22725,  14146,   1046,  22112,\n",
            "          12738,   1394,  75114,   3475,  23288,   2168,   1402,  72010,   4477,\n",
            "           1809,   3226,   1044,   2156,   1681,   1420,   7481,   3686,  52820,\n",
            "          21450,   2016,   1454, 115948,   1278,   3690,   1428,   1039,   9916,\n",
            "           2782,   1681,  24722,  35515,   1321,  75114,   1317,  10500,   1494,\n",
            "           4675,   1348,   1302,   4514, 123170,   1338,  74007,   1681,  24468,\n",
            "           1653,   1605,   9730,  14146,  22777,   1693,   1605,  55188,   1435,\n",
            "           1261,  44761,  14146,   4629,   1562,   7110,  11958,   1626,   1885,\n",
            "          74045,   3318,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   1062,      2,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[  1060,  74045,   1561,  35957,   1408,   1278,  18106,  48787,   5662,\n",
            "           1044,   1278,  14146,  72426,   1317,   9730,   1278,  41562,   3475,\n",
            "           1505,   2258,   2147,  17340,   3686,   1044,   6302,  16350,   1317,\n",
            "           6026,   1278,  41530,  18284,   2645,   2269,   2147,   9129,   1046,\n",
            "           4159,   2095,  33648,   1317,   9730,   2258,   7357,   1505,   6026,\n",
            "           9576,   1307,   1278,   6309,  10594,   1046,   4634,  57721,  26187,\n",
            "           2481,  18191,  10982,   1455,   1278,   2965,   4139,   1402,   6370,\n",
            "           1317,   3940,   1993,  41562,   1505,  41562,  19004,   1046,   5930,\n",
            "           1593,   5315,   1044,   1494,   1395,   4171,   1317,  14649,   1455,\n",
            "           1278,   5315,  29443,   1261,   3435,   2738,  14381,   1435,   1651,\n",
            "           1278,   4145,   1307,  11865,   3686,  13591,   1044,  35801,   1536,\n",
            "          41562,   9129,  24969,   1044,   1321,  10606,   1290,   3686,   7278,\n",
            "           8673,  24465,  77993,  27915,   1626,  75231,   1115,   7540,   1294,\n",
            "          41530,  35821,   5177,   2989,   1501,   1944,   5687,   1278,  14146,\n",
            "           6309,  10594,   1294,  14146,   1045,  37701,   1505,   2767,  50177,\n",
            "           1626,  62477,   1044,   1729,  15646,   1278,  10304,   5163,   5069,\n",
            "           1279,   4014,  45227,   5283,   1321,   1278,   2725,  16805,  17984,\n",
            "           1455,   7389,   1408,  37846,  23668,  84931,  13123,  38666,   1626,\n",
            "         111436,   1278,   3178,   1307,  52819,   1294,  13435,  26187,   1044,\n",
            "           1729,   8497,   1317,  10035,  10960,   3427,  41530,   5032,  48136,\n",
            "          40933,  24613,   1062,   1049,   1885,  24613,   4468,  74045,   1062,\n",
            "              2,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([1.8996], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 20711,   4812,  74045,   1062,   3606,   1605,  11495,   2258,   2081,\n",
            "           4811,   9576,   2314,   1278,   5449,   5677,   1044,  25330,   1278,\n",
            "          14146,   1536,  55890,   4811,   9576,   1799,   1584,  23672,   1317,\n",
            "           1402,  11530,   1319,  10683,   1278,   9916,   2782,  23419,   1294,\n",
            "           1032,   1052,   1050,   1041,   1321, 114813,   1455,   1278,   3804,\n",
            "           2295,  35515,   1307,   1278,   3475,   1402,  11865,   3066,   2258,\n",
            "           4514,   9576,   1584,  11530,  12529,   4116,   1386,   1494,  18267,\n",
            "          15591,   1121,   1046,   8494,   1593,  13578,   4546,   1394,   4514,\n",
            "           3686,   1319,  11018,   2481,  12494,   1402,   9576,   2479,   1278,\n",
            "           4811,   6309,   2782,   1505,   1278,   5275,  74254,   1505,   3804,\n",
            "           1032,   1052,  35515,   1307,   1278,   9916,   2782,   1041,  18267,\n",
            "           1261,   5659,   2081,  19577,   1046,   3797,   2576,   2481,  18191,\n",
            "           3820,   1317,  26943,   2283,   1278,   2937,   1044,   1799,   1486,\n",
            "           5595,   3226,   7423,   1044,   1799,   7510,   1494,   7759,   1261,\n",
            "           5659,   2479,   1261,   5289,  13035,   1046,   9380,   1681,   1925,\n",
            "           4171,  21823,   1044,   2878,   1650,   3369,   1278,   3629,   5305,\n",
            "          23779,   1112,   3318,  54255,   1561,  24187,   1062,  28149,  15776,\n",
            "           5662,   1536,   5150,  24468,   1319,   3265,   6309,  81853,   2653,\n",
            "          16692,   1041,   1435,   1729,   8806,   1653,   1605,   9730,   2516,\n",
            "           3686,   1454,   5888,  14027,  16574,  55890,   1593,  94114,   7091,\n",
            "          15342,   1978,   1561,  24187,   1062,  96436,   1317,   3346,   1278,\n",
            "           3711,   3643, 112910,   1693,   5662,   1317,   1457,  10028,   1278,\n",
            "           5449,   5203,   1885,   1978,   1561,  24187,   1062,  87211,  44384,\n",
            "           3686,   1394,  41562,   3816,  38576,   1307,   1278,  52546,  12460,\n",
            "          22470,  16692,   1486,   3214,  16624,   1307,   2424,   1394,   2948,\n",
            "          12216,  15342,   1978,   1561,  24187,   1062, 124566,   1570,  44016,\n",
            "          86055,  11099,  38791,   5279,   2104,   7928,  15342,   1978,   1561,\n",
            "          24187,   1062,   1784,   3804,   7791,   5662,   1394,   6026,   9576,\n",
            "           1584,  20234,   1420,  54030,   1317,   1278,  24527,  16350,   1455,\n",
            "           2505,   5888,  24926,   1564,   1394,  41562,   2168,   1402, 117467,\n",
            "          15342,   1978,   1561,   1885,   1366,   3318,  47746,   1729,  10500,\n",
            "           1278,  13968,   5662,   1394,   1278,  59128,  18894,   1044,   1536,\n",
            "           4514,  28524,   2203,   1278,   8122,   1338,  20711,   4812,  74045,\n",
            "           1062,   3761,   8110,   1454,  11549,   1501,  59128,   1710,   1402,\n",
            "          79644,  15342,   1112,   1561,  83569,   2516,  19599,   4771,  10098,\n",
            "          11778,   1321,   7185, 111191,   1046,   5930,   1455,   1294,   5759,\n",
            "           1044,   3147,  41530,  29694,   5153,   1736,   2801,  58063,   1319,\n",
            "          46370,   1286,   1408,   3686,  94904,   1321,  24821,  31892,   1317,\n",
            "           4514,  10328,  31901,   1574,   1261,   5659,   1307,   1261,   1429,\n",
            "           1114,   3038,   1034,   8070,  40052,   1429,  73949,   5109,   5370,\n",
            "           3686,   1034,   9896,   2203,   3354,   3226,   1046,   5930,   1836,\n",
            "          41562,   1307,   1278,   3475,   1321,  10718,   1044,   1593,   5966,\n",
            "          18267,   1261,   5659,  15591,   1121,   1044,   1317,   4283,   1494,\n",
            "          63780,   4004,   1338,   1885,  74045,   4468,   1112,   3318,   1060,\n",
            "          24613,   1062,   1048,   1046,   1055,   1053,   1885,  24613,   1062,\n",
            "              2]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}]\n",
            "[2025-10-28 08:41:38 IST] inputs are , {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[  1060,  74045,   1561,  35957,   1408,   1278,  18106,  48787,   5662,\n",
            "           1044,   1278,  14146,  72426,   1317,   9730,   1278,  41562,   3475,\n",
            "           1505,   2258,   2147,  17340,   3686,   1044,   6302,  16350,   1317,\n",
            "           6026,   1278,  41530,  18284,   2645,   2269,   2147,   9129,   1046,\n",
            "           4159,   2095,  33648,   1317,   9730,   2258,   7357,   1505,   6026,\n",
            "           9576,   1307,   1278,   6309,  10594,   1046,   4634,  57721,  26187,\n",
            "           2481,  18191,  10982,   1455,   1278,   2965,   4139,   1402,   6370,\n",
            "           1317,   3940,   1993,  41562,   1505,  41562,  19004,   1046,   5930,\n",
            "           1593,   5315,   1044,   1494,   1395,   4171,   1317,  14649,   1455,\n",
            "           1278,   5315,  29443,   1261,   3435,   2738,  14381,   1435,   1651,\n",
            "           1278,   4145,   1307,  11865,   3686,  13591,   1044,  35801,   1536,\n",
            "          41562,   9129,  24969,   1044,   1321,  10606,   1290,   3686,   7278,\n",
            "           8673,  24465,  77993,  27915,   1626,  75231,   1115,   7540,   1294,\n",
            "          41530,  35821,   5177,   2989,   1501,   1944,   5687,   1278,  14146,\n",
            "           6309,  10594,   1294,  14146,   1045,  37701,   1505,   2767,  50177,\n",
            "           1626,  62477,   1044,   1729,  15646,   1278,  10304,   5163,   5069,\n",
            "           1279,   4014,  45227,   5283,   1321,   1278,   2725,  16805,  17984,\n",
            "           1455,   7389,   1408,  37846,  23668,  84931,  13123,  38666,   1626,\n",
            "         111436,   1278,   3178,   1307,  52819,   1294,  13435,  26187,   1044,\n",
            "           1729,   8497,   1317,  10035,  10960,   3427,  41530,   5032,  48136,\n",
            "          40933,  24613,   1062,   1049,   1885,  24613,   4468,  74045,   1062,\n",
            "              2,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([1.8996], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}\n",
            "[2025-10-28 08:41:38 IST] END _prepare_inputs, keys=['prompt_ids', 'prompt_mask', 'completion_ids', 'completion_mask', 'advantages', 'num_items_in_batch'], prompt_ids.shape=(1, 670), completion_ids.shape=(1, 406)\n",
            "[2025-10-28 08:41:38 IST] ENTER compute_loss, use_liger_loss=False\n",
            "[2025-10-28 08:41:38 IST] ENTER _compute_loss, prompt_ids.shape=(1, 670), completion_ids.shape=(1, 406), loss_type=dapo, beta=0.0, importance_sampling_level=token\n",
            "[2025-10-28 08:41:38 IST] ENTER _get_per_token_logps_and_entropies, input_ids.shape=(1, 1076), attention_mask.shape=(1, 1076), logits_to_keep=406, batch_size=None, compute_entropy=True\n",
            "[2025-10-28 08:41:38 IST] END _get_per_token_logps_and_entropies, logps.shape=(1, 406), entropies=(1, 406)\n",
            "[2025-10-28 08:41:38 IST] END _compute_loss, loss=-0.16586819291114807\n",
            "[2025-10-28 08:41:38 IST] END compute_loss (standard)\n",
            "[2025-10-28 08:41:38 IST] ENTER _prepare_inputs, training=True, _step=711, len_batch=n/a, si_2\n",
            "[2025-10-28 08:41:38 IST] mode is , train\n",
            "[2025-10-28 08:41:38 IST] generate_every 8 = self.args.steps_per_generation 8 * self.num_iterations 1\n",
            "[2025-10-28 08:41:38 IST] self._step is , 711\n",
            "[2025-10-28 08:41:38 IST] self._buffered_inputs , [{'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1062,  11745,   1681,   1278,  38528,   7435,   1278,\n",
            "          14381,  14013,   2100,   1049,   1046,   1603,  20198,  15696,  28196,\n",
            "          30123,   5450,   7506,  46952,  18753,   4139,   1736,   2034,   6026,\n",
            "           9576,  44310,   1420,   6726,   1044,   1809,  12837,   1044,   1278,\n",
            "          34856,   4279,   6354,   2405,  16808,   1317,   1261,  23133,   1457,\n",
            "          63947,   3964,   1317,   1799,   1278,   6309,  10594,   1454,  41530,\n",
            "         122847,   4139,   1402,  25341,  35368,   3686,  23288,  16773,   1338,\n",
            "           1050,   1046,   1603,   3877, 112194,  18244,   5450,   1531,  14146,\n",
            "           6136,   1317,  10500,   1278,   3804,   2295,  35515,   1307,   1261,\n",
            "           4265,   3475,   1321,   1317,  10500,   2034,   9916,   2782,   1809,\n",
            "           4814,   2405,  85763,   1278,   2764,   6154,   1505,   9730,  15115,\n",
            "           6026,   3686,   1046,   2409,   2481,  10982,  86994,   8033,   1338,\n",
            "           1051,   1046,   1603,  99090,  16964,   5450,  11549,   1501,  29694,\n",
            "           5153,   9300,  38291,   1556,   9576,   1046,  23627,   1278, 113361,\n",
            "           8862,  22656,   1294,   1593,  18106,   1044,  46952,  44017,   1505,\n",
            "           5711,  64967,   2481,   1402,   1513,   3354,   1338,   1052,   1046,\n",
            "           1603,   2596, 129571,  14146,  19306,   5450,   2409,   2481,   2095,\n",
            "           3180,   6906,   1455,   1593,   4597,   1934,  46952,  12738,   1317,\n",
            "          21294,   2034,   3475,   1338,  41101,   1455,   3199,   4455,  29025,\n",
            "          16964,   1729,   3081,  77649,   9200,  47210,  18753,   1394,   6309,\n",
            "          31997,   1044,   1809,   1294,   2937,   1307,   4455,  16964,   1044,\n",
            "           1278,  18106,  18267,  23755,  30026,   1321,   2143,   3468,   1307,\n",
            "          13006,   1736,   2738,   5735,   1338,   1062,  34976,   1278,  14381,\n",
            "           1455,   1593,  14146,   1395,   1261,  41530,   5032,   1395,   2100,\n",
            "           1885,  74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,\n",
            "           1053,   1885,  24613,   1062,      2,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,  44296,  20505,  13151,  20505,  13151,  20505,\n",
            "          13151,   1059,  11745,   1395,   1278,   5315,   1307,   1278,   4265,\n",
            "          18106,   1321,   6334,  18106,   6422,  44296,  20505,  13151,  20505,\n",
            "          13151,  20505,  13151,   1059,   1784,   5150,  24468,  18106,   1877,\n",
            "          44296,  20505,  13151,  20505,  13151,  20505,  13151,  20505,  13151,\n",
            "          20505,  13151,   1059,   1045,  16896,   1536,  16798,   1278,   2965,\n",
            "          31912,   1278,   8516,   1317,   5234,  14146,  22777,   1317,   1261,\n",
            "           5888,  49209,  11105,   1394,   8549,  92436,  34493,   1302,   1044,\n",
            "           1799,   7444,  29025,   1321,  35499,   1115,  18119,  10098,  15999,\n",
            "           1319,   1101,   3596,   3109,  41562,  87765,   1584,   7754,   5753,\n",
            "           3214,   5059,   9916,   1505,  79350,   1535,   8426,  11696,   1455,\n",
            "           4771,   1261,   8877,   5449,   4731,   9077,   7265,   8686,   1044,\n",
            "          11396,   9916,  26439,   3475,   1044,   4346,  10098,   2782,   1505,\n",
            "           1395,   3214,   2015,   1307,  35006,   1271,  29398,   1321,  35006,\n",
            "           1401,   3083,   1319,   1982,   1317,   1032,   1050,   1053,  11084,\n",
            "           1294,   9960,  14953,   1041,   4811,   1317,   1455,  17718,   2658,\n",
            "           1046,   1766,   1065,   7537,  10011,   2715,   1402,   3214,   1408,\n",
            "           2606,   2744,   1307,   1278,  29481,   1584,  23834,   5823,   1046,\n",
            "           2820,  44296,  20505,  13151,  20505,  13151,  20505,  13151,  20505,\n",
            "          13151,  20505,  13151,   1059,   1045,  13921,   1455,   1278,  24628,\n",
            "           1934,   1278,  10485,   1307,  30407,   2034,   5449,   1693,  22777,\n",
            "           2607,   2405,   8132,   2424,   1044,   6187,   1593,   7685,   2081,\n",
            "          20702,   1748,  78659,   9500,   1278,   7453,   1307,   1261,  25988,\n",
            "           5449,   1429,  10559,   1660,   1034,   2251,   1010,  44296,  20505,\n",
            "          13151,  20505,  13151,  20505,  13151,  20505,  13151,  20505,  13151,\n",
            "           1059,   1045,  18244,   1115,   1278,  14146,   1317,  21294,   1261,\n",
            "           3475,   1321,   1429,   3715,  85763,   1278,   6960,   2764,   6154,\n",
            "           1897,   1799,   4139,  10982,   1261,   2801,   8967,   1044,   1605,\n",
            "           7655,  67122,   1454,   1278,  11105,   4139,   1402,   6370,   1317,\n",
            "           4731,  11820,   2127,  24598,   2405,  19486,  44296,  20505,  13151,\n",
            "          20505,  13151,  20505,  13151,   1059,   1784,  29049,   1612,   2395,\n",
            "          18106,   1877,  44296,  20505,  13151,  20505,  13151,  20505,  13151,\n",
            "          20505,  13151,  20505,  13151,   1059,   1045,   3316,  16533,   2200,\n",
            "           1278,  14146,  25747,   2314,   1278,   2782,   3144,   6878,   3746,\n",
            "           1420,  29025,   8174,   1321,  40052,   3236,   2965,   6026,   1321,\n",
            "          35801,  11530,   9576,   2251,   1010,  44296,  20505,  13151,  20505,\n",
            "          13151,  20505,  13151,  20505,  13151,  20505,  13151,   1059,   1045,\n",
            "          77291,   2283,  14146,   9452,   9576,   2516,   1435,  14593,   1115,\n",
            "           3508,   1114,   1338,  44296,  20505,  13151,  20505,  13151,  20505,\n",
            "          13151,   1059,  35957,   1408,   1278,  31215,   4455,   1321,   5735,\n",
            "           7981,   1536,   3629,  39945,   1051,   3175,   1486,  12636,   4455,\n",
            "           1044,   1593,  10637,   1010,  10683,   1261,   2937,   1307,   1261,\n",
            "          41530,  35821,   3690,  10119,   1562,   1261,   1010, 111778,  62929,\n",
            "           8967,   1626,   1885,  74045,   3318,   1060,  24613,   1062,   1048,\n",
            "           1046,   1055,   1053,   1885,  24613,   1062,      2,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1062,   1784,  10613,  19263,   1278,  18028,   1307,\n",
            "           1261,  14146,   1681,  13006,   1809,   2156,   1584,   2269,  96580,\n",
            "           1321,   2767,  71348,  15999,   1455,   1653,   1605,  11701,   1454,\n",
            "          15421,  14146,   3471,  15727,   1338,   1049,   1046,   1603,  34126,\n",
            "           1302,   1278,  16544,  10638,  35515,   1307,   1278,  13968,   1438,\n",
            "           1737,   2409,   1395,   9210,  29025,   1046,  57454,   1044,  14146,\n",
            "           3471,   2168,   4772,   4237,   1394,   1278,   6960,   9377,   1505,\n",
            "           3475,   1046,  17934,   1044,   2127,   4139,   4237,   1394,  10098,\n",
            "           8352,   1505,   1535,   8426,  22777,   1435,   1805,   1307,  41562,\n",
            "          40933,   3285,   1561,   1050,   1046,   1603,   1065,   4746,   1302,\n",
            "          15322,   6154,   8867,  17844,   1438,   1737,   1531,  14146, 105562,\n",
            "           8164,   1044,   1429,   1073,   4552,   2405,  85763,   2258,   7575,\n",
            "           1307,   1261,   2764,   6154,   2613,  27923,  13709,  15851,  10098,\n",
            "          11778,   3144,  57010,   1536,   1278,  14146,  40933,   3285,   1561,\n",
            "           1051,   1046,   1603,  83665,   1302,   1394,  29915,  33537,   1438,\n",
            "           1737,   1531,   4546,   1429,  35628,   2034,   9916,   2782,  15202,\n",
            "           1294,   1032,   1052,   1050,   1034,  18267,  57721,   3147,   9916,\n",
            "           8091,   1584,  12837,   5132,   1099,  12341,   1321,   3744,   1046,\n",
            "           3203,   2319,   2487,   6307,  26840,   1505,   5266,   1584,   4289,\n",
            "           6906,  15388,  41530,  35821,   3590,  17859,  24468,   1321,  39393,\n",
            "          94796,  14574,   1099,   3850,   1656,   1046,   1362,   3648,   1278,\n",
            "          18106,   3897, 106299,   1101,   5150,   5700,   3897,  18267,  44761,\n",
            "           1044,   1809,   1278,  15727,  18230,  88087,   5449,  90498,   1044,\n",
            "           2409,  12551,   1278,  10613,   2188,   1605,   1402,  17262,  54348,\n",
            "           1319,  11018,   3120,   1605,  20594,   4204,   1278,   5449,   2782,\n",
            "          10808,   9916,   9576,   1044, 111078,   3686,   3147,  41530,   5032,\n",
            "           1710,  17470,  35420,   5270,  41562,  40933,   3285,   1561,   1052,\n",
            "           1046,   1603, 105801,   2136,   1278,  53247,   1307,  29915,   9837,\n",
            "           1438,   1294,   1534, 100820,  18239,   3085,   1370,   1062,   1729,\n",
            "           9134,   1455,   1278,   3519,  10613,  26723,  57721,   1562,   1261,\n",
            "           9454,   2862,   1307,   3719,   1338,  36296,  15421,  14146,   4810,\n",
            "          16964,   1584,   1605,  21491,   1513,   1265,  31331,  33182,   7357,\n",
            "           9576,   1809,  55890,   2424,   1046,  39321,   5283,   1307,  52819,\n",
            "          10982,   1593,  10613,   2188,   1402,   1805,   1307,   8462,   3846,\n",
            "           1302,   1505,   1513,   3560,   1044,   1261,   2058,   1325,   1338,\n",
            "          93277,   1044,  11735,   1420,  48602,   1032,   2259,  74045,   4812,\n",
            "          24613,   1062,   1048,   1046,   1055,   1885,  14540,  17959,   1736,\n",
            "           2151,   9946,   2754,  40933,   3285,   1561,   1885,  24613,   1062,\n",
            "              2,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([-0.3243], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[  1975,   4754,   1010,  49250,   2077,   1062,   1785,   1593,  18106,\n",
            "           1044,   1729,   3219,   1261,  14146,  64897,  18028,   1307,  22777,\n",
            "           6307,   1046,   3264,  44853,   1455,   2165,   4552,   2405,   9730,\n",
            "           1261,   5275,   2764,   6154,   1505,  14146,   3686,   1046,   1349,\n",
            "           4546,   1455,  15202,   1454,   3946,   8091,   1395,   4878,   1294,\n",
            "           5443,   1454,   5558,  24198,  14976,   1505,   1394,   5751,   5266,\n",
            "           1046,   3886,   1044,   1593,  14146,   2095, 128736,  11495,   2258,\n",
            "           6026,   9576,   1044,   1799,   1395,  29025,   1046,  57454,  14146,\n",
            "           3831,  17942,   7782,   2576,  22482,   1536,  26943,   2283,   1454,\n",
            "          23288,   6026,   1321,   2147,  14146,   9576,   1394,  41562,   1046,\n",
            "           3249,   4546,   1044,   2165,  24372,   1317,   5234,   1278,   3804,\n",
            "           1032,   1050,  35515,   1307,   1278,   3475,   1319,  11018,   4139,\n",
            "           1402,   1261,   4878,   8482,   1809,  35499,   1302,   1577,   9840,\n",
            "           1044,   2156,   1395,   1261,   7693,   1307,   1261,   6309,   2782,\n",
            "          23419,   1294,   1032,   1052,   1050,   1044,   1799,   6122,  38339,\n",
            "           1307,   2269,   5186,   1307, 108681,   1505,  41530,  35821,   5177,\n",
            "           5452,   9734,  12482,   1435,  44761,   1046,   8055,   1044,   4265,\n",
            "           1455,   3686,   2948,  16251,  55705,  12522,  41530,   5032,  14541,\n",
            "          15342,  74045,   1561,   1060,  24613,   1062,   1048,   1046,   1053,\n",
            "           1885,  24613,   1561,   1975,      2,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([-1.8070], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[49250,  2077,  1561,  1784,  3629,  6763, 10982,  1455,  1278, 14146,\n",
            "          4139,  1402,  1261, 41530,  5032,  1562,  1278, 18106,  5662,  1877,\n",
            "          1049,  1046,  1429,  9476,  1605,  6026,  2424,  1046,  7490, 10500,\n",
            "          1278,  3804,  2295, 35515,  1307,  1278,  3475,  2613,  1462,  2409,\n",
            "          7444,  4382, 33144,  1394,  1261,  5270,  3690,  1321, 12551,  1278,\n",
            "          2965,  4139,  1402,  2425,  2300,  1423,  1317, 10500,  1261,  3475,\n",
            "          1435,  1261,  2070, 12754,  1626,  1050,  1046,  1429,  1073,  4552,\n",
            "          2405, 85763,  2258,  7575,  1307,  1261,  2764,  6154,  1034,  1462,\n",
            "          2409, 16054,  2577,  1562,  1278,  5270,  8482,  1307, 11495,  1261,\n",
            "          2764,  6154,  7655,  1626,  1051,  1046,  1429,  1073,  1710,  2405,\n",
            "          9730,  6026,  9576,  1034,  1462,  2409, 29025,  8033, 12551,  1278,\n",
            "         14146,  3120,  1605,  2933,  1317,  9730,  6026,  3686,  1454,  5888,\n",
            "         49209, 11105, 10317,  1626,  1051,  1046,  1531, 55552, 16964, 38576,\n",
            "          2314,  2034,  9916,  2782, 15202,  1294,  1032,  1052,  1050,  1435,\n",
            "          7259,  1307, 11530, 30269,  1044,  1799,  1395,  1420, 29025, 12705,\n",
            "          1317,  1402, 64897,  1626, 16124,  1317,  7061,  1321,  1593,  4369,\n",
            "         18106,  1681,  5965,  1044,  1261, 41530,  5032,  1505,  5888, 49209,\n",
            "         34487,  1317,  4237, 60672,  8352,  1321,  2607,  2405, 85763,  2034,\n",
            "         13006, 11904,  1626, 12598,  2190,  7137,  1278, 29881,  4057,  1408,\n",
            "          2576, 17811,  1261, 14381,  1307, 22240,  1294,  2396,  1046,  1534,\n",
            "          1274,  1561,  1885, 74045,  1561,  1060, 24613,  1561,  1048,  1046,\n",
            "          1055,  1053,  1010,  1885, 24613,  1062,     2,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   3318,   1785,   1278,  16023,  18106,   5662,   1044,\n",
            "           1278,  14146,  13921,   1429,   1073,   4552,   2405,  85763,   2258,\n",
            "           7575,   1307,   1261,   2764,   6154,   2613,   1321,   1429,   1073,\n",
            "           1710,   2405,   9730,   6026,   9576,  27170,   2409,   1395,  48602,\n",
            "           1307,   1261,  57721,  14146,   2274,  10249,   1317,   2121,   1121,\n",
            "          41562,   1536,  35329,   1263,   1372,   1405,  62762,  41562,   9578,\n",
            "          12837,   7125,   1536,  44761,   8616,   2274,   2534,   3508,   1457,\n",
            "           1571,   5130,   6949,   1046,  11796,   1307,   1593,  38530,   6896,\n",
            "           8094,   2405,   1261,   5990,  14146,   8033,   1046,  18244,   1302,\n",
            "          41562,  22777,   2200,  35801,   5449,  75128,  12285,   2405,   9730,\n",
            "           6026,   9576,   1321,  12285,   2405,   3894,   3686,  23288,   1584,\n",
            "           4804,  28061,   1394,  41530,   1046, 106299,   1101,   2095,   1934,\n",
            "           1317,   1576,   1264,   4526,   1419,   1039,   1799,   8806,   2342,\n",
            "          16581,   2200,  17365,   6560,   1402,  35801,   1435,   2156,   1395,\n",
            "           1261,   2534,   1317,  42668,   1261,  22725,  14146,   1046,  22112,\n",
            "          12738,   1394,  75114,   3475,  23288,   2168,   1402,  72010,   4477,\n",
            "           1809,   3226,   1044,   2156,   1681,   1420,   7481,   3686,  52820,\n",
            "          21450,   2016,   1454, 115948,   1278,   3690,   1428,   1039,   9916,\n",
            "           2782,   1681,  24722,  35515,   1321,  75114,   1317,  10500,   1494,\n",
            "           4675,   1348,   1302,   4514, 123170,   1338,  74007,   1681,  24468,\n",
            "           1653,   1605,   9730,  14146,  22777,   1693,   1605,  55188,   1435,\n",
            "           1261,  44761,  14146,   4629,   1562,   7110,  11958,   1626,   1885,\n",
            "          74045,   3318,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   1062,      2,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[  1060,  74045,   1561,  35957,   1408,   1278,  18106,  48787,   5662,\n",
            "           1044,   1278,  14146,  72426,   1317,   9730,   1278,  41562,   3475,\n",
            "           1505,   2258,   2147,  17340,   3686,   1044,   6302,  16350,   1317,\n",
            "           6026,   1278,  41530,  18284,   2645,   2269,   2147,   9129,   1046,\n",
            "           4159,   2095,  33648,   1317,   9730,   2258,   7357,   1505,   6026,\n",
            "           9576,   1307,   1278,   6309,  10594,   1046,   4634,  57721,  26187,\n",
            "           2481,  18191,  10982,   1455,   1278,   2965,   4139,   1402,   6370,\n",
            "           1317,   3940,   1993,  41562,   1505,  41562,  19004,   1046,   5930,\n",
            "           1593,   5315,   1044,   1494,   1395,   4171,   1317,  14649,   1455,\n",
            "           1278,   5315,  29443,   1261,   3435,   2738,  14381,   1435,   1651,\n",
            "           1278,   4145,   1307,  11865,   3686,  13591,   1044,  35801,   1536,\n",
            "          41562,   9129,  24969,   1044,   1321,  10606,   1290,   3686,   7278,\n",
            "           8673,  24465,  77993,  27915,   1626,  75231,   1115,   7540,   1294,\n",
            "          41530,  35821,   5177,   2989,   1501,   1944,   5687,   1278,  14146,\n",
            "           6309,  10594,   1294,  14146,   1045,  37701,   1505,   2767,  50177,\n",
            "           1626,  62477,   1044,   1729,  15646,   1278,  10304,   5163,   5069,\n",
            "           1279,   4014,  45227,   5283,   1321,   1278,   2725,  16805,  17984,\n",
            "           1455,   7389,   1408,  37846,  23668,  84931,  13123,  38666,   1626,\n",
            "         111436,   1278,   3178,   1307,  52819,   1294,  13435,  26187,   1044,\n",
            "           1729,   8497,   1317,  10035,  10960,   3427,  41530,   5032,  48136,\n",
            "          40933,  24613,   1062,   1049,   1885,  24613,   4468,  74045,   1062,\n",
            "              2,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'advantages': tensor([1.8996], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 20711,   4812,  74045,   1062,   3606,   1605,  11495,   2258,   2081,\n",
            "           4811,   9576,   2314,   1278,   5449,   5677,   1044,  25330,   1278,\n",
            "          14146,   1536,  55890,   4811,   9576,   1799,   1584,  23672,   1317,\n",
            "           1402,  11530,   1319,  10683,   1278,   9916,   2782,  23419,   1294,\n",
            "           1032,   1052,   1050,   1041,   1321, 114813,   1455,   1278,   3804,\n",
            "           2295,  35515,   1307,   1278,   3475,   1402,  11865,   3066,   2258,\n",
            "           4514,   9576,   1584,  11530,  12529,   4116,   1386,   1494,  18267,\n",
            "          15591,   1121,   1046,   8494,   1593,  13578,   4546,   1394,   4514,\n",
            "           3686,   1319,  11018,   2481,  12494,   1402,   9576,   2479,   1278,\n",
            "           4811,   6309,   2782,   1505,   1278,   5275,  74254,   1505,   3804,\n",
            "           1032,   1052,  35515,   1307,   1278,   9916,   2782,   1041,  18267,\n",
            "           1261,   5659,   2081,  19577,   1046,   3797,   2576,   2481,  18191,\n",
            "           3820,   1317,  26943,   2283,   1278,   2937,   1044,   1799,   1486,\n",
            "           5595,   3226,   7423,   1044,   1799,   7510,   1494,   7759,   1261,\n",
            "           5659,   2479,   1261,   5289,  13035,   1046,   9380,   1681,   1925,\n",
            "           4171,  21823,   1044,   2878,   1650,   3369,   1278,   3629,   5305,\n",
            "          23779,   1112,   3318,  54255,   1561,  24187,   1062,  28149,  15776,\n",
            "           5662,   1536,   5150,  24468,   1319,   3265,   6309,  81853,   2653,\n",
            "          16692,   1041,   1435,   1729,   8806,   1653,   1605,   9730,   2516,\n",
            "           3686,   1454,   5888,  14027,  16574,  55890,   1593,  94114,   7091,\n",
            "          15342,   1978,   1561,  24187,   1062,  96436,   1317,   3346,   1278,\n",
            "           3711,   3643, 112910,   1693,   5662,   1317,   1457,  10028,   1278,\n",
            "           5449,   5203,   1885,   1978,   1561,  24187,   1062,  87211,  44384,\n",
            "           3686,   1394,  41562,   3816,  38576,   1307,   1278,  52546,  12460,\n",
            "          22470,  16692,   1486,   3214,  16624,   1307,   2424,   1394,   2948,\n",
            "          12216,  15342,   1978,   1561,  24187,   1062, 124566,   1570,  44016,\n",
            "          86055,  11099,  38791,   5279,   2104,   7928,  15342,   1978,   1561,\n",
            "          24187,   1062,   1784,   3804,   7791,   5662,   1394,   6026,   9576,\n",
            "           1584,  20234,   1420,  54030,   1317,   1278,  24527,  16350,   1455,\n",
            "           2505,   5888,  24926,   1564,   1394,  41562,   2168,   1402, 117467,\n",
            "          15342,   1978,   1561,   1885,   1366,   3318,  47746,   1729,  10500,\n",
            "           1278,  13968,   5662,   1394,   1278,  59128,  18894,   1044,   1536,\n",
            "           4514,  28524,   2203,   1278,   8122,   1338,  20711,   4812,  74045,\n",
            "           1062,   3761,   8110,   1454,  11549,   1501,  59128,   1710,   1402,\n",
            "          79644,  15342,   1112,   1561,  83569,   2516,  19599,   4771,  10098,\n",
            "          11778,   1321,   7185, 111191,   1046,   5930,   1455,   1294,   5759,\n",
            "           1044,   3147,  41530,  29694,   5153,   1736,   2801,  58063,   1319,\n",
            "          46370,   1286,   1408,   3686,  94904,   1321,  24821,  31892,   1317,\n",
            "           4514,  10328,  31901,   1574,   1261,   5659,   1307,   1261,   1429,\n",
            "           1114,   3038,   1034,   8070,  40052,   1429,  73949,   5109,   5370,\n",
            "           3686,   1034,   9896,   2203,   3354,   3226,   1046,   5930,   1836,\n",
            "          41562,   1307,   1278,   3475,   1321,  10718,   1044,   1593,   5966,\n",
            "          18267,   1261,   5659,  15591,   1121,   1044,   1317,   4283,   1494,\n",
            "          63780,   4004,   1338,   1885,  74045,   4468,   1112,   3318,   1060,\n",
            "          24613,   1062,   1048,   1046,   1055,   1053,   1885,  24613,   1062,\n",
            "              2]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}]\n",
            "[2025-10-28 08:41:39 IST] inputs are , {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044, 106299,   1101,  21371,   1046,   2409,   1395,  29049,   1612,\n",
            "           2395,  11549,   1501,   1535,   1822,   1046,   2837,   6185,  34493,\n",
            "           1302,   8549,  92436,   1408,   1261,  11530,  14146,   1046,  18228,\n",
            "           1639,   1278,  41562,  22777,   2127,   6185,  12946,   1878,   1729,\n",
            "           1710,   1457,  10028,   2034,   5449,   1046,   2837,   2607,   2405,\n",
            "           9730,   2764, 104297,   1505,  14146,   3686,   1454,   5888,  14027,\n",
            "           1046,   3367,   2156,   1681,   1261,   6553,   1044,  10678,   1736,\n",
            "           1278,   6309,  10594,   6026,   1650,   7655,   2505,   1278,   2782,\n",
            "           1408,   1278,   2595,   1307,   2034,   6309,   1046,   4159,   6185,\n",
            "          72351,   1046,   3367,   1636,   2607,   2405,   5628,   1639,   1278,\n",
            "          22777,   1044,   2034,   5449,  10714,  27812,   1321,   1636,   7534,\n",
            "           1402,  12378,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'completion_ids': tensor([[ 20711,   4812,  74045,   1062,   3606,   1605,  11495,   2258,   2081,\n",
            "           4811,   9576,   2314,   1278,   5449,   5677,   1044,  25330,   1278,\n",
            "          14146,   1536,  55890,   4811,   9576,   1799,   1584,  23672,   1317,\n",
            "           1402,  11530,   1319,  10683,   1278,   9916,   2782,  23419,   1294,\n",
            "           1032,   1052,   1050,   1041,   1321, 114813,   1455,   1278,   3804,\n",
            "           2295,  35515,   1307,   1278,   3475,   1402,  11865,   3066,   2258,\n",
            "           4514,   9576,   1584,  11530,  12529,   4116,   1386,   1494,  18267,\n",
            "          15591,   1121,   1046,   8494,   1593,  13578,   4546,   1394,   4514,\n",
            "           3686,   1319,  11018,   2481,  12494,   1402,   9576,   2479,   1278,\n",
            "           4811,   6309,   2782,   1505,   1278,   5275,  74254,   1505,   3804,\n",
            "           1032,   1052,  35515,   1307,   1278,   9916,   2782,   1041,  18267,\n",
            "           1261,   5659,   2081,  19577,   1046,   3797,   2576,   2481,  18191,\n",
            "           3820,   1317,  26943,   2283,   1278,   2937,   1044,   1799,   1486,\n",
            "           5595,   3226,   7423,   1044,   1799,   7510,   1494,   7759,   1261,\n",
            "           5659,   2479,   1261,   5289,  13035,   1046,   9380,   1681,   1925,\n",
            "           4171,  21823,   1044,   2878,   1650,   3369,   1278,   3629,   5305,\n",
            "          23779,   1112,   3318,  54255,   1561,  24187,   1062,  28149,  15776,\n",
            "           5662,   1536,   5150,  24468,   1319,   3265,   6309,  81853,   2653,\n",
            "          16692,   1041,   1435,   1729,   8806,   1653,   1605,   9730,   2516,\n",
            "           3686,   1454,   5888,  14027,  16574,  55890,   1593,  94114,   7091,\n",
            "          15342,   1978,   1561,  24187,   1062,  96436,   1317,   3346,   1278,\n",
            "           3711,   3643, 112910,   1693,   5662,   1317,   1457,  10028,   1278,\n",
            "           5449,   5203,   1885,   1978,   1561,  24187,   1062,  87211,  44384,\n",
            "           3686,   1394,  41562,   3816,  38576,   1307,   1278,  52546,  12460,\n",
            "          22470,  16692,   1486,   3214,  16624,   1307,   2424,   1394,   2948,\n",
            "          12216,  15342,   1978,   1561,  24187,   1062, 124566,   1570,  44016,\n",
            "          86055,  11099,  38791,   5279,   2104,   7928,  15342,   1978,   1561,\n",
            "          24187,   1062,   1784,   3804,   7791,   5662,   1394,   6026,   9576,\n",
            "           1584,  20234,   1420,  54030,   1317,   1278,  24527,  16350,   1455,\n",
            "           2505,   5888,  24926,   1564,   1394,  41562,   2168,   1402, 117467,\n",
            "          15342,   1978,   1561,   1885,   1366,   3318,  47746,   1729,  10500,\n",
            "           1278,  13968,   5662,   1394,   1278,  59128,  18894,   1044,   1536,\n",
            "           4514,  28524,   2203,   1278,   8122,   1338,  20711,   4812,  74045,\n",
            "           1062,   3761,   8110,   1454,  11549,   1501,  59128,   1710,   1402,\n",
            "          79644,  15342,   1112,   1561,  83569,   2516,  19599,   4771,  10098,\n",
            "          11778,   1321,   7185, 111191,   1046,   5930,   1455,   1294,   5759,\n",
            "           1044,   3147,  41530,  29694,   5153,   1736,   2801,  58063,   1319,\n",
            "          46370,   1286,   1408,   3686,  94904,   1321,  24821,  31892,   1317,\n",
            "           4514,  10328,  31901,   1574,   1261,   5659,   1307,   1261,   1429,\n",
            "           1114,   3038,   1034,   8070,  40052,   1429,  73949,   5109,   5370,\n",
            "           3686,   1034,   9896,   2203,   3354,   3226,   1046,   5930,   1836,\n",
            "          41562,   1307,   1278,   3475,   1321,  10718,   1044,   1593,   5966,\n",
            "          18267,   1261,   5659,  15591,   1121,   1044,   1317,   4283,   1494,\n",
            "          63780,   4004,   1338,   1885,  74045,   4468,   1112,   3318,   1060,\n",
            "          24613,   1062,   1048,   1046,   1055,   1053,   1885,  24613,   1062,\n",
            "              2]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0'), 'advantages': tensor([0.0463], device='cuda:0'), 'num_items_in_batch': tensor(2176, device='cuda:0')}\n",
            "[2025-10-28 08:41:39 IST] END _prepare_inputs, keys=['prompt_ids', 'prompt_mask', 'completion_ids', 'completion_mask', 'advantages', 'num_items_in_batch'], prompt_ids.shape=(1, 670), completion_ids.shape=(1, 406)\n",
            "[2025-10-28 08:41:39 IST] ENTER compute_loss, use_liger_loss=False\n",
            "[2025-10-28 08:41:39 IST] ENTER _compute_loss, prompt_ids.shape=(1, 670), completion_ids.shape=(1, 406), loss_type=dapo, beta=0.0, importance_sampling_level=token\n",
            "[2025-10-28 08:41:39 IST] ENTER _get_per_token_logps_and_entropies, input_ids.shape=(1, 1076), attention_mask.shape=(1, 1076), logits_to_keep=406, batch_size=None, compute_entropy=True\n",
            "[2025-10-28 08:41:39 IST] END _get_per_token_logps_and_entropies, logps.shape=(1, 406), entropies=(1, 406)\n",
            "[2025-10-28 08:41:39 IST] END _compute_loss, loss=-0.008644606918096542\n",
            "[2025-10-28 08:41:39 IST] END compute_loss (standard)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [245/245 3:25:49, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>-0.278000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>-0.029100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>-0.051600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.055900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>-0.012000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>-0.035400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.237200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.056600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.414900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.254900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>-0.107800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.121900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>-0.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.073100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>-0.145300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.222400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>-0.194800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>-0.185500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.247200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.024000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.090300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.288200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.210800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.801800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>-0.266800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>-0.028300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.011200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>-0.150800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.645100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>-0.020300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>-0.153000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>-0.368200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.065900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>-0.017200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.071500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.074100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.635600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>-0.059100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.191800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>-0.025300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.060300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.295200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>-0.135600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>-0.029000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.157200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.184000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>-0.030300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>-0.135700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.069700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.196300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>-0.148800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.259400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>-0.260100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.186000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.068800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.137700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>-0.139100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.137300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.378800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.023500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.466200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>-0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.032300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.162000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.087000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.316300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>-0.163000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.121200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>-0.022900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.112100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.101200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.182900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.369600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>-0.061000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.097300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>-0.011600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.138600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>-0.231200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>-0.051400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.169400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.016700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.277400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.111800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.756000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.063600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.177000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.070700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.052300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.340700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.109300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>-0.132300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.039600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>-0.098500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>-0.096200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.100700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.133900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>-0.073000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.171400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.357800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>0.008500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>0.076200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>0.312400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>0.148100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>-0.241900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>-0.162000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>-0.024200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>-0.088000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>-0.088800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>-0.178000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>0.053000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>-0.107700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>-0.007700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>0.121400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>-0.148900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>0.246400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>0.276500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>-0.121500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>-0.011800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>0.109400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>0.350600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>0.171700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>-0.016700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>-0.324300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>0.035700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>-0.192800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>-0.220500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>0.067700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>-0.142800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>0.070000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>-0.077000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>0.459600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>-0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>0.318900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>0.554500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>0.014300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>0.178000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>-0.013000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.040700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>0.151100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>-0.206900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>0.029900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>0.242800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>-0.009400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>0.029900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>0.132000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>-0.059300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>0.355500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>-0.299900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>-0.145000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>0.168500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>0.143400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>0.187000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.053600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>0.320700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>0.159400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>0.109600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>-0.252800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.120500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>-0.349300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>-0.096000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>-0.363900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>0.082200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>-0.065000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>0.178200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>0.165200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>-0.139400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>0.170200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.552400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>0.034100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>-0.164700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>0.217700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>0.086000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.205500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>-0.064600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>0.172400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>-0.099700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>-0.102700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.083100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>0.157800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>0.018800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>-0.172300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>-0.024100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>0.061900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.142800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>0.426200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>-0.043000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>0.042000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>-0.265000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>-0.026600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>0.094500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>-0.230600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>-0.181100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>-0.072200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>-0.090800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>0.079900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>0.114700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>-0.076300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.079900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>201</td>\n",
              "      <td>0.184800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>202</td>\n",
              "      <td>-0.024800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>203</td>\n",
              "      <td>0.097500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>204</td>\n",
              "      <td>0.182800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>-0.066700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>206</td>\n",
              "      <td>-0.342100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>207</td>\n",
              "      <td>0.037400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>208</td>\n",
              "      <td>0.138200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>209</td>\n",
              "      <td>-0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.140400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>211</td>\n",
              "      <td>-0.087300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>212</td>\n",
              "      <td>0.215300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>213</td>\n",
              "      <td>-0.097700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>214</td>\n",
              "      <td>-0.017300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>-0.076400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>0.553700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>217</td>\n",
              "      <td>0.451000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>218</td>\n",
              "      <td>-0.294800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>219</td>\n",
              "      <td>0.163700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.087500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>221</td>\n",
              "      <td>0.078300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>222</td>\n",
              "      <td>-0.030400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>223</td>\n",
              "      <td>-0.067600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>224</td>\n",
              "      <td>0.156700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.016000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>226</td>\n",
              "      <td>0.041000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>227</td>\n",
              "      <td>0.254600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>228</td>\n",
              "      <td>0.281600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>229</td>\n",
              "      <td>-0.018400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>-0.032100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>231</td>\n",
              "      <td>-0.029800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>232</td>\n",
              "      <td>0.037600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>233</td>\n",
              "      <td>0.132900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>-0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>-0.086200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>236</td>\n",
              "      <td>0.226600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>237</td>\n",
              "      <td>-0.054700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>238</td>\n",
              "      <td>-0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>239</td>\n",
              "      <td>-0.080900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>-0.123400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>241</td>\n",
              "      <td>-0.008000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>242</td>\n",
              "      <td>0.037800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>243</td>\n",
              "      <td>0.047800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>244</td>\n",
              "      <td>0.181400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>0.229300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}]\n",
            "[2025-10-28 10:38:37 IST] inputs are , {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 1060, 74045,  1561, 12598,  2190, 26812,  1278, 14146,  1681,  4546,\n",
            "          1321,  8033,  1046,  1531, 14146, 17000,  1278, 10162,  3581,  1317,\n",
            "          1402, 28645,  1435,  1429,  3715,  6307,  1034,  1454,  1836,  7259,\n",
            "          1307, 14496,  1044,  7652,  1278, 46770,  8942, 91865,  1681, 24405,\n",
            "         71508,  4810,  1046, 18011,  1044,  1278, 14146, 17000,  1278,  8551,\n",
            "          2595, 10912,  3816, 36227,  1278,  9578,  1455,  7560,  1317,  1402,\n",
            "          6574,  1394,  1278, 10162,  3581,  1046,  2409,  6987, 11495,  3686,\n",
            "          2516,  1435,  1429,  2391,  1044,  3804,  3946, 35515,  1044, 81743,\n",
            "         29542,  4225,  1799,  2481, 18191,  1402,  5753,  1435,  3940,  1288,\n",
            "          1556,  1693,  2127,  6185, 67735,  1317, 85763,  2081,  7357,  9576,\n",
            "          1046,  1534, 46651,  1066,  8062,  9387, 23921,  1561,  2757,  7444,\n",
            "         27310,  1693,  1278, 14146,  1934,  3199, 58697, 11865,  1278, 14496,\n",
            "          1046,  1534,  9568,  4557,  1561,  4380,  8033,  2481, 18191,  1402,\n",
            "         57721,  1693,  1278,  7293, 14496,  1486,  1046,  3886,  1044,  4265,\n",
            "          1278, 27310,  6594,  1307, 14496,  1044,  1494,  4139,  1402,  1261,\n",
            "         44761,  8516,  1010,  4998,  1278,  8412,  1307, 72219,  1532,  1321,\n",
            "         28524,  1562,  1278, 14146,  4139, 18191,  1402, 16088,  1435, 41530,\n",
            "         35821,  1046,  1534, 29846, 21537,  1561,  4380,  1710,  1402,  6493,\n",
            "          1536,  2606, 57721,  1494,  7444,  6153,  2224,  1278, 14541,  1455,\n",
            "          1278, 20086,  4139,  1605,  1736,  2151, 20333,  1010,  4380,  8033,\n",
            "          1395, 12837,  5753,  1294, 41530, 35821, 33878,  2478,  7586,  1321,\n",
            "         36621,  1850,  1395,  6136,  1885, 74045,  1561,  1060, 24613,  1062,\n",
            "          1048,  1046,  1055,  1053,  1885, 24613,  1062,     2,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}\n",
            "[2025-10-28 10:38:37 IST] END _prepare_inputs, keys=['prompt_ids', 'prompt_mask', 'completion_ids', 'completion_mask', 'advantages', 'num_items_in_batch'], prompt_ids.shape=(1, 660), completion_ids.shape=(1, 509)\n",
            "[2025-10-28 10:38:37 IST] ENTER compute_loss, use_liger_loss=False\n",
            "[2025-10-28 10:38:37 IST] ENTER _compute_loss, prompt_ids.shape=(1, 660), completion_ids.shape=(1, 509), loss_type=dapo, beta=0.0, importance_sampling_level=token\n",
            "[2025-10-28 10:38:37 IST] ENTER _get_per_token_logps_and_entropies, input_ids.shape=(1, 1169), attention_mask.shape=(1, 1169), logits_to_keep=509, batch_size=None, compute_entropy=True\n",
            "[2025-10-28 10:38:37 IST] END _get_per_token_logps_and_entropies, logps.shape=(1, 509), entropies=(1, 509)\n",
            "[2025-10-28 10:38:37 IST] END _compute_loss, loss=-0.033402420580387115\n",
            "[2025-10-28 10:38:37 IST] END compute_loss (standard)\n",
            "[2025-10-28 10:38:38 IST] ENTER _prepare_inputs, training=True, _step=1821, len_batch=n/a, si_2\n",
            "[2025-10-28 10:38:38 IST] mode is , train\n",
            "[2025-10-28 10:38:38 IST] generate_every 8 = self.args.steps_per_generation 8 * self.num_iterations 1\n",
            "[2025-10-28 10:38:38 IST] self._step is , 1821\n",
            "[2025-10-28 10:38:38 IST] self._buffered_inputs , [{'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[  6711,   1278,  16023,   5662,   1877,   1975,  44122,   2149,   1010,\n",
            "          37696,   1046,   2837,   2534,  18501,  12738,   1046,   3367,   1278,\n",
            "          46770,   6122,  14496,   1454,  21734,   1044,   1605,   6307,  12285,\n",
            "           2405,  11145,   1626,   4268,   1710,  20225,   1850,  17973,   1505,\n",
            "           1605,   1435,   5055,   1693,  83992,   2453,  41562,   1046,   1362,\n",
            "           2607,   2405,   2933,  10721,   1044,   1362,   2933,   1261,  17959,\n",
            "           1626,  67935,   1494,   1486,   4772,  20333,   1046,   1362,   1710,\n",
            "           2405,   5711,   3176,   3274,   1261,  34369,   1046,  27625,  27528,\n",
            "           1321,  10304,  18189,   1044,   1362,   1710,   2405,   3432,   1261,\n",
            "           2937,   1626,   2640,   4380,  14146,   7444,   1480,  46945,   1621,\n",
            "           1321,  77697,  29919,   1394,   1261,  73428,   3816,  11495,  12738,\n",
            "           1505,  15115,  18189,   1046,   4159,   2095,   8902,   2127,   1584,\n",
            "           6298,   1321,  33648,   2258,   8267,   1513,  41562,   1338,   1595,\n",
            "          24900,   1795,   1877,   1049,   1046,   1603,   1086,   5838,   2767,\n",
            "          96180,   1302,  18189,   3795,  13709,   8412,   1307,  21165,   7259,\n",
            "           1626,   1050,   1046,   1603,  57193,  41083,   3795,   3021,  21514,\n",
            "           1278,  18106,   1454,   1429,   1073,   1710,   2405,   5711,   3176,\n",
            "           3274,   1261,  34369,   2613,   6122,  89268,   1626,   1051,   1046,\n",
            "           1603,  66360,   4527, 124632,   1307, 112718,  26112,   3686,   3795,\n",
            "           1531,  13639,   1307,   1576,   3715,   6307,  12285,   2405,  11145,\n",
            "          72467,  29190,   2034,  17984,   1626,   1052,   1046,   1603,   1087,\n",
            "           9184,   3651,   1317,   6124,   1261,  17959,   3795, 128918,   2130,\n",
            "           1261,   7847,   2534,   1394,   2134,  10965,   1476,   3816,  33463,\n",
            "           1455,   6674,   1974,   2595,   4514,   1626,   1053,   1046,   1603,\n",
            "          16434,  86084,   1394,   1278,   2142,   1321,   8267,   1307,   1278,\n",
            "           3571,   1046,  62518,  10788,  11848,   9837,  21490,   1278,   3690,\n",
            "           3795,   1536,  87509, 103470,   1321,  25341,   2081,   6582,   6357,\n",
            "          30225,   1338,   1595,  32955,  44762,   1332,   5769,  64544,   1877,\n",
            "          31500,  39184,   3435,  73177,  14146,  61202,   1063,   3730,   1584,\n",
            "           5990,  14146, 120274,   9578,   1294,  12191,  27413,  14644,   2247,\n",
            "           4634,   1584,   1605,   2586,  42219,   4965,   1809, 118808,   2595,\n",
            "           4303,   8601,   2935,   1115,   8617, 113070,  22090,   4804,  12585,\n",
            "           6683,  14146,   2937,   1536,  16798,   2081,   1321,  11855,   6025,\n",
            "           2013,  89189,  80570,  34369,  15721, 127531,   1562,   1032,  68393,\n",
            "         109372,  16897,   2790,   1394,   1261,   2667, 124709,   8602,   1307,\n",
            "          13697,   2902,  41562,   1338,   1595,  91452,   7041,   1302,   1321,\n",
            "          15079,   2117,   1302,   1267,   1045,   5500,  15115,  14496,   4983,\n",
            "           5059,  81764,   2168,   2534,   7293,  26662,   6658,   8267,  43562,\n",
            "           4206,  26112,   5059,  20575,   1626,   1045,  99478,  36840,  21263,\n",
            "           3274,  23762,  15696,  21043,  90417,  73730,   1757,  25032,  53247,\n",
            "           1335,  32304,   6658,  16123,  11958,   1394,   1278,   2142,  73746,\n",
            "          21263,   3274,   1278,   2965,   1338,   1595,   1534,  74045,   1062,\n",
            "         123050,   1877,  23302,   7529,   1278,  15090,   1307,   1261,  44761,\n",
            "          34369,  10714,   3879,  74037,  67243,   1294,  37497,  11958,   1046,\n",
            "          20342,   1044,   1514,   4139,   1402,  54048,   1278,   2663,  11495,\n",
            "           9165,   1307,  15989,   6245,   5213,   8971,   3816,   7442,   3067,\n",
            "           3097,   7924,  62973,   1338,  23302,   6906,   1514,   1681,  59187,\n",
            "          43562,  54272,   2879,  97170,   7850,  29976,   1317,  94955,  14400,\n",
            "          96048,   1455, 121566,  41530,  35821,  13921,   1454,   1794,  70440,\n",
            "          41743,  63094,   3205,   3471,   2181,   2915,  13176,   1046,   1534,\n",
            "           1474,   1047,  74045,   1561,   2438,  34053, 116193,   2100,   2640,\n",
            "           1049,   1046,   1514,  43390,  72983,   7796,   1278,   8551,   2595,\n",
            "           3816,   9703,  96048,   1505,   1420,  15834,  16581,   1626,   1050,\n",
            "           1046,   6304,  17444,   1294,   1278,  46770,   1681,  27155,   1454,\n",
            "           3121,  24124,  33502,   1710,   5840,  32057,   2081,  75956,   1795,\n",
            "           1626,   2731,   1595,   1534,  24613,   1062,   1048,   1046,   1055,\n",
            "           1053,   1885,  24613,   1062,      2]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1]], device='cuda:0'), 'advantages': tensor([-2.4712], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   3318,   4380,  14146,   1395, 102359,   2034,  34369,\n",
            "           1435,   1261,   2767,  36549,  29270,   1799,   6122,   1261,   2738,\n",
            "           5289,   1394,  41530,   1046,   1531,  14146,   1877,   1045,   1395,\n",
            "           1605,  19984,   1317,   5234,  15115,  18189,   1505,  41562,   1520,\n",
            "           1045,  17000,   1261,  22506,  73428,   1435,   2034,   3804,   3110,\n",
            "           1307,  20748,   1520,   1045,   1395,  17470,  11051,   1278,   3542,\n",
            "           1486,   4772,  70270,   1520,   1045,   6354,   2405,   2479,   1278,\n",
            "           7900,   1307,  33755,   1564,   1505,  10721,   1520,   1045,   1395,\n",
            "          72144,   1349,   5180,   1088,   1394,   1261,  13035,   1454,  20726,\n",
            "          22506,  73428,   1520,   1045,  12551,  26112,   1395, 103046,   1321,\n",
            "           6354,   2405,  17105,   1494,   1338,  71289,   1044,   1278,  14146,\n",
            "           7444,   1317,   5759,  43562,   3323,  61202,   1321,  64629,   1317,\n",
            "           2012,   1261,  73428,   3816,  42016,   2034,   2362,   1046,   2409,\n",
            "           7444,   3435,  57721,   3147,   1494,   1681,  11779,   1278,  13435,\n",
            "           2534,   1394,  80046,   1562,   1278,  14146,   1321,   2034,   2362,\n",
            "           1605,   9705,   2034,  10636,   1338,   1073,   2084,  16426,   1261,\n",
            "          14381,   1307,   1032,   1048,   1046,   1049,   3147,   1494,   1681,\n",
            "           1261,   8385,  34369,   1059,   5444,   4670,   2203,   1494,   2127,\n",
            "           1584,  21752,   8462,   2314,  26112,   1044,   2156,   1395,  52819,\n",
            "           1307,   5711,   3176,   3643,   1307,   2127,   1584,  16106,   1605,\n",
            "           1278,  46952,  16692,   1338, 117682,   1454,   2516,   2738,   7481,\n",
            "          57721,   6763,   2576,   2168,   3180,   1278,  14146,   1261,   2738,\n",
            "          41530,   5032,  22802,   1321,   6894,   1534,   8228,   3274,  14381,\n",
            "         108740,   1408,  32975,   1046,   2259,   1411,   2077,   3318,   1060,\n",
            "          24613,   1062,   1048,   1046,   1055,   1053,   1885,  24613,   1062,\n",
            "              2,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   3318,  35957,   1408,   1278,   4265,  18106,   1321,\n",
            "           1278,  38528,   1394,  78813,   1307,  73428,   1044,   2156,   1584,\n",
            "           4804,  28061,  14655,   1278,   4546,   2188,   1402,  41530,  35821,\n",
            "           1046,   9380,   1584,   1278,   5305,   2100,   1042,  32868,  17000,\n",
            "          20726,  73428,   3816,  49654,   1317,  21294,  32113,   1321,  18028,\n",
            "           1626,   1042,   4159,   6730,  73427,   1317,  21294,   2585,   1045,\n",
            "          44994,   1536,   1278,   6021,   5178,   1321,   2034,   6266,   1317,\n",
            "          17995,   1294,  36924,  99862,   7444,   1317,   2685,   1562,   1261,\n",
            "         120256,   1408,   1278,   2832,   1626,   1042,  59094,   5815,   6904,\n",
            "           1319,  19974,   1041,   1462,   3933,   5449,   5677,   1486,   1710,\n",
            "           2405,   5234,   1536,   1278,  14146,   1395,  18857,   1261,   4804,\n",
            "          12585,   1010,   1042,  22183,   1278,  24149,  19294,   4546,   2071,\n",
            "           1987,  19294,   9150,   2071,   5059,   5303,   1681,   2160,   2756,\n",
            "           1291,   6850,   1987,   4228,   5192,  20086,   1987,  71191,   8141,\n",
            "           4254,   1395,   1593,   1317,   6889,   1278,   3468,  20341,   2866,\n",
            "           4546,   2782,   1010,   1042,   2157,   7560,  27511,   5449,   2782,\n",
            "           3686,   2790,   1799,   6122,  14146,  76662,   1455,   2481,  13372,\n",
            "          17718,   1626,   1042,   2813,   1636,   6933,  49879,  37851,   6465,\n",
            "           1636,   2534,   4938,   2810,   1397,   3504,   3146,   1317,   2840,\n",
            "           1321,   2767,  36549,  29270,   4254,  13023,   1626,   1042, 115763,\n",
            "          17793,   1395,   3964,   2516,   1261,  12785,  22397,   1317,   2012,\n",
            "          10066,   1047,  10500, 126404,   6307,   1338,  48812,   1044,   2156,\n",
            "           1584,   4631,  53182,   1455,   1278,   6591,  19295,  14420,  23253,\n",
            "          47843,   1044,  24124,   5449,  12559,   1044,   6127,   4853,   5735,\n",
            "           6591,   4254,   3715,  73428,   1046,  54447,   1278,  58832,   6878,\n",
            "           1317,   5526,   1286,  14146,   1748,  57859,  21956,   4804,   1053,\n",
            "          11658,   1046,  18244,   3214,   1319,   1593,   4731,   6591,   1584,\n",
            "           1584,   1605,   1284,   1041,   1275,   1261,  22619,   2634,   1885,\n",
            "          74045,   3318,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   1062,      2,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1785,   1593,   4811,  18106,   1044,   1278,\n",
            "          31341,   7444,   1317,   1402,   8729,   2781,  13808,   1321,  48212,\n",
            "           1454,  14832,  10384,  21067,   1044,  16798,   1394,   1261,   5275,\n",
            "          73428,  10912,   3964,   1317,   1261,   2767,   8643,  13038,   5610,\n",
            "           1046,   1531,   2534,   1394,   3236,   9150,   1321,   4811,   3686,\n",
            "           1394,  41562,   1044,   2516,   1435,   1278,   3804,   3946,  35515,\n",
            "           1321,  81743, 119287,   1044,  12551,   1261,   8412,   1307,   9705,\n",
            "           1455,   1925,   1934,   1317,   7377,   4570,  24594,   1394,  11110,\n",
            "          32113,   1321,   1934,   1317,   5234,  16647,   1505,   2210,   7481,\n",
            "          99862,  11855,   1278,   4607,   3169,  56590,   6933,   2782,   1046,\n",
            "           2409,  21823,   4145,  50269,   1925,   2481,  17407,   2081,   1809,\n",
            "           1514,  30762,  16798,   2314,   1278,  14146,   6187,   1278,   4546,\n",
            "           1046,   3886,   1044,   2576,   5186,   1307,  16964,   2481,   2342,\n",
            "           1402,   1562,  41530,  29694,   3147,  46952,  17412,   2168,   2196,\n",
            "          31709,   1317,  18507,   1278,  34369,   1435,   2156,   4139,   1402,\n",
            "           2269,  11053,   1505,  22070,   1294,   1278,   2832,   1455,   1395,\n",
            "         116929,   1046,   5646,   2190,   2549,  46952,  14146,   2168,   1653,\n",
            "           1044,   1429,   4237,   1394,  18675,   3871,   3886,   1044,   1278,\n",
            "          33830,   2136, 114767,   1307,   1278,   2832,   1294,   1278,   3039,\n",
            "           1278,  14146,   1395,  21490,   1278,   8122,   7510,   1639,   3648,\n",
            "           1455,   1278,  14146,   2481,   1402,   1261,  41530,   5032,   1338,\n",
            "           1885,  74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,\n",
            "           1053,   1885,  24613,   1062,      2,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 1060, 74045,  1561, 12598,  2190, 26812,  1278, 14146,  1681,  4546,\n",
            "          1321,  8033,  1046,  1531, 14146, 17000,  1278, 10162,  3581,  1317,\n",
            "          1402, 28645,  1435,  1429,  3715,  6307,  1034,  1454,  1836,  7259,\n",
            "          1307, 14496,  1044,  7652,  1278, 46770,  8942, 91865,  1681, 24405,\n",
            "         71508,  4810,  1046, 18011,  1044,  1278, 14146, 17000,  1278,  8551,\n",
            "          2595, 10912,  3816, 36227,  1278,  9578,  1455,  7560,  1317,  1402,\n",
            "          6574,  1394,  1278, 10162,  3581,  1046,  2409,  6987, 11495,  3686,\n",
            "          2516,  1435,  1429,  2391,  1044,  3804,  3946, 35515,  1044, 81743,\n",
            "         29542,  4225,  1799,  2481, 18191,  1402,  5753,  1435,  3940,  1288,\n",
            "          1556,  1693,  2127,  6185, 67735,  1317, 85763,  2081,  7357,  9576,\n",
            "          1046,  1534, 46651,  1066,  8062,  9387, 23921,  1561,  2757,  7444,\n",
            "         27310,  1693,  1278, 14146,  1934,  3199, 58697, 11865,  1278, 14496,\n",
            "          1046,  1534,  9568,  4557,  1561,  4380,  8033,  2481, 18191,  1402,\n",
            "         57721,  1693,  1278,  7293, 14496,  1486,  1046,  3886,  1044,  4265,\n",
            "          1278, 27310,  6594,  1307, 14496,  1044,  1494,  4139,  1402,  1261,\n",
            "         44761,  8516,  1010,  4998,  1278,  8412,  1307, 72219,  1532,  1321,\n",
            "         28524,  1562,  1278, 14146,  4139, 18191,  1402, 16088,  1435, 41530,\n",
            "         35821,  1046,  1534, 29846, 21537,  1561,  4380,  1710,  1402,  6493,\n",
            "          1536,  2606, 57721,  1494,  7444,  6153,  2224,  1278, 14541,  1455,\n",
            "          1278, 20086,  4139,  1605,  1736,  2151, 20333,  1010,  4380,  8033,\n",
            "          1395, 12837,  5753,  1294, 41530, 35821, 33878,  2478,  7586,  1321,\n",
            "         36621,  1850,  1395,  6136,  1885, 74045,  1561,  1060, 24613,  1062,\n",
            "          1048,  1046,  1055,  1053,  1885, 24613,  1062,     2,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1049,   1046,   1603,   6882,  11680,   1294,\n",
            "          54539,  17460,   2042,   3795,  60985,  24215,  16964,   1278,   5275,\n",
            "           1659,   1049,   1049,   1057,   1057,   1850,   1044,  10431,   1278,\n",
            "          14541,   1307,  41530,   1046,   9970, 122922,  10721,  12837,  12358,\n",
            "           1261,   2081,  22810,   5647,   4057,   1408,   2549,   1486,   1605,\n",
            "          20333,   1626,   1050,   1046,   1603,   1076,   1663,   1307,  22470,\n",
            "           3711,   3643,   3795,   1531,  14146,   3120,   1605,   2933,   1317,\n",
            "           7377,   1394,   5449,  41562,   1321, 102494,   1408,  21490,   1278,\n",
            "          73428,   1536,   2147,   4938,   1626,   1051,   1046,   1603,   1076,\n",
            "           1663,   1307,  46914,   3795,   1531,  71850,   1317,   5234,   1278,\n",
            "           5074,  18189,   1321,  83867,   1454,   1278,   9617,   5125,  40101,\n",
            "           1261,   8412,   1307,   9150,  57970,   1626,   1052,   1046,   1603,\n",
            "          45954,   8867,   1946,   1264,   3795,   9809,   8081,   1307,   4607,\n",
            "          35329,   1263,  29498,   1536,  34148,   1317,  10162,   3581,   3816,\n",
            "          11495,   7293,  18189, 118808,   8520,   1454,   2767,  36549,  29270,\n",
            "           1044,  30047,   8994,   4607,  41530,  35821,   8033,   1626,   1053,\n",
            "           1046,   1603,  15500,   1394,   4045,  44110,  15446,   3795,   1531,\n",
            "           2781,  13808,   2534,   1394,   1278,   6769,   1317,   1402,  26249,\n",
            "           1435,   9012,   1435,   4171,   3816,  27342,  18189,   4206,   1626,\n",
            "           1054,   1046,   1603,   1785,  37294,   1419,   3073,  33475, 115763,\n",
            "          18244,   3795,  71829,   1302,  26112,   8520,   1584,   1261,  47895,\n",
            "           2866,   1317,  19588,   1278,  26941,   6594,   1307,   4607,   1505,\n",
            "           1408, 126570,  14496,   8520,   1626,   1885,  74045,   1561,   1060,\n",
            "          24613,   1062,   1048,   1046,   1056,   1885,  24613,   1062,      2,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.4732], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1784,   4597,  16964,   1317,   3323,   1261,\n",
            "           1429,   2958,  10700,   1044,   4772,   6307,   1034,  34369,   1394,\n",
            "           1261,   2738,  26498,   5610,  12872,   1659,   1049,   1044,   1049,\n",
            "           1057,   1057,   1044,  10912,  64897,   1261,  22506,  31463,  73428,\n",
            "           1046,   2157,   1681,  29025,   1317,  10912,   4546,   1261,  22506,\n",
            "          73428,   1044,   1321,   2034,   8412,   1307,  11083,   1307,   1278,\n",
            "           9495,   2663,   2481,  41032,   3940,   9131,   1307,   3964,  18028,\n",
            "           8273,  10244,  77826,   1394,  73428,   1115,   1046,   1656,   5315,\n",
            "           1044,   1494,   1681,   7805,   4352,  53902,  11696,   1651,  15421,\n",
            "          17973,   1046,   2409,  25731,  97336,  38576,   1454,   2564,   1321,\n",
            "           1554,  19470,   1044,   1799,   2481,   1402,  41530,   4136,   1605,\n",
            "          39523,   1394,   1278,   6856,   6727,   1044,   1321,  27408,  47916,\n",
            "          10636,   1294,  26756,   1044,  38167,  72010,  21354,   1317,  89482,\n",
            "           1047,   2320,  25978,  17959,  10912,   1747,  14761,  52819,   1046,\n",
            "           8702,   1307,   5315,   2181,   6354,   2405,  11701,   1454,  45793,\n",
            "          58641,   3066,   1505,   1934,  40664,   6594,   1307,  25731,   1059,\n",
            "           6933,   1638,   1294,  98076,   1047,  41265,  11958,  10548,   2168,\n",
            "           9656,   3675,  51049,   1935,   2023,   1046,  57454,   1044,  73428,\n",
            "          11778,  89786,   1047,  37513,  26021,   7638,   1799,   2442,  16155,\n",
            "         107584,  10197,   4527,   6955,   3419,  92592, 102967,   6347,   1605,\n",
            "         118200,  34369,   9301,   1321,   1584,  23808,   1302,   1294,  41530,\n",
            "           5144,   2187,   1626,   1885,  74045,   1561,   1060,  24613,   1062,\n",
            "           1048,   1046,   1055,   1053,   1885,  24613,   1062,      2,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[  1060,  74045,   3318,   1784,  14146,   1294,   1278,   3519,  18106,\n",
            "           1395,  16798,   1394,   1261,  17959,   4057,   1408,   1278,  46770,\n",
            "          11050,  14496,   1454,  21734,   1044,   1605,   6307,   1044,  12285,\n",
            "           2405,  11145,   1046,  22468,   6763,   4128,   1593,   4139,   1402,\n",
            "           1261,  41530,   2937,   2100,   1049,   1046,   1603,  13148,   7903,\n",
            "          24687,   1532,   5450,   1531,  14146,   8222,   8031,   3686,   7504,\n",
            "           4998,   4275,  34369,   1044,  60985,  21371,   1046,  14116,   1278,\n",
            "          10162,   2595,   1394,   1261,  43164,   1562,  35108,  20249,   1659,\n",
            "           1049,   1044,   1049,   1057,   1057,   2613,   1041,   1321,  15786,\n",
            "           1261,   3750,   7575,   1307,  67630,   2034,  13921,   1317,   1278,\n",
            "          11105,  10496,   1338,   1050,   1046,   1603,   1080,  57634,   5450,\n",
            "           1531,  14146,  40101,   1794,  10103,   1317,   1429,  37513,   2143,\n",
            "           5449,   1321,   6369,   1278,  17718,   9576,   1034,   1799,   2481,\n",
            "           1402,  15421,   1693,   5595,  43850,   1046,   7209,  12585,   3226,\n",
            "           1395,   1283,   4091,   4110,  75750,   1394,   8673,   1261,  10162,\n",
            "           3581,   1044,  35420,   1302,   1278,  41562,   7079,   7754,   5074,\n",
            "           3066,   2516,  13921,   1710,   1402,  22528,   3816,  21165,   7259,\n",
            "           1307,   1420, 110229,  17718,   1505,   2767,   8643,  71322,   1338,\n",
            "           1051,   1046,   1603,   2822,   4993,   1394,  58973,  85277,   5450,\n",
            "           4925,   1278,  10496,   2639,   1429,  17013,   5234,   2143,   2564,\n",
            "           1044,   3804,   3946,  35515,   1044,  81743,   1554,  19470,   1044,\n",
            "           1321,  68077,   1278,   1294,  36924,  16925,   1362,   4525,  20234,\n",
            "           1044,   1278,  14146,  26658,   1429,   4753,   1044,   2586,   3323,\n",
            "           1494,   1435,   2767,  36549,  29270,   1034,  33370,   1278,   4804,\n",
            "          12585,   4136,   1278,  14146,   1395,  35420,   1302,   1278, 121606,\n",
            "          21609,   6618,   1394,   1278,   2937,   1046,   8494,   1044,   2127,\n",
            "           7693,   1429,  14096,   1476,  26112,   1395,   1261,   8871,   1034,\n",
            "           3199,   5572,  26112,  11820,  12837,   8222,   1278,   8417,   1307,\n",
            "           1261,  37497,   1338,   1052,   1046,   1603,   2438,   2565,   7081,\n",
            "          23613,   5450,   1429,   1073,   7534,  21294,   2143,   5449,   1321,\n",
            "           6369,   1278,  17718,   9576,   1046,  13980,   5234,   2143,   2564,\n",
            "           1044,   3804,   3946,  35515,   2880,   4568,   2607,   2405,   2933,\n",
            "           1639,   1605,  11133,   2143,   2830,   6170,   2118,   2613,   1531,\n",
            "           1429,  30879,   9396,   8453,   1034, 108681,   1395,  87002,   1044,\n",
            "          13709,   1278,  14146,  37827,   2127,   1710,  57026,   1278,   2663,\n",
            "           3816,  22116,  21831,   1338,   1053,   1046,   1603,  44345,  16924,\n",
            "          45261,  30887,   5450,   2409,   2481,  41032,   2152,  47119,   1278,\n",
            "          46770,   1394,  23683,  62591,   1824,   1044,  70362,   1455,   1349,\n",
            "           1804,   1120,   1681,   3471,   1395,   5418,  25187,   1505,   4895,\n",
            "           2383,  25844,  11824,   1394,  63753,   1294,   2516,   5443,   2100,\n",
            "           1784,  14146,  24277,   1278,  21340,  24489,  38528,   1394,   1278,\n",
            "           8412,   1307,  49625,   1046, 128135,  58025,   2862,   1455,   2269,\n",
            "           2084,   2985,   1317,   3355,  71344,   7195,   2187,  67866,   1405,\n",
            "           1317,  10035,  57317,   3850,   1435,  70278,   1338,  18395,   5628,\n",
            "           2738,   5972,   1317,  23808,   1261,  41530,  35821,  17718,   4983,\n",
            "           1046,   2259,  74045,   3318,   1060,  24613,   1062,   1048,   1046,\n",
            "           1055,   1053,   1885,  24613,   1062,      2,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}]\n",
            "[2025-10-28 10:38:38 IST] inputs are , {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1049,   1046,   1603,   6882,  11680,   1294,\n",
            "          54539,  17460,   2042,   3795,  60985,  24215,  16964,   1278,   5275,\n",
            "           1659,   1049,   1049,   1057,   1057,   1850,   1044,  10431,   1278,\n",
            "          14541,   1307,  41530,   1046,   9970, 122922,  10721,  12837,  12358,\n",
            "           1261,   2081,  22810,   5647,   4057,   1408,   2549,   1486,   1605,\n",
            "          20333,   1626,   1050,   1046,   1603,   1076,   1663,   1307,  22470,\n",
            "           3711,   3643,   3795,   1531,  14146,   3120,   1605,   2933,   1317,\n",
            "           7377,   1394,   5449,  41562,   1321, 102494,   1408,  21490,   1278,\n",
            "          73428,   1536,   2147,   4938,   1626,   1051,   1046,   1603,   1076,\n",
            "           1663,   1307,  46914,   3795,   1531,  71850,   1317,   5234,   1278,\n",
            "           5074,  18189,   1321,  83867,   1454,   1278,   9617,   5125,  40101,\n",
            "           1261,   8412,   1307,   9150,  57970,   1626,   1052,   1046,   1603,\n",
            "          45954,   8867,   1946,   1264,   3795,   9809,   8081,   1307,   4607,\n",
            "          35329,   1263,  29498,   1536,  34148,   1317,  10162,   3581,   3816,\n",
            "          11495,   7293,  18189, 118808,   8520,   1454,   2767,  36549,  29270,\n",
            "           1044,  30047,   8994,   4607,  41530,  35821,   8033,   1626,   1053,\n",
            "           1046,   1603,  15500,   1394,   4045,  44110,  15446,   3795,   1531,\n",
            "           2781,  13808,   2534,   1394,   1278,   6769,   1317,   1402,  26249,\n",
            "           1435,   9012,   1435,   4171,   3816,  27342,  18189,   4206,   1626,\n",
            "           1054,   1046,   1603,   1785,  37294,   1419,   3073,  33475, 115763,\n",
            "          18244,   3795,  71829,   1302,  26112,   8520,   1584,   1261,  47895,\n",
            "           2866,   1317,  19588,   1278,  26941,   6594,   1307,   4607,   1505,\n",
            "           1408, 126570,  14496,   8520,   1626,   1885,  74045,   1561,   1060,\n",
            "          24613,   1062,   1048,   1046,   1056,   1885,  24613,   1062,      2,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.4732], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}\n",
            "[2025-10-28 10:38:38 IST] END _prepare_inputs, keys=['prompt_ids', 'prompt_mask', 'completion_ids', 'completion_mask', 'advantages', 'num_items_in_batch'], prompt_ids.shape=(1, 660), completion_ids.shape=(1, 509)\n",
            "[2025-10-28 10:38:38 IST] ENTER compute_loss, use_liger_loss=False\n",
            "[2025-10-28 10:38:38 IST] ENTER _compute_loss, prompt_ids.shape=(1, 660), completion_ids.shape=(1, 509), loss_type=dapo, beta=0.0, importance_sampling_level=token\n",
            "[2025-10-28 10:38:38 IST] ENTER _get_per_token_logps_and_entropies, input_ids.shape=(1, 1169), attention_mask.shape=(1, 1169), logits_to_keep=509, batch_size=None, compute_entropy=True\n",
            "[2025-10-28 10:38:38 IST] END _get_per_token_logps_and_entropies, logps.shape=(1, 509), entropies=(1, 509)\n",
            "[2025-10-28 10:38:38 IST] END _compute_loss, loss=-0.04496839642524719\n",
            "[2025-10-28 10:38:38 IST] END compute_loss (standard)\n",
            "[2025-10-28 10:38:39 IST] ENTER _prepare_inputs, training=True, _step=1822, len_batch=n/a, si_2\n",
            "[2025-10-28 10:38:39 IST] mode is , train\n",
            "[2025-10-28 10:38:39 IST] generate_every 8 = self.args.steps_per_generation 8 * self.num_iterations 1\n",
            "[2025-10-28 10:38:39 IST] self._step is , 1822\n",
            "[2025-10-28 10:38:39 IST] self._buffered_inputs , [{'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[  6711,   1278,  16023,   5662,   1877,   1975,  44122,   2149,   1010,\n",
            "          37696,   1046,   2837,   2534,  18501,  12738,   1046,   3367,   1278,\n",
            "          46770,   6122,  14496,   1454,  21734,   1044,   1605,   6307,  12285,\n",
            "           2405,  11145,   1626,   4268,   1710,  20225,   1850,  17973,   1505,\n",
            "           1605,   1435,   5055,   1693,  83992,   2453,  41562,   1046,   1362,\n",
            "           2607,   2405,   2933,  10721,   1044,   1362,   2933,   1261,  17959,\n",
            "           1626,  67935,   1494,   1486,   4772,  20333,   1046,   1362,   1710,\n",
            "           2405,   5711,   3176,   3274,   1261,  34369,   1046,  27625,  27528,\n",
            "           1321,  10304,  18189,   1044,   1362,   1710,   2405,   3432,   1261,\n",
            "           2937,   1626,   2640,   4380,  14146,   7444,   1480,  46945,   1621,\n",
            "           1321,  77697,  29919,   1394,   1261,  73428,   3816,  11495,  12738,\n",
            "           1505,  15115,  18189,   1046,   4159,   2095,   8902,   2127,   1584,\n",
            "           6298,   1321,  33648,   2258,   8267,   1513,  41562,   1338,   1595,\n",
            "          24900,   1795,   1877,   1049,   1046,   1603,   1086,   5838,   2767,\n",
            "          96180,   1302,  18189,   3795,  13709,   8412,   1307,  21165,   7259,\n",
            "           1626,   1050,   1046,   1603,  57193,  41083,   3795,   3021,  21514,\n",
            "           1278,  18106,   1454,   1429,   1073,   1710,   2405,   5711,   3176,\n",
            "           3274,   1261,  34369,   2613,   6122,  89268,   1626,   1051,   1046,\n",
            "           1603,  66360,   4527, 124632,   1307, 112718,  26112,   3686,   3795,\n",
            "           1531,  13639,   1307,   1576,   3715,   6307,  12285,   2405,  11145,\n",
            "          72467,  29190,   2034,  17984,   1626,   1052,   1046,   1603,   1087,\n",
            "           9184,   3651,   1317,   6124,   1261,  17959,   3795, 128918,   2130,\n",
            "           1261,   7847,   2534,   1394,   2134,  10965,   1476,   3816,  33463,\n",
            "           1455,   6674,   1974,   2595,   4514,   1626,   1053,   1046,   1603,\n",
            "          16434,  86084,   1394,   1278,   2142,   1321,   8267,   1307,   1278,\n",
            "           3571,   1046,  62518,  10788,  11848,   9837,  21490,   1278,   3690,\n",
            "           3795,   1536,  87509, 103470,   1321,  25341,   2081,   6582,   6357,\n",
            "          30225,   1338,   1595,  32955,  44762,   1332,   5769,  64544,   1877,\n",
            "          31500,  39184,   3435,  73177,  14146,  61202,   1063,   3730,   1584,\n",
            "           5990,  14146, 120274,   9578,   1294,  12191,  27413,  14644,   2247,\n",
            "           4634,   1584,   1605,   2586,  42219,   4965,   1809, 118808,   2595,\n",
            "           4303,   8601,   2935,   1115,   8617, 113070,  22090,   4804,  12585,\n",
            "           6683,  14146,   2937,   1536,  16798,   2081,   1321,  11855,   6025,\n",
            "           2013,  89189,  80570,  34369,  15721, 127531,   1562,   1032,  68393,\n",
            "         109372,  16897,   2790,   1394,   1261,   2667, 124709,   8602,   1307,\n",
            "          13697,   2902,  41562,   1338,   1595,  91452,   7041,   1302,   1321,\n",
            "          15079,   2117,   1302,   1267,   1045,   5500,  15115,  14496,   4983,\n",
            "           5059,  81764,   2168,   2534,   7293,  26662,   6658,   8267,  43562,\n",
            "           4206,  26112,   5059,  20575,   1626,   1045,  99478,  36840,  21263,\n",
            "           3274,  23762,  15696,  21043,  90417,  73730,   1757,  25032,  53247,\n",
            "           1335,  32304,   6658,  16123,  11958,   1394,   1278,   2142,  73746,\n",
            "          21263,   3274,   1278,   2965,   1338,   1595,   1534,  74045,   1062,\n",
            "         123050,   1877,  23302,   7529,   1278,  15090,   1307,   1261,  44761,\n",
            "          34369,  10714,   3879,  74037,  67243,   1294,  37497,  11958,   1046,\n",
            "          20342,   1044,   1514,   4139,   1402,  54048,   1278,   2663,  11495,\n",
            "           9165,   1307,  15989,   6245,   5213,   8971,   3816,   7442,   3067,\n",
            "           3097,   7924,  62973,   1338,  23302,   6906,   1514,   1681,  59187,\n",
            "          43562,  54272,   2879,  97170,   7850,  29976,   1317,  94955,  14400,\n",
            "          96048,   1455, 121566,  41530,  35821,  13921,   1454,   1794,  70440,\n",
            "          41743,  63094,   3205,   3471,   2181,   2915,  13176,   1046,   1534,\n",
            "           1474,   1047,  74045,   1561,   2438,  34053, 116193,   2100,   2640,\n",
            "           1049,   1046,   1514,  43390,  72983,   7796,   1278,   8551,   2595,\n",
            "           3816,   9703,  96048,   1505,   1420,  15834,  16581,   1626,   1050,\n",
            "           1046,   6304,  17444,   1294,   1278,  46770,   1681,  27155,   1454,\n",
            "           3121,  24124,  33502,   1710,   5840,  32057,   2081,  75956,   1795,\n",
            "           1626,   2731,   1595,   1534,  24613,   1062,   1048,   1046,   1055,\n",
            "           1053,   1885,  24613,   1062,      2]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1]], device='cuda:0'), 'advantages': tensor([-2.4712], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   3318,   4380,  14146,   1395, 102359,   2034,  34369,\n",
            "           1435,   1261,   2767,  36549,  29270,   1799,   6122,   1261,   2738,\n",
            "           5289,   1394,  41530,   1046,   1531,  14146,   1877,   1045,   1395,\n",
            "           1605,  19984,   1317,   5234,  15115,  18189,   1505,  41562,   1520,\n",
            "           1045,  17000,   1261,  22506,  73428,   1435,   2034,   3804,   3110,\n",
            "           1307,  20748,   1520,   1045,   1395,  17470,  11051,   1278,   3542,\n",
            "           1486,   4772,  70270,   1520,   1045,   6354,   2405,   2479,   1278,\n",
            "           7900,   1307,  33755,   1564,   1505,  10721,   1520,   1045,   1395,\n",
            "          72144,   1349,   5180,   1088,   1394,   1261,  13035,   1454,  20726,\n",
            "          22506,  73428,   1520,   1045,  12551,  26112,   1395, 103046,   1321,\n",
            "           6354,   2405,  17105,   1494,   1338,  71289,   1044,   1278,  14146,\n",
            "           7444,   1317,   5759,  43562,   3323,  61202,   1321,  64629,   1317,\n",
            "           2012,   1261,  73428,   3816,  42016,   2034,   2362,   1046,   2409,\n",
            "           7444,   3435,  57721,   3147,   1494,   1681,  11779,   1278,  13435,\n",
            "           2534,   1394,  80046,   1562,   1278,  14146,   1321,   2034,   2362,\n",
            "           1605,   9705,   2034,  10636,   1338,   1073,   2084,  16426,   1261,\n",
            "          14381,   1307,   1032,   1048,   1046,   1049,   3147,   1494,   1681,\n",
            "           1261,   8385,  34369,   1059,   5444,   4670,   2203,   1494,   2127,\n",
            "           1584,  21752,   8462,   2314,  26112,   1044,   2156,   1395,  52819,\n",
            "           1307,   5711,   3176,   3643,   1307,   2127,   1584,  16106,   1605,\n",
            "           1278,  46952,  16692,   1338, 117682,   1454,   2516,   2738,   7481,\n",
            "          57721,   6763,   2576,   2168,   3180,   1278,  14146,   1261,   2738,\n",
            "          41530,   5032,  22802,   1321,   6894,   1534,   8228,   3274,  14381,\n",
            "         108740,   1408,  32975,   1046,   2259,   1411,   2077,   3318,   1060,\n",
            "          24613,   1062,   1048,   1046,   1055,   1053,   1885,  24613,   1062,\n",
            "              2,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   3318,  35957,   1408,   1278,   4265,  18106,   1321,\n",
            "           1278,  38528,   1394,  78813,   1307,  73428,   1044,   2156,   1584,\n",
            "           4804,  28061,  14655,   1278,   4546,   2188,   1402,  41530,  35821,\n",
            "           1046,   9380,   1584,   1278,   5305,   2100,   1042,  32868,  17000,\n",
            "          20726,  73428,   3816,  49654,   1317,  21294,  32113,   1321,  18028,\n",
            "           1626,   1042,   4159,   6730,  73427,   1317,  21294,   2585,   1045,\n",
            "          44994,   1536,   1278,   6021,   5178,   1321,   2034,   6266,   1317,\n",
            "          17995,   1294,  36924,  99862,   7444,   1317,   2685,   1562,   1261,\n",
            "         120256,   1408,   1278,   2832,   1626,   1042,  59094,   5815,   6904,\n",
            "           1319,  19974,   1041,   1462,   3933,   5449,   5677,   1486,   1710,\n",
            "           2405,   5234,   1536,   1278,  14146,   1395,  18857,   1261,   4804,\n",
            "          12585,   1010,   1042,  22183,   1278,  24149,  19294,   4546,   2071,\n",
            "           1987,  19294,   9150,   2071,   5059,   5303,   1681,   2160,   2756,\n",
            "           1291,   6850,   1987,   4228,   5192,  20086,   1987,  71191,   8141,\n",
            "           4254,   1395,   1593,   1317,   6889,   1278,   3468,  20341,   2866,\n",
            "           4546,   2782,   1010,   1042,   2157,   7560,  27511,   5449,   2782,\n",
            "           3686,   2790,   1799,   6122,  14146,  76662,   1455,   2481,  13372,\n",
            "          17718,   1626,   1042,   2813,   1636,   6933,  49879,  37851,   6465,\n",
            "           1636,   2534,   4938,   2810,   1397,   3504,   3146,   1317,   2840,\n",
            "           1321,   2767,  36549,  29270,   4254,  13023,   1626,   1042, 115763,\n",
            "          17793,   1395,   3964,   2516,   1261,  12785,  22397,   1317,   2012,\n",
            "          10066,   1047,  10500, 126404,   6307,   1338,  48812,   1044,   2156,\n",
            "           1584,   4631,  53182,   1455,   1278,   6591,  19295,  14420,  23253,\n",
            "          47843,   1044,  24124,   5449,  12559,   1044,   6127,   4853,   5735,\n",
            "           6591,   4254,   3715,  73428,   1046,  54447,   1278,  58832,   6878,\n",
            "           1317,   5526,   1286,  14146,   1748,  57859,  21956,   4804,   1053,\n",
            "          11658,   1046,  18244,   3214,   1319,   1593,   4731,   6591,   1584,\n",
            "           1584,   1605,   1284,   1041,   1275,   1261,  22619,   2634,   1885,\n",
            "          74045,   3318,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   1062,      2,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1785,   1593,   4811,  18106,   1044,   1278,\n",
            "          31341,   7444,   1317,   1402,   8729,   2781,  13808,   1321,  48212,\n",
            "           1454,  14832,  10384,  21067,   1044,  16798,   1394,   1261,   5275,\n",
            "          73428,  10912,   3964,   1317,   1261,   2767,   8643,  13038,   5610,\n",
            "           1046,   1531,   2534,   1394,   3236,   9150,   1321,   4811,   3686,\n",
            "           1394,  41562,   1044,   2516,   1435,   1278,   3804,   3946,  35515,\n",
            "           1321,  81743, 119287,   1044,  12551,   1261,   8412,   1307,   9705,\n",
            "           1455,   1925,   1934,   1317,   7377,   4570,  24594,   1394,  11110,\n",
            "          32113,   1321,   1934,   1317,   5234,  16647,   1505,   2210,   7481,\n",
            "          99862,  11855,   1278,   4607,   3169,  56590,   6933,   2782,   1046,\n",
            "           2409,  21823,   4145,  50269,   1925,   2481,  17407,   2081,   1809,\n",
            "           1514,  30762,  16798,   2314,   1278,  14146,   6187,   1278,   4546,\n",
            "           1046,   3886,   1044,   2576,   5186,   1307,  16964,   2481,   2342,\n",
            "           1402,   1562,  41530,  29694,   3147,  46952,  17412,   2168,   2196,\n",
            "          31709,   1317,  18507,   1278,  34369,   1435,   2156,   4139,   1402,\n",
            "           2269,  11053,   1505,  22070,   1294,   1278,   2832,   1455,   1395,\n",
            "         116929,   1046,   5646,   2190,   2549,  46952,  14146,   2168,   1653,\n",
            "           1044,   1429,   4237,   1394,  18675,   3871,   3886,   1044,   1278,\n",
            "          33830,   2136, 114767,   1307,   1278,   2832,   1294,   1278,   3039,\n",
            "           1278,  14146,   1395,  21490,   1278,   8122,   7510,   1639,   3648,\n",
            "           1455,   1278,  14146,   2481,   1402,   1261,  41530,   5032,   1338,\n",
            "           1885,  74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,\n",
            "           1053,   1885,  24613,   1062,      2,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 1060, 74045,  1561, 12598,  2190, 26812,  1278, 14146,  1681,  4546,\n",
            "          1321,  8033,  1046,  1531, 14146, 17000,  1278, 10162,  3581,  1317,\n",
            "          1402, 28645,  1435,  1429,  3715,  6307,  1034,  1454,  1836,  7259,\n",
            "          1307, 14496,  1044,  7652,  1278, 46770,  8942, 91865,  1681, 24405,\n",
            "         71508,  4810,  1046, 18011,  1044,  1278, 14146, 17000,  1278,  8551,\n",
            "          2595, 10912,  3816, 36227,  1278,  9578,  1455,  7560,  1317,  1402,\n",
            "          6574,  1394,  1278, 10162,  3581,  1046,  2409,  6987, 11495,  3686,\n",
            "          2516,  1435,  1429,  2391,  1044,  3804,  3946, 35515,  1044, 81743,\n",
            "         29542,  4225,  1799,  2481, 18191,  1402,  5753,  1435,  3940,  1288,\n",
            "          1556,  1693,  2127,  6185, 67735,  1317, 85763,  2081,  7357,  9576,\n",
            "          1046,  1534, 46651,  1066,  8062,  9387, 23921,  1561,  2757,  7444,\n",
            "         27310,  1693,  1278, 14146,  1934,  3199, 58697, 11865,  1278, 14496,\n",
            "          1046,  1534,  9568,  4557,  1561,  4380,  8033,  2481, 18191,  1402,\n",
            "         57721,  1693,  1278,  7293, 14496,  1486,  1046,  3886,  1044,  4265,\n",
            "          1278, 27310,  6594,  1307, 14496,  1044,  1494,  4139,  1402,  1261,\n",
            "         44761,  8516,  1010,  4998,  1278,  8412,  1307, 72219,  1532,  1321,\n",
            "         28524,  1562,  1278, 14146,  4139, 18191,  1402, 16088,  1435, 41530,\n",
            "         35821,  1046,  1534, 29846, 21537,  1561,  4380,  1710,  1402,  6493,\n",
            "          1536,  2606, 57721,  1494,  7444,  6153,  2224,  1278, 14541,  1455,\n",
            "          1278, 20086,  4139,  1605,  1736,  2151, 20333,  1010,  4380,  8033,\n",
            "          1395, 12837,  5753,  1294, 41530, 35821, 33878,  2478,  7586,  1321,\n",
            "         36621,  1850,  1395,  6136,  1885, 74045,  1561,  1060, 24613,  1062,\n",
            "          1048,  1046,  1055,  1053,  1885, 24613,  1062,     2,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1049,   1046,   1603,   6882,  11680,   1294,\n",
            "          54539,  17460,   2042,   3795,  60985,  24215,  16964,   1278,   5275,\n",
            "           1659,   1049,   1049,   1057,   1057,   1850,   1044,  10431,   1278,\n",
            "          14541,   1307,  41530,   1046,   9970, 122922,  10721,  12837,  12358,\n",
            "           1261,   2081,  22810,   5647,   4057,   1408,   2549,   1486,   1605,\n",
            "          20333,   1626,   1050,   1046,   1603,   1076,   1663,   1307,  22470,\n",
            "           3711,   3643,   3795,   1531,  14146,   3120,   1605,   2933,   1317,\n",
            "           7377,   1394,   5449,  41562,   1321, 102494,   1408,  21490,   1278,\n",
            "          73428,   1536,   2147,   4938,   1626,   1051,   1046,   1603,   1076,\n",
            "           1663,   1307,  46914,   3795,   1531,  71850,   1317,   5234,   1278,\n",
            "           5074,  18189,   1321,  83867,   1454,   1278,   9617,   5125,  40101,\n",
            "           1261,   8412,   1307,   9150,  57970,   1626,   1052,   1046,   1603,\n",
            "          45954,   8867,   1946,   1264,   3795,   9809,   8081,   1307,   4607,\n",
            "          35329,   1263,  29498,   1536,  34148,   1317,  10162,   3581,   3816,\n",
            "          11495,   7293,  18189, 118808,   8520,   1454,   2767,  36549,  29270,\n",
            "           1044,  30047,   8994,   4607,  41530,  35821,   8033,   1626,   1053,\n",
            "           1046,   1603,  15500,   1394,   4045,  44110,  15446,   3795,   1531,\n",
            "           2781,  13808,   2534,   1394,   1278,   6769,   1317,   1402,  26249,\n",
            "           1435,   9012,   1435,   4171,   3816,  27342,  18189,   4206,   1626,\n",
            "           1054,   1046,   1603,   1785,  37294,   1419,   3073,  33475, 115763,\n",
            "          18244,   3795,  71829,   1302,  26112,   8520,   1584,   1261,  47895,\n",
            "           2866,   1317,  19588,   1278,  26941,   6594,   1307,   4607,   1505,\n",
            "           1408, 126570,  14496,   8520,   1626,   1885,  74045,   1561,   1060,\n",
            "          24613,   1062,   1048,   1046,   1056,   1885,  24613,   1062,      2,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.4732], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1784,   4597,  16964,   1317,   3323,   1261,\n",
            "           1429,   2958,  10700,   1044,   4772,   6307,   1034,  34369,   1394,\n",
            "           1261,   2738,  26498,   5610,  12872,   1659,   1049,   1044,   1049,\n",
            "           1057,   1057,   1044,  10912,  64897,   1261,  22506,  31463,  73428,\n",
            "           1046,   2157,   1681,  29025,   1317,  10912,   4546,   1261,  22506,\n",
            "          73428,   1044,   1321,   2034,   8412,   1307,  11083,   1307,   1278,\n",
            "           9495,   2663,   2481,  41032,   3940,   9131,   1307,   3964,  18028,\n",
            "           8273,  10244,  77826,   1394,  73428,   1115,   1046,   1656,   5315,\n",
            "           1044,   1494,   1681,   7805,   4352,  53902,  11696,   1651,  15421,\n",
            "          17973,   1046,   2409,  25731,  97336,  38576,   1454,   2564,   1321,\n",
            "           1554,  19470,   1044,   1799,   2481,   1402,  41530,   4136,   1605,\n",
            "          39523,   1394,   1278,   6856,   6727,   1044,   1321,  27408,  47916,\n",
            "          10636,   1294,  26756,   1044,  38167,  72010,  21354,   1317,  89482,\n",
            "           1047,   2320,  25978,  17959,  10912,   1747,  14761,  52819,   1046,\n",
            "           8702,   1307,   5315,   2181,   6354,   2405,  11701,   1454,  45793,\n",
            "          58641,   3066,   1505,   1934,  40664,   6594,   1307,  25731,   1059,\n",
            "           6933,   1638,   1294,  98076,   1047,  41265,  11958,  10548,   2168,\n",
            "           9656,   3675,  51049,   1935,   2023,   1046,  57454,   1044,  73428,\n",
            "          11778,  89786,   1047,  37513,  26021,   7638,   1799,   2442,  16155,\n",
            "         107584,  10197,   4527,   6955,   3419,  92592, 102967,   6347,   1605,\n",
            "         118200,  34369,   9301,   1321,   1584,  23808,   1302,   1294,  41530,\n",
            "           5144,   2187,   1626,   1885,  74045,   1561,   1060,  24613,   1062,\n",
            "           1048,   1046,   1055,   1053,   1885,  24613,   1062,      2,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[  1060,  74045,   3318,   1784,  14146,   1294,   1278,   3519,  18106,\n",
            "           1395,  16798,   1394,   1261,  17959,   4057,   1408,   1278,  46770,\n",
            "          11050,  14496,   1454,  21734,   1044,   1605,   6307,   1044,  12285,\n",
            "           2405,  11145,   1046,  22468,   6763,   4128,   1593,   4139,   1402,\n",
            "           1261,  41530,   2937,   2100,   1049,   1046,   1603,  13148,   7903,\n",
            "          24687,   1532,   5450,   1531,  14146,   8222,   8031,   3686,   7504,\n",
            "           4998,   4275,  34369,   1044,  60985,  21371,   1046,  14116,   1278,\n",
            "          10162,   2595,   1394,   1261,  43164,   1562,  35108,  20249,   1659,\n",
            "           1049,   1044,   1049,   1057,   1057,   2613,   1041,   1321,  15786,\n",
            "           1261,   3750,   7575,   1307,  67630,   2034,  13921,   1317,   1278,\n",
            "          11105,  10496,   1338,   1050,   1046,   1603,   1080,  57634,   5450,\n",
            "           1531,  14146,  40101,   1794,  10103,   1317,   1429,  37513,   2143,\n",
            "           5449,   1321,   6369,   1278,  17718,   9576,   1034,   1799,   2481,\n",
            "           1402,  15421,   1693,   5595,  43850,   1046,   7209,  12585,   3226,\n",
            "           1395,   1283,   4091,   4110,  75750,   1394,   8673,   1261,  10162,\n",
            "           3581,   1044,  35420,   1302,   1278,  41562,   7079,   7754,   5074,\n",
            "           3066,   2516,  13921,   1710,   1402,  22528,   3816,  21165,   7259,\n",
            "           1307,   1420, 110229,  17718,   1505,   2767,   8643,  71322,   1338,\n",
            "           1051,   1046,   1603,   2822,   4993,   1394,  58973,  85277,   5450,\n",
            "           4925,   1278,  10496,   2639,   1429,  17013,   5234,   2143,   2564,\n",
            "           1044,   3804,   3946,  35515,   1044,  81743,   1554,  19470,   1044,\n",
            "           1321,  68077,   1278,   1294,  36924,  16925,   1362,   4525,  20234,\n",
            "           1044,   1278,  14146,  26658,   1429,   4753,   1044,   2586,   3323,\n",
            "           1494,   1435,   2767,  36549,  29270,   1034,  33370,   1278,   4804,\n",
            "          12585,   4136,   1278,  14146,   1395,  35420,   1302,   1278, 121606,\n",
            "          21609,   6618,   1394,   1278,   2937,   1046,   8494,   1044,   2127,\n",
            "           7693,   1429,  14096,   1476,  26112,   1395,   1261,   8871,   1034,\n",
            "           3199,   5572,  26112,  11820,  12837,   8222,   1278,   8417,   1307,\n",
            "           1261,  37497,   1338,   1052,   1046,   1603,   2438,   2565,   7081,\n",
            "          23613,   5450,   1429,   1073,   7534,  21294,   2143,   5449,   1321,\n",
            "           6369,   1278,  17718,   9576,   1046,  13980,   5234,   2143,   2564,\n",
            "           1044,   3804,   3946,  35515,   2880,   4568,   2607,   2405,   2933,\n",
            "           1639,   1605,  11133,   2143,   2830,   6170,   2118,   2613,   1531,\n",
            "           1429,  30879,   9396,   8453,   1034, 108681,   1395,  87002,   1044,\n",
            "          13709,   1278,  14146,  37827,   2127,   1710,  57026,   1278,   2663,\n",
            "           3816,  22116,  21831,   1338,   1053,   1046,   1603,  44345,  16924,\n",
            "          45261,  30887,   5450,   2409,   2481,  41032,   2152,  47119,   1278,\n",
            "          46770,   1394,  23683,  62591,   1824,   1044,  70362,   1455,   1349,\n",
            "           1804,   1120,   1681,   3471,   1395,   5418,  25187,   1505,   4895,\n",
            "           2383,  25844,  11824,   1394,  63753,   1294,   2516,   5443,   2100,\n",
            "           1784,  14146,  24277,   1278,  21340,  24489,  38528,   1394,   1278,\n",
            "           8412,   1307,  49625,   1046, 128135,  58025,   2862,   1455,   2269,\n",
            "           2084,   2985,   1317,   3355,  71344,   7195,   2187,  67866,   1405,\n",
            "           1317,  10035,  57317,   3850,   1435,  70278,   1338,  18395,   5628,\n",
            "           2738,   5972,   1317,  23808,   1261,  41530,  35821,  17718,   4983,\n",
            "           1046,   2259,  74045,   3318,   1060,  24613,   1062,   1048,   1046,\n",
            "           1055,   1053,   1885,  24613,   1062,      2,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}]\n",
            "[2025-10-28 10:38:39 IST] inputs are , {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1784,   4597,  16964,   1317,   3323,   1261,\n",
            "           1429,   2958,  10700,   1044,   4772,   6307,   1034,  34369,   1394,\n",
            "           1261,   2738,  26498,   5610,  12872,   1659,   1049,   1044,   1049,\n",
            "           1057,   1057,   1044,  10912,  64897,   1261,  22506,  31463,  73428,\n",
            "           1046,   2157,   1681,  29025,   1317,  10912,   4546,   1261,  22506,\n",
            "          73428,   1044,   1321,   2034,   8412,   1307,  11083,   1307,   1278,\n",
            "           9495,   2663,   2481,  41032,   3940,   9131,   1307,   3964,  18028,\n",
            "           8273,  10244,  77826,   1394,  73428,   1115,   1046,   1656,   5315,\n",
            "           1044,   1494,   1681,   7805,   4352,  53902,  11696,   1651,  15421,\n",
            "          17973,   1046,   2409,  25731,  97336,  38576,   1454,   2564,   1321,\n",
            "           1554,  19470,   1044,   1799,   2481,   1402,  41530,   4136,   1605,\n",
            "          39523,   1394,   1278,   6856,   6727,   1044,   1321,  27408,  47916,\n",
            "          10636,   1294,  26756,   1044,  38167,  72010,  21354,   1317,  89482,\n",
            "           1047,   2320,  25978,  17959,  10912,   1747,  14761,  52819,   1046,\n",
            "           8702,   1307,   5315,   2181,   6354,   2405,  11701,   1454,  45793,\n",
            "          58641,   3066,   1505,   1934,  40664,   6594,   1307,  25731,   1059,\n",
            "           6933,   1638,   1294,  98076,   1047,  41265,  11958,  10548,   2168,\n",
            "           9656,   3675,  51049,   1935,   2023,   1046,  57454,   1044,  73428,\n",
            "          11778,  89786,   1047,  37513,  26021,   7638,   1799,   2442,  16155,\n",
            "         107584,  10197,   4527,   6955,   3419,  92592, 102967,   6347,   1605,\n",
            "         118200,  34369,   9301,   1321,   1584,  23808,   1302,   1294,  41530,\n",
            "           5144,   2187,   1626,   1885,  74045,   1561,   1060,  24613,   1062,\n",
            "           1048,   1046,   1055,   1053,   1885,  24613,   1062,      2,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}\n",
            "[2025-10-28 10:38:39 IST] END _prepare_inputs, keys=['prompt_ids', 'prompt_mask', 'completion_ids', 'completion_mask', 'advantages', 'num_items_in_batch'], prompt_ids.shape=(1, 660), completion_ids.shape=(1, 509)\n",
            "[2025-10-28 10:38:39 IST] ENTER compute_loss, use_liger_loss=False\n",
            "[2025-10-28 10:38:39 IST] ENTER _compute_loss, prompt_ids.shape=(1, 660), completion_ids.shape=(1, 509), loss_type=dapo, beta=0.0, importance_sampling_level=token\n",
            "[2025-10-28 10:38:39 IST] ENTER _get_per_token_logps_and_entropies, input_ids.shape=(1, 1169), attention_mask.shape=(1, 1169), logits_to_keep=509, batch_size=None, compute_entropy=True\n",
            "[2025-10-28 10:38:39 IST] END _get_per_token_logps_and_entropies, logps.shape=(1, 509), entropies=(1, 509)\n",
            "[2025-10-28 10:38:39 IST] END _compute_loss, loss=-0.030179381370544434\n",
            "[2025-10-28 10:38:39 IST] END compute_loss (standard)\n",
            "[2025-10-28 10:38:40 IST] ENTER _prepare_inputs, training=True, _step=1823, len_batch=n/a, si_2\n",
            "[2025-10-28 10:38:40 IST] mode is , train\n",
            "[2025-10-28 10:38:40 IST] generate_every 8 = self.args.steps_per_generation 8 * self.num_iterations 1\n",
            "[2025-10-28 10:38:40 IST] self._step is , 1823\n",
            "[2025-10-28 10:38:40 IST] self._buffered_inputs , [{'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[  6711,   1278,  16023,   5662,   1877,   1975,  44122,   2149,   1010,\n",
            "          37696,   1046,   2837,   2534,  18501,  12738,   1046,   3367,   1278,\n",
            "          46770,   6122,  14496,   1454,  21734,   1044,   1605,   6307,  12285,\n",
            "           2405,  11145,   1626,   4268,   1710,  20225,   1850,  17973,   1505,\n",
            "           1605,   1435,   5055,   1693,  83992,   2453,  41562,   1046,   1362,\n",
            "           2607,   2405,   2933,  10721,   1044,   1362,   2933,   1261,  17959,\n",
            "           1626,  67935,   1494,   1486,   4772,  20333,   1046,   1362,   1710,\n",
            "           2405,   5711,   3176,   3274,   1261,  34369,   1046,  27625,  27528,\n",
            "           1321,  10304,  18189,   1044,   1362,   1710,   2405,   3432,   1261,\n",
            "           2937,   1626,   2640,   4380,  14146,   7444,   1480,  46945,   1621,\n",
            "           1321,  77697,  29919,   1394,   1261,  73428,   3816,  11495,  12738,\n",
            "           1505,  15115,  18189,   1046,   4159,   2095,   8902,   2127,   1584,\n",
            "           6298,   1321,  33648,   2258,   8267,   1513,  41562,   1338,   1595,\n",
            "          24900,   1795,   1877,   1049,   1046,   1603,   1086,   5838,   2767,\n",
            "          96180,   1302,  18189,   3795,  13709,   8412,   1307,  21165,   7259,\n",
            "           1626,   1050,   1046,   1603,  57193,  41083,   3795,   3021,  21514,\n",
            "           1278,  18106,   1454,   1429,   1073,   1710,   2405,   5711,   3176,\n",
            "           3274,   1261,  34369,   2613,   6122,  89268,   1626,   1051,   1046,\n",
            "           1603,  66360,   4527, 124632,   1307, 112718,  26112,   3686,   3795,\n",
            "           1531,  13639,   1307,   1576,   3715,   6307,  12285,   2405,  11145,\n",
            "          72467,  29190,   2034,  17984,   1626,   1052,   1046,   1603,   1087,\n",
            "           9184,   3651,   1317,   6124,   1261,  17959,   3795, 128918,   2130,\n",
            "           1261,   7847,   2534,   1394,   2134,  10965,   1476,   3816,  33463,\n",
            "           1455,   6674,   1974,   2595,   4514,   1626,   1053,   1046,   1603,\n",
            "          16434,  86084,   1394,   1278,   2142,   1321,   8267,   1307,   1278,\n",
            "           3571,   1046,  62518,  10788,  11848,   9837,  21490,   1278,   3690,\n",
            "           3795,   1536,  87509, 103470,   1321,  25341,   2081,   6582,   6357,\n",
            "          30225,   1338,   1595,  32955,  44762,   1332,   5769,  64544,   1877,\n",
            "          31500,  39184,   3435,  73177,  14146,  61202,   1063,   3730,   1584,\n",
            "           5990,  14146, 120274,   9578,   1294,  12191,  27413,  14644,   2247,\n",
            "           4634,   1584,   1605,   2586,  42219,   4965,   1809, 118808,   2595,\n",
            "           4303,   8601,   2935,   1115,   8617, 113070,  22090,   4804,  12585,\n",
            "           6683,  14146,   2937,   1536,  16798,   2081,   1321,  11855,   6025,\n",
            "           2013,  89189,  80570,  34369,  15721, 127531,   1562,   1032,  68393,\n",
            "         109372,  16897,   2790,   1394,   1261,   2667, 124709,   8602,   1307,\n",
            "          13697,   2902,  41562,   1338,   1595,  91452,   7041,   1302,   1321,\n",
            "          15079,   2117,   1302,   1267,   1045,   5500,  15115,  14496,   4983,\n",
            "           5059,  81764,   2168,   2534,   7293,  26662,   6658,   8267,  43562,\n",
            "           4206,  26112,   5059,  20575,   1626,   1045,  99478,  36840,  21263,\n",
            "           3274,  23762,  15696,  21043,  90417,  73730,   1757,  25032,  53247,\n",
            "           1335,  32304,   6658,  16123,  11958,   1394,   1278,   2142,  73746,\n",
            "          21263,   3274,   1278,   2965,   1338,   1595,   1534,  74045,   1062,\n",
            "         123050,   1877,  23302,   7529,   1278,  15090,   1307,   1261,  44761,\n",
            "          34369,  10714,   3879,  74037,  67243,   1294,  37497,  11958,   1046,\n",
            "          20342,   1044,   1514,   4139,   1402,  54048,   1278,   2663,  11495,\n",
            "           9165,   1307,  15989,   6245,   5213,   8971,   3816,   7442,   3067,\n",
            "           3097,   7924,  62973,   1338,  23302,   6906,   1514,   1681,  59187,\n",
            "          43562,  54272,   2879,  97170,   7850,  29976,   1317,  94955,  14400,\n",
            "          96048,   1455, 121566,  41530,  35821,  13921,   1454,   1794,  70440,\n",
            "          41743,  63094,   3205,   3471,   2181,   2915,  13176,   1046,   1534,\n",
            "           1474,   1047,  74045,   1561,   2438,  34053, 116193,   2100,   2640,\n",
            "           1049,   1046,   1514,  43390,  72983,   7796,   1278,   8551,   2595,\n",
            "           3816,   9703,  96048,   1505,   1420,  15834,  16581,   1626,   1050,\n",
            "           1046,   6304,  17444,   1294,   1278,  46770,   1681,  27155,   1454,\n",
            "           3121,  24124,  33502,   1710,   5840,  32057,   2081,  75956,   1795,\n",
            "           1626,   2731,   1595,   1534,  24613,   1062,   1048,   1046,   1055,\n",
            "           1053,   1885,  24613,   1062,      2]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1]], device='cuda:0'), 'advantages': tensor([-2.4712], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   3318,   4380,  14146,   1395, 102359,   2034,  34369,\n",
            "           1435,   1261,   2767,  36549,  29270,   1799,   6122,   1261,   2738,\n",
            "           5289,   1394,  41530,   1046,   1531,  14146,   1877,   1045,   1395,\n",
            "           1605,  19984,   1317,   5234,  15115,  18189,   1505,  41562,   1520,\n",
            "           1045,  17000,   1261,  22506,  73428,   1435,   2034,   3804,   3110,\n",
            "           1307,  20748,   1520,   1045,   1395,  17470,  11051,   1278,   3542,\n",
            "           1486,   4772,  70270,   1520,   1045,   6354,   2405,   2479,   1278,\n",
            "           7900,   1307,  33755,   1564,   1505,  10721,   1520,   1045,   1395,\n",
            "          72144,   1349,   5180,   1088,   1394,   1261,  13035,   1454,  20726,\n",
            "          22506,  73428,   1520,   1045,  12551,  26112,   1395, 103046,   1321,\n",
            "           6354,   2405,  17105,   1494,   1338,  71289,   1044,   1278,  14146,\n",
            "           7444,   1317,   5759,  43562,   3323,  61202,   1321,  64629,   1317,\n",
            "           2012,   1261,  73428,   3816,  42016,   2034,   2362,   1046,   2409,\n",
            "           7444,   3435,  57721,   3147,   1494,   1681,  11779,   1278,  13435,\n",
            "           2534,   1394,  80046,   1562,   1278,  14146,   1321,   2034,   2362,\n",
            "           1605,   9705,   2034,  10636,   1338,   1073,   2084,  16426,   1261,\n",
            "          14381,   1307,   1032,   1048,   1046,   1049,   3147,   1494,   1681,\n",
            "           1261,   8385,  34369,   1059,   5444,   4670,   2203,   1494,   2127,\n",
            "           1584,  21752,   8462,   2314,  26112,   1044,   2156,   1395,  52819,\n",
            "           1307,   5711,   3176,   3643,   1307,   2127,   1584,  16106,   1605,\n",
            "           1278,  46952,  16692,   1338, 117682,   1454,   2516,   2738,   7481,\n",
            "          57721,   6763,   2576,   2168,   3180,   1278,  14146,   1261,   2738,\n",
            "          41530,   5032,  22802,   1321,   6894,   1534,   8228,   3274,  14381,\n",
            "         108740,   1408,  32975,   1046,   2259,   1411,   2077,   3318,   1060,\n",
            "          24613,   1062,   1048,   1046,   1055,   1053,   1885,  24613,   1062,\n",
            "              2,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   3318,  35957,   1408,   1278,   4265,  18106,   1321,\n",
            "           1278,  38528,   1394,  78813,   1307,  73428,   1044,   2156,   1584,\n",
            "           4804,  28061,  14655,   1278,   4546,   2188,   1402,  41530,  35821,\n",
            "           1046,   9380,   1584,   1278,   5305,   2100,   1042,  32868,  17000,\n",
            "          20726,  73428,   3816,  49654,   1317,  21294,  32113,   1321,  18028,\n",
            "           1626,   1042,   4159,   6730,  73427,   1317,  21294,   2585,   1045,\n",
            "          44994,   1536,   1278,   6021,   5178,   1321,   2034,   6266,   1317,\n",
            "          17995,   1294,  36924,  99862,   7444,   1317,   2685,   1562,   1261,\n",
            "         120256,   1408,   1278,   2832,   1626,   1042,  59094,   5815,   6904,\n",
            "           1319,  19974,   1041,   1462,   3933,   5449,   5677,   1486,   1710,\n",
            "           2405,   5234,   1536,   1278,  14146,   1395,  18857,   1261,   4804,\n",
            "          12585,   1010,   1042,  22183,   1278,  24149,  19294,   4546,   2071,\n",
            "           1987,  19294,   9150,   2071,   5059,   5303,   1681,   2160,   2756,\n",
            "           1291,   6850,   1987,   4228,   5192,  20086,   1987,  71191,   8141,\n",
            "           4254,   1395,   1593,   1317,   6889,   1278,   3468,  20341,   2866,\n",
            "           4546,   2782,   1010,   1042,   2157,   7560,  27511,   5449,   2782,\n",
            "           3686,   2790,   1799,   6122,  14146,  76662,   1455,   2481,  13372,\n",
            "          17718,   1626,   1042,   2813,   1636,   6933,  49879,  37851,   6465,\n",
            "           1636,   2534,   4938,   2810,   1397,   3504,   3146,   1317,   2840,\n",
            "           1321,   2767,  36549,  29270,   4254,  13023,   1626,   1042, 115763,\n",
            "          17793,   1395,   3964,   2516,   1261,  12785,  22397,   1317,   2012,\n",
            "          10066,   1047,  10500, 126404,   6307,   1338,  48812,   1044,   2156,\n",
            "           1584,   4631,  53182,   1455,   1278,   6591,  19295,  14420,  23253,\n",
            "          47843,   1044,  24124,   5449,  12559,   1044,   6127,   4853,   5735,\n",
            "           6591,   4254,   3715,  73428,   1046,  54447,   1278,  58832,   6878,\n",
            "           1317,   5526,   1286,  14146,   1748,  57859,  21956,   4804,   1053,\n",
            "          11658,   1046,  18244,   3214,   1319,   1593,   4731,   6591,   1584,\n",
            "           1584,   1605,   1284,   1041,   1275,   1261,  22619,   2634,   1885,\n",
            "          74045,   3318,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   1062,      2,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1785,   1593,   4811,  18106,   1044,   1278,\n",
            "          31341,   7444,   1317,   1402,   8729,   2781,  13808,   1321,  48212,\n",
            "           1454,  14832,  10384,  21067,   1044,  16798,   1394,   1261,   5275,\n",
            "          73428,  10912,   3964,   1317,   1261,   2767,   8643,  13038,   5610,\n",
            "           1046,   1531,   2534,   1394,   3236,   9150,   1321,   4811,   3686,\n",
            "           1394,  41562,   1044,   2516,   1435,   1278,   3804,   3946,  35515,\n",
            "           1321,  81743, 119287,   1044,  12551,   1261,   8412,   1307,   9705,\n",
            "           1455,   1925,   1934,   1317,   7377,   4570,  24594,   1394,  11110,\n",
            "          32113,   1321,   1934,   1317,   5234,  16647,   1505,   2210,   7481,\n",
            "          99862,  11855,   1278,   4607,   3169,  56590,   6933,   2782,   1046,\n",
            "           2409,  21823,   4145,  50269,   1925,   2481,  17407,   2081,   1809,\n",
            "           1514,  30762,  16798,   2314,   1278,  14146,   6187,   1278,   4546,\n",
            "           1046,   3886,   1044,   2576,   5186,   1307,  16964,   2481,   2342,\n",
            "           1402,   1562,  41530,  29694,   3147,  46952,  17412,   2168,   2196,\n",
            "          31709,   1317,  18507,   1278,  34369,   1435,   2156,   4139,   1402,\n",
            "           2269,  11053,   1505,  22070,   1294,   1278,   2832,   1455,   1395,\n",
            "         116929,   1046,   5646,   2190,   2549,  46952,  14146,   2168,   1653,\n",
            "           1044,   1429,   4237,   1394,  18675,   3871,   3886,   1044,   1278,\n",
            "          33830,   2136, 114767,   1307,   1278,   2832,   1294,   1278,   3039,\n",
            "           1278,  14146,   1395,  21490,   1278,   8122,   7510,   1639,   3648,\n",
            "           1455,   1278,  14146,   2481,   1402,   1261,  41530,   5032,   1338,\n",
            "           1885,  74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,\n",
            "           1053,   1885,  24613,   1062,      2,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 1060, 74045,  1561, 12598,  2190, 26812,  1278, 14146,  1681,  4546,\n",
            "          1321,  8033,  1046,  1531, 14146, 17000,  1278, 10162,  3581,  1317,\n",
            "          1402, 28645,  1435,  1429,  3715,  6307,  1034,  1454,  1836,  7259,\n",
            "          1307, 14496,  1044,  7652,  1278, 46770,  8942, 91865,  1681, 24405,\n",
            "         71508,  4810,  1046, 18011,  1044,  1278, 14146, 17000,  1278,  8551,\n",
            "          2595, 10912,  3816, 36227,  1278,  9578,  1455,  7560,  1317,  1402,\n",
            "          6574,  1394,  1278, 10162,  3581,  1046,  2409,  6987, 11495,  3686,\n",
            "          2516,  1435,  1429,  2391,  1044,  3804,  3946, 35515,  1044, 81743,\n",
            "         29542,  4225,  1799,  2481, 18191,  1402,  5753,  1435,  3940,  1288,\n",
            "          1556,  1693,  2127,  6185, 67735,  1317, 85763,  2081,  7357,  9576,\n",
            "          1046,  1534, 46651,  1066,  8062,  9387, 23921,  1561,  2757,  7444,\n",
            "         27310,  1693,  1278, 14146,  1934,  3199, 58697, 11865,  1278, 14496,\n",
            "          1046,  1534,  9568,  4557,  1561,  4380,  8033,  2481, 18191,  1402,\n",
            "         57721,  1693,  1278,  7293, 14496,  1486,  1046,  3886,  1044,  4265,\n",
            "          1278, 27310,  6594,  1307, 14496,  1044,  1494,  4139,  1402,  1261,\n",
            "         44761,  8516,  1010,  4998,  1278,  8412,  1307, 72219,  1532,  1321,\n",
            "         28524,  1562,  1278, 14146,  4139, 18191,  1402, 16088,  1435, 41530,\n",
            "         35821,  1046,  1534, 29846, 21537,  1561,  4380,  1710,  1402,  6493,\n",
            "          1536,  2606, 57721,  1494,  7444,  6153,  2224,  1278, 14541,  1455,\n",
            "          1278, 20086,  4139,  1605,  1736,  2151, 20333,  1010,  4380,  8033,\n",
            "          1395, 12837,  5753,  1294, 41530, 35821, 33878,  2478,  7586,  1321,\n",
            "         36621,  1850,  1395,  6136,  1885, 74045,  1561,  1060, 24613,  1062,\n",
            "          1048,  1046,  1055,  1053,  1885, 24613,  1062,     2,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11,    11,\n",
            "            11,    11,    11,    11,    11,    11,    11,    11,    11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1049,   1046,   1603,   6882,  11680,   1294,\n",
            "          54539,  17460,   2042,   3795,  60985,  24215,  16964,   1278,   5275,\n",
            "           1659,   1049,   1049,   1057,   1057,   1850,   1044,  10431,   1278,\n",
            "          14541,   1307,  41530,   1046,   9970, 122922,  10721,  12837,  12358,\n",
            "           1261,   2081,  22810,   5647,   4057,   1408,   2549,   1486,   1605,\n",
            "          20333,   1626,   1050,   1046,   1603,   1076,   1663,   1307,  22470,\n",
            "           3711,   3643,   3795,   1531,  14146,   3120,   1605,   2933,   1317,\n",
            "           7377,   1394,   5449,  41562,   1321, 102494,   1408,  21490,   1278,\n",
            "          73428,   1536,   2147,   4938,   1626,   1051,   1046,   1603,   1076,\n",
            "           1663,   1307,  46914,   3795,   1531,  71850,   1317,   5234,   1278,\n",
            "           5074,  18189,   1321,  83867,   1454,   1278,   9617,   5125,  40101,\n",
            "           1261,   8412,   1307,   9150,  57970,   1626,   1052,   1046,   1603,\n",
            "          45954,   8867,   1946,   1264,   3795,   9809,   8081,   1307,   4607,\n",
            "          35329,   1263,  29498,   1536,  34148,   1317,  10162,   3581,   3816,\n",
            "          11495,   7293,  18189, 118808,   8520,   1454,   2767,  36549,  29270,\n",
            "           1044,  30047,   8994,   4607,  41530,  35821,   8033,   1626,   1053,\n",
            "           1046,   1603,  15500,   1394,   4045,  44110,  15446,   3795,   1531,\n",
            "           2781,  13808,   2534,   1394,   1278,   6769,   1317,   1402,  26249,\n",
            "           1435,   9012,   1435,   4171,   3816,  27342,  18189,   4206,   1626,\n",
            "           1054,   1046,   1603,   1785,  37294,   1419,   3073,  33475, 115763,\n",
            "          18244,   3795,  71829,   1302,  26112,   8520,   1584,   1261,  47895,\n",
            "           2866,   1317,  19588,   1278,  26941,   6594,   1307,   4607,   1505,\n",
            "           1408, 126570,  14496,   8520,   1626,   1885,  74045,   1561,   1060,\n",
            "          24613,   1062,   1048,   1046,   1056,   1885,  24613,   1062,      2,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.4732], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1784,   4597,  16964,   1317,   3323,   1261,\n",
            "           1429,   2958,  10700,   1044,   4772,   6307,   1034,  34369,   1394,\n",
            "           1261,   2738,  26498,   5610,  12872,   1659,   1049,   1044,   1049,\n",
            "           1057,   1057,   1044,  10912,  64897,   1261,  22506,  31463,  73428,\n",
            "           1046,   2157,   1681,  29025,   1317,  10912,   4546,   1261,  22506,\n",
            "          73428,   1044,   1321,   2034,   8412,   1307,  11083,   1307,   1278,\n",
            "           9495,   2663,   2481,  41032,   3940,   9131,   1307,   3964,  18028,\n",
            "           8273,  10244,  77826,   1394,  73428,   1115,   1046,   1656,   5315,\n",
            "           1044,   1494,   1681,   7805,   4352,  53902,  11696,   1651,  15421,\n",
            "          17973,   1046,   2409,  25731,  97336,  38576,   1454,   2564,   1321,\n",
            "           1554,  19470,   1044,   1799,   2481,   1402,  41530,   4136,   1605,\n",
            "          39523,   1394,   1278,   6856,   6727,   1044,   1321,  27408,  47916,\n",
            "          10636,   1294,  26756,   1044,  38167,  72010,  21354,   1317,  89482,\n",
            "           1047,   2320,  25978,  17959,  10912,   1747,  14761,  52819,   1046,\n",
            "           8702,   1307,   5315,   2181,   6354,   2405,  11701,   1454,  45793,\n",
            "          58641,   3066,   1505,   1934,  40664,   6594,   1307,  25731,   1059,\n",
            "           6933,   1638,   1294,  98076,   1047,  41265,  11958,  10548,   2168,\n",
            "           9656,   3675,  51049,   1935,   2023,   1046,  57454,   1044,  73428,\n",
            "          11778,  89786,   1047,  37513,  26021,   7638,   1799,   2442,  16155,\n",
            "         107584,  10197,   4527,   6955,   3419,  92592, 102967,   6347,   1605,\n",
            "         118200,  34369,   9301,   1321,   1584,  23808,   1302,   1294,  41530,\n",
            "           5144,   2187,   1626,   1885,  74045,   1561,   1060,  24613,   1062,\n",
            "           1048,   1046,   1055,   1053,   1885,  24613,   1062,      2,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[  1060,  74045,   3318,   1784,  14146,   1294,   1278,   3519,  18106,\n",
            "           1395,  16798,   1394,   1261,  17959,   4057,   1408,   1278,  46770,\n",
            "          11050,  14496,   1454,  21734,   1044,   1605,   6307,   1044,  12285,\n",
            "           2405,  11145,   1046,  22468,   6763,   4128,   1593,   4139,   1402,\n",
            "           1261,  41530,   2937,   2100,   1049,   1046,   1603,  13148,   7903,\n",
            "          24687,   1532,   5450,   1531,  14146,   8222,   8031,   3686,   7504,\n",
            "           4998,   4275,  34369,   1044,  60985,  21371,   1046,  14116,   1278,\n",
            "          10162,   2595,   1394,   1261,  43164,   1562,  35108,  20249,   1659,\n",
            "           1049,   1044,   1049,   1057,   1057,   2613,   1041,   1321,  15786,\n",
            "           1261,   3750,   7575,   1307,  67630,   2034,  13921,   1317,   1278,\n",
            "          11105,  10496,   1338,   1050,   1046,   1603,   1080,  57634,   5450,\n",
            "           1531,  14146,  40101,   1794,  10103,   1317,   1429,  37513,   2143,\n",
            "           5449,   1321,   6369,   1278,  17718,   9576,   1034,   1799,   2481,\n",
            "           1402,  15421,   1693,   5595,  43850,   1046,   7209,  12585,   3226,\n",
            "           1395,   1283,   4091,   4110,  75750,   1394,   8673,   1261,  10162,\n",
            "           3581,   1044,  35420,   1302,   1278,  41562,   7079,   7754,   5074,\n",
            "           3066,   2516,  13921,   1710,   1402,  22528,   3816,  21165,   7259,\n",
            "           1307,   1420, 110229,  17718,   1505,   2767,   8643,  71322,   1338,\n",
            "           1051,   1046,   1603,   2822,   4993,   1394,  58973,  85277,   5450,\n",
            "           4925,   1278,  10496,   2639,   1429,  17013,   5234,   2143,   2564,\n",
            "           1044,   3804,   3946,  35515,   1044,  81743,   1554,  19470,   1044,\n",
            "           1321,  68077,   1278,   1294,  36924,  16925,   1362,   4525,  20234,\n",
            "           1044,   1278,  14146,  26658,   1429,   4753,   1044,   2586,   3323,\n",
            "           1494,   1435,   2767,  36549,  29270,   1034,  33370,   1278,   4804,\n",
            "          12585,   4136,   1278,  14146,   1395,  35420,   1302,   1278, 121606,\n",
            "          21609,   6618,   1394,   1278,   2937,   1046,   8494,   1044,   2127,\n",
            "           7693,   1429,  14096,   1476,  26112,   1395,   1261,   8871,   1034,\n",
            "           3199,   5572,  26112,  11820,  12837,   8222,   1278,   8417,   1307,\n",
            "           1261,  37497,   1338,   1052,   1046,   1603,   2438,   2565,   7081,\n",
            "          23613,   5450,   1429,   1073,   7534,  21294,   2143,   5449,   1321,\n",
            "           6369,   1278,  17718,   9576,   1046,  13980,   5234,   2143,   2564,\n",
            "           1044,   3804,   3946,  35515,   2880,   4568,   2607,   2405,   2933,\n",
            "           1639,   1605,  11133,   2143,   2830,   6170,   2118,   2613,   1531,\n",
            "           1429,  30879,   9396,   8453,   1034, 108681,   1395,  87002,   1044,\n",
            "          13709,   1278,  14146,  37827,   2127,   1710,  57026,   1278,   2663,\n",
            "           3816,  22116,  21831,   1338,   1053,   1046,   1603,  44345,  16924,\n",
            "          45261,  30887,   5450,   2409,   2481,  41032,   2152,  47119,   1278,\n",
            "          46770,   1394,  23683,  62591,   1824,   1044,  70362,   1455,   1349,\n",
            "           1804,   1120,   1681,   3471,   1395,   5418,  25187,   1505,   4895,\n",
            "           2383,  25844,  11824,   1394,  63753,   1294,   2516,   5443,   2100,\n",
            "           1784,  14146,  24277,   1278,  21340,  24489,  38528,   1394,   1278,\n",
            "           8412,   1307,  49625,   1046, 128135,  58025,   2862,   1455,   2269,\n",
            "           2084,   2985,   1317,   3355,  71344,   7195,   2187,  67866,   1405,\n",
            "           1317,  10035,  57317,   3850,   1435,  70278,   1338,  18395,   5628,\n",
            "           2738,   5972,   1317,  23808,   1261,  41530,  35821,  17718,   4983,\n",
            "           1046,   2259,  74045,   3318,   1060,  24613,   1062,   1048,   1046,\n",
            "           1055,   1053,   1885,  24613,   1062,      2,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}]\n",
            "[2025-10-28 10:38:40 IST] inputs are , {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   3060,   4275,\n",
            "          34369,   1044,  60985,  21371,   1046,  14116,   1278,  10162,   2595,\n",
            "           1394,   1261,  43164,   1562,  35108,  20249,   1659,   1049,   1044,\n",
            "           1049,   1057,   1057,   1046,   6627,   1494,   1435,   1605,   6307,\n",
            "           1046,   1362,   2534,   1278,   8551,   2595,   9406,   1046,   1362,\n",
            "           7534,  21294,   2143,   5449,   1321,   6369,   1278,  17718,   9576,\n",
            "           1046,  13980,   5234,   2143,   2564,   1044,   3804,   3946,  35515,\n",
            "           1044,  81743,   1554,  19470,   1044,   1321,  68077,   1278,   1294,\n",
            "          36924,  16925,   1362,   4525,  20234,   1046,   3501,   1044,   2586,\n",
            "           3323,   1494,   1435,   2767,  36549,  29270,   1046,   3073,  33475,\n",
            "          26112,   1395,   1261,   8871,   1321,   1362,   2607,   2405,   1736,\n",
            "           2142,   1046,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[  1060,  74045,   3318,   1784,  14146,   1294,   1278,   3519,  18106,\n",
            "           1395,  16798,   1394,   1261,  17959,   4057,   1408,   1278,  46770,\n",
            "          11050,  14496,   1454,  21734,   1044,   1605,   6307,   1044,  12285,\n",
            "           2405,  11145,   1046,  22468,   6763,   4128,   1593,   4139,   1402,\n",
            "           1261,  41530,   2937,   2100,   1049,   1046,   1603,  13148,   7903,\n",
            "          24687,   1532,   5450,   1531,  14146,   8222,   8031,   3686,   7504,\n",
            "           4998,   4275,  34369,   1044,  60985,  21371,   1046,  14116,   1278,\n",
            "          10162,   2595,   1394,   1261,  43164,   1562,  35108,  20249,   1659,\n",
            "           1049,   1044,   1049,   1057,   1057,   2613,   1041,   1321,  15786,\n",
            "           1261,   3750,   7575,   1307,  67630,   2034,  13921,   1317,   1278,\n",
            "          11105,  10496,   1338,   1050,   1046,   1603,   1080,  57634,   5450,\n",
            "           1531,  14146,  40101,   1794,  10103,   1317,   1429,  37513,   2143,\n",
            "           5449,   1321,   6369,   1278,  17718,   9576,   1034,   1799,   2481,\n",
            "           1402,  15421,   1693,   5595,  43850,   1046,   7209,  12585,   3226,\n",
            "           1395,   1283,   4091,   4110,  75750,   1394,   8673,   1261,  10162,\n",
            "           3581,   1044,  35420,   1302,   1278,  41562,   7079,   7754,   5074,\n",
            "           3066,   2516,  13921,   1710,   1402,  22528,   3816,  21165,   7259,\n",
            "           1307,   1420, 110229,  17718,   1505,   2767,   8643,  71322,   1338,\n",
            "           1051,   1046,   1603,   2822,   4993,   1394,  58973,  85277,   5450,\n",
            "           4925,   1278,  10496,   2639,   1429,  17013,   5234,   2143,   2564,\n",
            "           1044,   3804,   3946,  35515,   1044,  81743,   1554,  19470,   1044,\n",
            "           1321,  68077,   1278,   1294,  36924,  16925,   1362,   4525,  20234,\n",
            "           1044,   1278,  14146,  26658,   1429,   4753,   1044,   2586,   3323,\n",
            "           1494,   1435,   2767,  36549,  29270,   1034,  33370,   1278,   4804,\n",
            "          12585,   4136,   1278,  14146,   1395,  35420,   1302,   1278, 121606,\n",
            "          21609,   6618,   1394,   1278,   2937,   1046,   8494,   1044,   2127,\n",
            "           7693,   1429,  14096,   1476,  26112,   1395,   1261,   8871,   1034,\n",
            "           3199,   5572,  26112,  11820,  12837,   8222,   1278,   8417,   1307,\n",
            "           1261,  37497,   1338,   1052,   1046,   1603,   2438,   2565,   7081,\n",
            "          23613,   5450,   1429,   1073,   7534,  21294,   2143,   5449,   1321,\n",
            "           6369,   1278,  17718,   9576,   1046,  13980,   5234,   2143,   2564,\n",
            "           1044,   3804,   3946,  35515,   2880,   4568,   2607,   2405,   2933,\n",
            "           1639,   1605,  11133,   2143,   2830,   6170,   2118,   2613,   1531,\n",
            "           1429,  30879,   9396,   8453,   1034, 108681,   1395,  87002,   1044,\n",
            "          13709,   1278,  14146,  37827,   2127,   1710,  57026,   1278,   2663,\n",
            "           3816,  22116,  21831,   1338,   1053,   1046,   1603,  44345,  16924,\n",
            "          45261,  30887,   5450,   2409,   2481,  41032,   2152,  47119,   1278,\n",
            "          46770,   1394,  23683,  62591,   1824,   1044,  70362,   1455,   1349,\n",
            "           1804,   1120,   1681,   3471,   1395,   5418,  25187,   1505,   4895,\n",
            "           2383,  25844,  11824,   1394,  63753,   1294,   2516,   5443,   2100,\n",
            "           1784,  14146,  24277,   1278,  21340,  24489,  38528,   1394,   1278,\n",
            "           8412,   1307,  49625,   1046, 128135,  58025,   2862,   1455,   2269,\n",
            "           2084,   2985,   1317,   3355,  71344,   7195,   2187,  67866,   1405,\n",
            "           1317,  10035,  57317,   3850,   1435,  70278,   1338,  18395,   5628,\n",
            "           2738,   5972,   1317,  23808,   1261,  41530,  35821,  17718,   4983,\n",
            "           1046,   2259,  74045,   3318,   1060,  24613,   1062,   1048,   1046,\n",
            "           1055,   1053,   1885,  24613,   1062,      2,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11]], device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.3330], device='cuda:0'), 'num_items_in_batch': tensor(2273, device='cuda:0')}\n",
            "[2025-10-28 10:38:40 IST] END _prepare_inputs, keys=['prompt_ids', 'prompt_mask', 'completion_ids', 'completion_mask', 'advantages', 'num_items_in_batch'], prompt_ids.shape=(1, 660), completion_ids.shape=(1, 509)\n",
            "[2025-10-28 10:38:40 IST] ENTER compute_loss, use_liger_loss=False\n",
            "[2025-10-28 10:38:40 IST] ENTER _compute_loss, prompt_ids.shape=(1, 660), completion_ids.shape=(1, 509), loss_type=dapo, beta=0.0, importance_sampling_level=token\n",
            "[2025-10-28 10:38:40 IST] ENTER _get_per_token_logps_and_entropies, input_ids.shape=(1, 1169), attention_mask.shape=(1, 1169), logits_to_keep=509, batch_size=None, compute_entropy=True\n",
            "[2025-10-28 10:38:41 IST] END _get_per_token_logps_and_entropies, logps.shape=(1, 509), entropies=(1, 509)\n",
            "[2025-10-28 10:38:41 IST] END _compute_loss, loss=-0.06153077632188797\n",
            "[2025-10-28 10:38:41 IST] END compute_loss (standard)\n",
            "[2025-10-28 10:38:41 IST] ENTER log, keys=['loss', 'grad_norm', 'learning_rate']\n",
            "[2025-10-28 10:38:41 IST] END log\n",
            "[2025-10-28 10:38:41 IST] ENTER _save_checkpoint\n",
            "[2025-10-28 10:38:41 IST] _save_checkpoint created model card, model_name=Voxtral-Mini-3B-2507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "HTTP Error 504 thrown while requesting HEAD https://huggingface.co/mistralai/Voxtral-Mini-3B-2507/resolve/main/config.json\n",
            "WARNING:huggingface_hub.utils._http:HTTP Error 504 thrown while requesting HEAD https://huggingface.co/mistralai/Voxtral-Mini-3B-2507/resolve/main/config.json\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n",
            "HTTP Error 504 thrown while requesting HEAD https://huggingface.co/mistralai/Voxtral-Mini-3B-2507/resolve/main/config.json\n",
            "WARNING:huggingface_hub.utils._http:HTTP Error 504 thrown while requesting HEAD https://huggingface.co/mistralai/Voxtral-Mini-3B-2507/resolve/main/config.json\n",
            "Retrying in 2s [Retry 2/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 2s [Retry 2/5].\n",
            "HTTP Error 504 thrown while requesting HEAD https://huggingface.co/mistralai/Voxtral-Mini-3B-2507/resolve/main/config.json\n",
            "WARNING:huggingface_hub.utils._http:HTTP Error 504 thrown while requesting HEAD https://huggingface.co/mistralai/Voxtral-Mini-3B-2507/resolve/main/config.json\n",
            "Retrying in 4s [Retry 3/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 4s [Retry 3/5].\n",
            "HTTP Error 504 thrown while requesting HEAD https://huggingface.co/mistralai/Voxtral-Mini-3B-2507/resolve/main/config.json\n",
            "WARNING:huggingface_hub.utils._http:HTTP Error 504 thrown while requesting HEAD https://huggingface.co/mistralai/Voxtral-Mini-3B-2507/resolve/main/config.json\n",
            "Retrying in 8s [Retry 4/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 8s [Retry 4/5].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([1.3649], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[  1975,   1123,  60087,   2002,  28932,   1054,   4453,   1622,   5764,\n",
            "           1058,  23493,  39893,  32213,   1748,  72191,  39319,   1370,   1885,\n",
            "           1104,   1054,   1561,   1060,   2132,   1062,   1534,   1098,   1062,\n",
            "          25413,   1058,   2259,   1098,   1062,  12082,   1455,   1362,   1736,\n",
            "          12220,   2036,   5751,   1044,   2606,   2168,   1362,   1653,   1317,\n",
            "           9168,   1593,   1875,   5751,   1454,   2036,  24527,   5449,   1063,\n",
            "           3797,   2036,   9150,   2715,   8848,   1317,   2036,   1875,   5751,\n",
            "           1435,  11564,  15342,   2132,   1561,   1060,   2132,   4453,   1622,\n",
            "           5764,   1058,  23493, 101018,   1098,   1062,  25413,  17697,  44119,\n",
            "          23779,   1098,   1062,  84331,   1934,   2586,   4108,   1420,   6726,\n",
            "          12522,  28106,   1294,   5751,   7981,   1046,   3367,   2143,   9150,\n",
            "           7560,   1584,  13330,   1044,   2127,   4139,   1402,   5083,   1317,\n",
            "           7782,   1278,  94892,   1307,   9150,   2586,   1317,   2143,   1875,\n",
            "           5751,  15342,   2132,   1561,   1885,   3285,   1561,   2731,   1975,\n",
            "          18154,   1010,   1060,  74045,   1561,   1060,   1336,   1561,  24187,\n",
            "           1062,   4268,   1722,   4265,   1278,  18106,   2396,   8720,   1321,\n",
            "           1261,  32868,  17697,  19833,   1394,   1278,   5150,  24468,  12460,\n",
            "           3016,  12327,   1261,   1875,  21114,   5751,  15342,   1978,   1561,\n",
            "          24187,   1062,   4268,   8178,   1455,   1278,  32868,   3831,  19833,\n",
            "           1536,   2269, 107209,   1741,   8942,   1278,   3148,  13006,  41562,\n",
            "           1536,  16798,   1394,  16544,   3946,  35515,   1044,  18926,   8686,\n",
            "           1321,   7600,   1307,  11573,   1044,   1321,   2430,  12327,  54030,\n",
            "          93588,  37490,  15342,   1978,   1561,  24187,   1062,   4268,   2224,\n",
            "           3219,   1455,  32868,   1319,   1349,   2667,   1875,  14146,   1041,\n",
            "          25747,   1394,  94892,   1307,   9150,   1317,   1261,   1875,   5751,\n",
            "           1394,  95449,   1794,  68415,   3754,  24527,   5449,   3016,   1494,\n",
            "           2342,  29036,   1317,   6309,   5751,   7981,  15342,   1978,   1561,\n",
            "          24187,   1062,   4668,   1593,   1044,  21622,   1261,  52819,   1455,\n",
            "           1261,   1875,   2965,   6906,  38953,   1435,   1420,  24527,  19833,\n",
            "           1317,   2016,   2015,   1278,  13006, 118808,   9576,   2479,  11573,\n",
            "          18814,   1044,   8686,  42281,   2247,  12431,   1044,   1278,   1875,\n",
            "           2965,  25747,   1394,  94892,   1307,   1747,  24600,   1435,   2903,\n",
            "           1046,   3886,   1044,   1278,   5719,  10103,   7444,   1317,   1402,\n",
            "           1261,  13392,   2108,   2396,  17275,   1317, 124382,   2012,   9576,\n",
            "          15342,   1978,   1561,  24187,   1062,   1073,   1855,  12857,   5257,\n",
            "           1455,   1593,   6836,  14146,   2564,   1321,   5263,   1302,   1395,\n",
            "          32323,   1374,   1317,   2012,   1278,  13006,  35801,   9576,   2479,\n",
            "          18814,   1321,   8686,   1317,   1402,   5949,   1317,   1278,   6309,\n",
            "           1044,   7655,   1047, 104676,   1536,  72144,   2147,  24995,   1047,\n",
            "          18194,   5200,   1046,   1531,  33871,  39852,   1395,   1420,  14183,\n",
            "           1272,  10414,   1307,   2269,   2516,  24527,   1321,   1395,   3226,\n",
            "           1317,  21294,   2269,  17676,  15342,   1978,   1561,   1885,   1336,\n",
            "           1561,   1885,  74045,   1561,   1060,  24613,   1062,   1048,   1046,\n",
            "           1055,   1053,   1885,  24613,   1561,   1975,      2,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-0.1950], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1049,   1046,   1603,  10587,   3711,   3643,\n",
            "           1438,   1462,   1531,  14146,   8720,  38276,   5662,   1261,   1875,\n",
            "           5751,   1321,  11865,   2034,  10098,   9576,   2516,   1435,   1261,\n",
            "           3519,   8686,   1321,  11573,   5451,   1046,   2157,   1681,  41494,\n",
            "           1455,   2127,   2715,   2840,   1278,   3804,   3946,  35515,   1307,\n",
            "           2034,   6309,   1321,   9576,   2314,   2147,   5266,   1338,   1050,\n",
            "           1046,   1603,  11765,  22402,   1438,   1462,  56102,   1044,   1278,\n",
            "           6334,  18106,  79388,   1836,   8686,   4036,   1046,   3626,   1294,\n",
            "           1593,  18106,   1044,   8720,  58568,   1317,  65874,   1044,   1794,\n",
            "          68415,   9705,   1455,   1576,   1055,  10126,   1398,  51615,   1395,\n",
            "          39095,   1454,   1278,   6309,   9528,   3886,   1044,   1875,   9576,\n",
            "           1408,  10098,   1319,   1083,   7985,  93588,   1041,   1584,  11865,\n",
            "           3066,   1278,   2832,   1307,  28342,   7520,  21834,   1046,   2409,\n",
            "          13335,   1317,  27094,   5444,   1046,  33440,   6231,  13664,   1307,\n",
            "           1593,   2832,   1044,  51040,   1584,   1605,   7655,  35801,   1435,\n",
            "           1593,  10045,   2405,   5282,   4616,  25392,  28069,   1307,  41530,\n",
            "           1338,   1051,   1046,   1603,   1069,  39472,  58285,   1321,  19966,\n",
            "          13240,   8713,   1438,   1462,  65874,   6354,   2405,  21294,   1455,\n",
            "          59489,   1032,   1055,   1395,   6298,   1321,  26376,   2782,   1317,\n",
            "           7873,   4527,   4036,   1046,   5646,  15786,   4945,  64624,   2314,\n",
            "           2246,   2019,  13167,   1046,   3886,   1044,   2481,   1402,  35801,\n",
            "           4057,   1408,   1794,   2158,   8686,  10674,   1046,  20398,   1927,\n",
            "           1115,   1044,   8673,  45489,   1435,   5124,  28061,   1505,  24368,\n",
            "           2210,  16902,  11696,   1338,   1052,   1046,   1603,  10696,   3571,\n",
            "           3983,   3795,  15050,  15730,  12606,   6967,  10739,  12694,  10982,\n",
            "           9698,   2832,  44868,   4289,   1317,   2034,  11546,   9620,   7667,\n",
            "           5444,   1044,  14954,  26662,   2481,  66159,   6967,   9916,  23965,\n",
            "          26187,   1046,   4493,  13664,   7444,   1317,   1402,  11090,  40660,\n",
            "          41530,  22802,   1338,   1053,   1046,   1603,  33111,   1302,   1748,\n",
            "          42743,  13920,  11279,   1271,   1093,   1505,   9086,   1603,  32116,\n",
            "           1438,   1704,  22356,  14620,   1408,   1693,   6330,  28061,  74375,\n",
            "          12178,  50487,   1044,   1505,   1278,  17718,  24277,   1046,   1531,\n",
            "          58841,   7693,   1307,  15449,   8164,   1307,   1429,  16539,  90716,\n",
            "           5548,   3039,  24263,  12353,   1398,   1395,   8017,   2613,  44258,\n",
            "          18891,  17718,  26877,  48001,  24850,   9664,  26187,   1626,   1060,\n",
            "          74045,   3318,   8032,   1044,   7283,   1513,   1278,   6960,  11100,\n",
            "           2535,   3988,   1748,  84612,   1317,  24124,   1848,   4597,   9576,\n",
            "           1294,   1278,  18106,  13335,   1317,   1420,  42528,  19190,   1307,\n",
            "           1278,   6594,  34195,  79012,   1307,  25342, 127870,   9044,   1877,\n",
            "         111436,   8516,   1044,   2156,   1584,  29439,   1394,   2991, 121042,\n",
            "           1532,   1307,  41530,  99862,   1261,  19101,   1525,   1311,   1356,\n",
            "           1626,  49766,   3880,   1505,   1605,  24013,  28697,   9750,   8033,\n",
            "           5561,  11696,  12585,   6683,  99862,  13035,  19190,   1626,   1060,\n",
            "          24613,   1062,   1048,   1046,   1050,   1053,   1885,  24613,   1062,\n",
            "              2,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-1.7549], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   6958,   1681,   1261,  68548,   5965,   1321,\n",
            "           3686,   4546,   7980,   3184,   1278,   5150,  24468,  14146,   3690,\n",
            "           1046,   1531,  18119,  10777,   1395,   1317,   3030,   1454,   5751,\n",
            "           1321,  18191,   1278,   2479,   8352,   7125,   1536,  10098,  41562,\n",
            "           1321,   2258,  51905,   4810,  38576,   1505,  17718,  38576,   1044,\n",
            "          11267,   1294,   1455,   3542,   1046,   1349,  70385,   3226,  61134,\n",
            "           1562,   1593,   1058,   1278,   2210,   1307,   1278,  11396,   2782,\n",
            "           2158,   1394,  12276,   1302,   3066,   7211,   2849,   1338,   4380,\n",
            "           1395,   4955,   4804,   1045,  19783,   6683,   3147,   7110, 117176,\n",
            "           1536,   5150,  24468,   4136,   1278,  19467,   1307,   1278,  10914,\n",
            "           8617,   3120,   1605,   3894,   6207,  98391,   3643,   1435,   1261,\n",
            "          10097,   1536,  40878,   1044,   2158,   1044,   6026,  41562,   1321,\n",
            "           2342,   2430,  39792,   6026,  93588,   3009,  93931,   1626,   1784,\n",
            "           9916,   2782,   5662,   2188,   1402,  36840,   1319,  55838,   8091,\n",
            "           1584,  10421,  24992,   2790,   1454,   1278, 125017,   6021,   1574,\n",
            "           1321,  93588,   4139,   5558,  40172,   1454,  30555,   1317,   1261,\n",
            "          14420,  13006,   1046,   1656,   2081,  41530,  35821,  15999,   1044,\n",
            "           1278,   7530,   1319,   1273, 112376,  13006,   1454,  18644,  17049,\n",
            "           3686,   1041,   1710,  14222,   7720,   3816,   1344,  98391,  11133,\n",
            "           2081,   5072,   1039,   3686,   1626,  14859,   1405,   1044,   3746,\n",
            "           3066,   1278,  24722,   1044,   1324,  34873,   2148,   5579,  89149,\n",
            "           1319,   1948,  17960,   5030,  17094,   1395,  18884,   1302,  44761,\n",
            "          44809,   4527,  11820,   1041,   3816,  19294,   1799, 103660,   3746,\n",
            "           1278,   5275,   7771,   2848,   2471,   7357,   6591,  73751,   1562,\n",
            "          10133,   1046,  38276,   1046,   9380,   5315,   3287, 107192,  49241,\n",
            "          10103,   4527,   1044,   2342,   1513,  95199,  24124,   7293,   4023,\n",
            "           1809,   1605,   8971,   4810,  24124,   7805,   1307,   8686,   5751,\n",
            "           4036,   2879,   1809,  13426,   8935,   1317,   1935,   2427,   1638,\n",
            "           6726,   1307,   4454,  89869,   1536,   4119,   3275,   1286,  14022,\n",
            "           2790,  34052,   1046,   1534,   1411,  34053,   1561,   1785,  25186,\n",
            "          23157,  14029,   3907,  21114,   1044,  28621, 111093,   1307,   9741,\n",
            "          50269,   5205,   1597,   2611,  11219,  13988,   1319,   1112,  69911,\n",
            "           8532,   4888,   1302,  15299,  34060,   1109,   5420,   2071,   1317,\n",
            "          12178,   4772,  11110,   3515,  22315,   1321,   7905, 103828,  64655,\n",
            "           2414,   2917,   7435,   1294,   1875,   4810,   2058,   8849,   1041,\n",
            "           2430,   1044,   2200, 109172,   5965,  13625,  16646,  16541,   1046,\n",
            "          12634,  32131,  16925,  63523,   3690,  49543,   1302,  29196,   9743,\n",
            "           1278,  14146,  85639,  35686,   1044,   1457, 107205,   5266,   1294,\n",
            "           2801,   4556,  91291,  37741,   1319,  96480,  26619,   1041,   1294,\n",
            "           8132,   1638,  10678,   2360,   4561,   1105,   1307,   6089,   2087,\n",
            "           2782,   1317,   1639,   1505,   8491,   1605,  15851,   3780,  26840,\n",
            "           9077,   1733,   1338,  93277,   1044,   1278,   2667,  28342,   1536,\n",
            "           2165,   1934,   2019,   1532,   4773,   3305,   8119,  54149,   1302,\n",
            "          12026,  49350,  39943,   1435,  48500,  90825,  17959,   6309,   3145,\n",
            "           1046,   2159,  31562,   1760,   7873,  27094,   1321,  13006,   6410,\n",
            "           1044,  26304,  16614,  12319,   1605,  19794,   1338,  24877,   7415,\n",
            "           1044,   6580,  15412,   1317,   4206,   1259,  11489,   3686,   3323,\n",
            "           1044,   2127,   2534,  12296,   3884,  29652,   1115,   2744,   4036,\n",
            "          19004,  11692,   1121,   2744,   3330,   1408,   2246,   1319,   1102,\n",
            "          17436,   1302,   1044, 105031,  15299,   2102,  61957,  22214,   1338,\n",
            "         118589,   7607,  26021,  87313,   9134,  17094,   2487,   1319,   1112,\n",
            "          40582,   5370,   1853,   5807,  32449,   1041,  13294,   7796,  12921,\n",
            "           5711,  95511,   6565,  21269,   1278,  14146,   1435,  14183,   2767,\n",
            "           3421,   1357,   1501,   5032,   1046,  12431,   8720,  38276,   1681,\n",
            "          17353,  80046,   1044,   1344,   1411,  48231,  28251,   3642,   4491,\n",
            "          15148,  23568,  16388,   6021,  70468,  29196,  41530,   1747,   1562,\n",
            "          17597,  47821,   3769,  15342,  74045,   3318,   1060,  24613,   1062,\n",
            "           1048,   1046,   1055,   1053,   1885,  24613,   1062,      2]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'advantages': tensor([-0.1950], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1784,  21166,   1562,   2960,  15819,   4395,\n",
            "          22809,   1046,   1531,  14146,  11865,   1278,   5751,   1536,  23288,\n",
            "           1278,   5451,   1307,  11573,   3066,  25217,   5250,  67541,   1505,\n",
            "          59218,   1278,   3686,   2314,   1278,   3804,   3946,  35515,   1044,\n",
            "          86688,   2424,   5029,  51905,  33396,   1046,  58271,   1593,   1044,\n",
            "           2127,   4983,   1261,  41562,   6983,   4108,   1420,  54030,   1044,\n",
            "           1799,   2127,   2715,   2012,   1294,   1278,  10910,   2142,   1046,\n",
            "           1531,   3831,  12334,  72219,   1944,  24511,   1278,   4546,   3816,\n",
            "          57363,  67545,   1505,  40812,  93851,  25157,   1059,   2147,   2224,\n",
            "           1455,  96032,  15202,   1044,   1420,  29025,  10613,  18964,   1278,\n",
            "          18106,   1681,   5965,   1729,  53515,   3066,   1046,  51506,   1513,\n",
            "           2576,   5305,   1044,   1494,  28594,   5349,   1394,  52819,   3675,\n",
            "           1278,  14146,   1626,   4393,   1261,  41530,   5032,   1317,  31544,\n",
            "           1278,   2663,   1044,   2127,   2168,   2629,   2269,   2005,  88251,\n",
            "           1307,   1324,   3890,   1494,   1486,  54237,   1626,  35957,   1408,\n",
            "          40281,   1681,  17919,  11137,   1454,  25636,  13307,  28524,   1044,\n",
            "           2156,   1395,   6727,   1317,   1402,  16232,   7259,   1394,  38576,\n",
            "           1289,   3326,   3403,   1302,   2424,   1505,   1536,   8385,   6369,\n",
            "          50221,   3226,   1058,  16967,   1681,  38528,   5662,   1278,  55907,\n",
            "          22428,   6610,  38669, 110736,   1278,   4127,   1046,   4925,  18964,\n",
            "           1278,   6960,  18106,   1799,  10249,   1317, 112859,   8119,  10235,\n",
            "           1261,  18119,   5216,  17008,  10197,   1454,  74843,   2181,  66505,\n",
            "          45917,   3522,   4837,   1454,  11696,   1394,  41562,  24184,  96048,\n",
            "           1044,   1494,  61050,   1394,   1383,  38394,   2282,   1046,   4493,\n",
            "           1278,  14146,   4139,   1402,  44761,   1294,  18119,   6856,   1626,\n",
            "           1885,  74045,   1561,   1060,  24613,   1062,   1048,   1046,   1053,\n",
            "           1885,  24613,   1062,      2,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5850], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 75263,  74045,   1062,  35322,   1934,   2151,   6908,   1454,   1794,\n",
            "           5449,   1044,  24130,   1261,   6165,   4036,   1317,   1794, 114341,\n",
            "           5751,   1044,   1321,   5662,   7924,   3686,   1394,  41562,   1046,\n",
            "           2182,   2095,   7444,   1317,   1402,   1261,  90122,   4548,   3330,\n",
            "           1435,  20702,   1562,   1794,   4546,   1317,   5807,   1794,   3519,\n",
            "           6309,   1321,   6726,  54030,  93588,   1046,   3730,   1681,   1836,\n",
            "          28069,   1307,  78694,   1505,  41530,  35821,   8033,   1046,   2182,\n",
            "          64897,  16157,  26840,   5305,   2414,   8994,   1261,   3683,   4274,\n",
            "          34745,   1455, 100269,   7924, 111191,  40933,   3285,   1561,   2182,\n",
            "          11383,   1747,   7357,   2181,   2314,   2414,  26873,   1405,   3016,\n",
            "          16798,   1394,   7924,   5266,   1044,   8154,   5384,  74045,   1062,\n",
            "          17061,  13833,   1060,  24613,   1062,   1048,   1046,   1048,   1885,\n",
            "          24613,   1062,      2,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-0.9749], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[  2293,   9825,   4832,   1877,  49250,   2077,   1561,  25280,  33352,\n",
            "           1278,   9614,  10636,   2645,   1261,   5735,  14013,   5125,   2100,\n",
            "           1049,   1046,   1603,   4967,   1394,  36121,   1302,  28263,  16104,\n",
            "          24185,   1256,   1462,   9970, 122922,  17365,  14987,   4036,   2034,\n",
            "          26662,   1394,   5561,  12738,   1046,   4159,   2933,   2034,  20089,\n",
            "           1914,   4312,   1317,   1278,   6298,   5751,   1338,   1050,   1046,\n",
            "           1603, 102282,   1307,  73382,  20317,  24185,   1256,   1462,  32505,\n",
            "          21385,   1317,   5234,  16544,   1032,   1052,  48044,   2383,   1044,\n",
            "           8686,   1044,  21478,   1066,   1044,   1321,   8686,   1747,   6274,\n",
            "           5990,   1046,   8720,  11495,   1593,  27899,   4139,  10982,   5270,\n",
            "           8453,   1338,   1051,   1046,   1603,   9334,  18926,  28263,  24185,\n",
            "           1256,   1462,   8720,   1395,  49410,   1317,   6726,   1794, 114341,\n",
            "           5751,   1317,   1576,  32111,   1032,   1057,   1056,   1049,   1048,\n",
            "           1057,   9528,   2409,  40791,   4878,  11696,   1307,  37474,  26840,\n",
            "           1338,   1052,   1046,   1603,  13958,  27339,   1261,  52546,  12460,\n",
            "          13920,  24185,   1256,   1462,  88258,   9780,   4546,   1317,   8214,\n",
            "           1454,   1278,  10430,   6309,   2782,  11701,   1115,   1454,   6170,\n",
            "           1435,  18119,   7560,   1046,   3886,   1044,   1593,  58254,   7357,\n",
            "          41562,   1044,   1435,   2147,   7513,  11279,   3174,   2181,   1722,\n",
            "           2342,  24130,   1394,   5751,  41562,   1044,   7754,   3147,   8720,\n",
            "           5314,  60199,   1278,   9048,   1454,  57351,  11820,   1338,   1256,\n",
            "          10228,   1317,   4878,  41530,  11696,   1044, 113894,   2725,   6906,\n",
            "           5314,   1736,   7357,   3686,   5059,   2181,   3200,  20964,   1338,\n",
            "           1053,   1046,   1603,   1083,   7985,  38751,   1115,  18244,  24185,\n",
            "           1256,   1462,   9970, 122922,   8616,   4139,   2012,  17656,   2314,\n",
            "          10098,   1809,  16798,   1317,   2229,  54030,  93588,   1395,   3435,\n",
            "           1573,   1290,   2440,   1321,  10098,   4884,   1420,  54030,   2168,\n",
            "           5234,  11915,   9576,   1626,   1885,  74045,   1062,   1534,  24613,\n",
            "           1062,   1048,   1046,   1053,   1885,  24613,   1062,      2,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5850], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1062,   2409,   1395,   1278,   6334,  18106,   1046,\n",
            "           1531,  14146,  73845,   1747,   1278,   8520,   1321,  26840,   1317,\n",
            "           5751,   1321,   3686,   1408,   6245,  34854,   1877,  35853, 114341,\n",
            "           5751,   1520,   2596,  48708,   6309,  26840,   1321,  38576,   1520,\n",
            "           4998,   7867,   1278,  12220,   2782,   2478,  93588,   1974,   1044,\n",
            "           3199,   2453,  13471,   9781,   1435,   2903,   1626,   2892,   1402,\n",
            "          41530,   5032,   1505,   1605,   2342,   1294,   1593,   8516,  89458,\n",
            "          74045,   1561,   1060,  24613,   1062,   1032,   1048,   1046,   1053,\n",
            "           1885,  24613,   1062,      2,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5850], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}]\n",
            "[2025-10-28 10:52:46 IST] inputs are , {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 75263,  74045,   1062,  35322,   1934,   2151,   6908,   1454,   1794,\n",
            "           5449,   1044,  24130,   1261,   6165,   4036,   1317,   1794, 114341,\n",
            "           5751,   1044,   1321,   5662,   7924,   3686,   1394,  41562,   1046,\n",
            "           2182,   2095,   7444,   1317,   1402,   1261,  90122,   4548,   3330,\n",
            "           1435,  20702,   1562,   1794,   4546,   1317,   5807,   1794,   3519,\n",
            "           6309,   1321,   6726,  54030,  93588,   1046,   3730,   1681,   1836,\n",
            "          28069,   1307,  78694,   1505,  41530,  35821,   8033,   1046,   2182,\n",
            "          64897,  16157,  26840,   5305,   2414,   8994,   1261,   3683,   4274,\n",
            "          34745,   1455, 100269,   7924, 111191,  40933,   3285,   1561,   2182,\n",
            "          11383,   1747,   7357,   2181,   2314,   2414,  26873,   1405,   3016,\n",
            "          16798,   1394,   7924,   5266,   1044,   8154,   5384,  74045,   1062,\n",
            "          17061,  13833,   1060,  24613,   1062,   1048,   1046,   1048,   1885,\n",
            "          24613,   1062,      2,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-0.9749], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}\n",
            "[2025-10-28 10:52:46 IST] END _prepare_inputs, keys=['prompt_ids', 'prompt_mask', 'completion_ids', 'completion_mask', 'advantages', 'num_items_in_batch'], prompt_ids.shape=(1, 731), completion_ids.shape=(1, 521)\n",
            "[2025-10-28 10:52:46 IST] ENTER compute_loss, use_liger_loss=False\n",
            "[2025-10-28 10:52:46 IST] ENTER _compute_loss, prompt_ids.shape=(1, 731), completion_ids.shape=(1, 521), loss_type=dapo, beta=0.0, importance_sampling_level=token\n",
            "[2025-10-28 10:52:46 IST] ENTER _get_per_token_logps_and_entropies, input_ids.shape=(1, 1252), attention_mask.shape=(1, 1252), logits_to_keep=521, batch_size=None, compute_entropy=True\n",
            "[2025-10-28 10:52:46 IST] END _get_per_token_logps_and_entropies, logps.shape=(1, 521), entropies=(1, 521)\n",
            "[2025-10-28 10:52:46 IST] END _compute_loss, loss=0.05114249140024185\n",
            "[2025-10-28 10:52:46 IST] END compute_loss (standard)\n",
            "[2025-10-28 10:52:47 IST] ENTER _prepare_inputs, training=True, _step=1958, len_batch=n/a, si_2\n",
            "[2025-10-28 10:52:47 IST] mode is , train\n",
            "[2025-10-28 10:52:47 IST] generate_every 8 = self.args.steps_per_generation 8 * self.num_iterations 1\n",
            "[2025-10-28 10:52:47 IST] self._step is , 1958\n",
            "[2025-10-28 10:52:47 IST] self._buffered_inputs , [{'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1062,  10107,   1405,   1044,   1278,  18106,   1486,\n",
            "           8031,   1294,  15115,  48065,   2314,   4590,   5751,   1044,   6309,\n",
            "          10317,   1044,   1321,  62183,   3816,   7481,  41530,  33649,  15342,\n",
            "           1411,   2077,   1561,   1060,  74045,   1062,   4393,  11618,  41562,\n",
            "           2479,  10098,   8352,   1321,   4811,   9576,   1044,   1729,   1710,\n",
            "           4150,   1494,   1681,   3683,   1317,  17898,  15342,   1411,   2077,\n",
            "           1561,   1060,  74045,   1062,   7651,   1486,   1278,  30179,  41530,\n",
            "           1046,   2898,   1639,   1044,   1278,  18106,   5978,   1261,  25052,\n",
            "           1321,  25052,   2721,   8070,   1278,  76249,  27223,   1505,   1261,\n",
            "         113940,  21490,   7211,  15342,   1411,   2077,   1062,   1319,  16860,\n",
            "           1044,   1514,   2697,   1605,   4237,   2081,   3686,   2479, 113940,\n",
            "           1681,   2564,   1505,  13591,   3686,   1577,   1885,  74045,   1561,\n",
            "           1060,  24613,   1062,   1048,   1046,   1050,   1053,   1885,  24613,\n",
            "           1062,      2,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([1.3649], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[  1975,   1123,  60087,   2002,  28932,   1054,   4453,   1622,   5764,\n",
            "           1058,  23493,  39893,  32213,   1748,  72191,  39319,   1370,   1885,\n",
            "           1104,   1054,   1561,   1060,   2132,   1062,   1534,   1098,   1062,\n",
            "          25413,   1058,   2259,   1098,   1062,  12082,   1455,   1362,   1736,\n",
            "          12220,   2036,   5751,   1044,   2606,   2168,   1362,   1653,   1317,\n",
            "           9168,   1593,   1875,   5751,   1454,   2036,  24527,   5449,   1063,\n",
            "           3797,   2036,   9150,   2715,   8848,   1317,   2036,   1875,   5751,\n",
            "           1435,  11564,  15342,   2132,   1561,   1060,   2132,   4453,   1622,\n",
            "           5764,   1058,  23493, 101018,   1098,   1062,  25413,  17697,  44119,\n",
            "          23779,   1098,   1062,  84331,   1934,   2586,   4108,   1420,   6726,\n",
            "          12522,  28106,   1294,   5751,   7981,   1046,   3367,   2143,   9150,\n",
            "           7560,   1584,  13330,   1044,   2127,   4139,   1402,   5083,   1317,\n",
            "           7782,   1278,  94892,   1307,   9150,   2586,   1317,   2143,   1875,\n",
            "           5751,  15342,   2132,   1561,   1885,   3285,   1561,   2731,   1975,\n",
            "          18154,   1010,   1060,  74045,   1561,   1060,   1336,   1561,  24187,\n",
            "           1062,   4268,   1722,   4265,   1278,  18106,   2396,   8720,   1321,\n",
            "           1261,  32868,  17697,  19833,   1394,   1278,   5150,  24468,  12460,\n",
            "           3016,  12327,   1261,   1875,  21114,   5751,  15342,   1978,   1561,\n",
            "          24187,   1062,   4268,   8178,   1455,   1278,  32868,   3831,  19833,\n",
            "           1536,   2269, 107209,   1741,   8942,   1278,   3148,  13006,  41562,\n",
            "           1536,  16798,   1394,  16544,   3946,  35515,   1044,  18926,   8686,\n",
            "           1321,   7600,   1307,  11573,   1044,   1321,   2430,  12327,  54030,\n",
            "          93588,  37490,  15342,   1978,   1561,  24187,   1062,   4268,   2224,\n",
            "           3219,   1455,  32868,   1319,   1349,   2667,   1875,  14146,   1041,\n",
            "          25747,   1394,  94892,   1307,   9150,   1317,   1261,   1875,   5751,\n",
            "           1394,  95449,   1794,  68415,   3754,  24527,   5449,   3016,   1494,\n",
            "           2342,  29036,   1317,   6309,   5751,   7981,  15342,   1978,   1561,\n",
            "          24187,   1062,   4668,   1593,   1044,  21622,   1261,  52819,   1455,\n",
            "           1261,   1875,   2965,   6906,  38953,   1435,   1420,  24527,  19833,\n",
            "           1317,   2016,   2015,   1278,  13006, 118808,   9576,   2479,  11573,\n",
            "          18814,   1044,   8686,  42281,   2247,  12431,   1044,   1278,   1875,\n",
            "           2965,  25747,   1394,  94892,   1307,   1747,  24600,   1435,   2903,\n",
            "           1046,   3886,   1044,   1278,   5719,  10103,   7444,   1317,   1402,\n",
            "           1261,  13392,   2108,   2396,  17275,   1317, 124382,   2012,   9576,\n",
            "          15342,   1978,   1561,  24187,   1062,   1073,   1855,  12857,   5257,\n",
            "           1455,   1593,   6836,  14146,   2564,   1321,   5263,   1302,   1395,\n",
            "          32323,   1374,   1317,   2012,   1278,  13006,  35801,   9576,   2479,\n",
            "          18814,   1321,   8686,   1317,   1402,   5949,   1317,   1278,   6309,\n",
            "           1044,   7655,   1047, 104676,   1536,  72144,   2147,  24995,   1047,\n",
            "          18194,   5200,   1046,   1531,  33871,  39852,   1395,   1420,  14183,\n",
            "           1272,  10414,   1307,   2269,   2516,  24527,   1321,   1395,   3226,\n",
            "           1317,  21294,   2269,  17676,  15342,   1978,   1561,   1885,   1336,\n",
            "           1561,   1885,  74045,   1561,   1060,  24613,   1062,   1048,   1046,\n",
            "           1055,   1053,   1885,  24613,   1561,   1975,      2,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-0.1950], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1049,   1046,   1603,  10587,   3711,   3643,\n",
            "           1438,   1462,   1531,  14146,   8720,  38276,   5662,   1261,   1875,\n",
            "           5751,   1321,  11865,   2034,  10098,   9576,   2516,   1435,   1261,\n",
            "           3519,   8686,   1321,  11573,   5451,   1046,   2157,   1681,  41494,\n",
            "           1455,   2127,   2715,   2840,   1278,   3804,   3946,  35515,   1307,\n",
            "           2034,   6309,   1321,   9576,   2314,   2147,   5266,   1338,   1050,\n",
            "           1046,   1603,  11765,  22402,   1438,   1462,  56102,   1044,   1278,\n",
            "           6334,  18106,  79388,   1836,   8686,   4036,   1046,   3626,   1294,\n",
            "           1593,  18106,   1044,   8720,  58568,   1317,  65874,   1044,   1794,\n",
            "          68415,   9705,   1455,   1576,   1055,  10126,   1398,  51615,   1395,\n",
            "          39095,   1454,   1278,   6309,   9528,   3886,   1044,   1875,   9576,\n",
            "           1408,  10098,   1319,   1083,   7985,  93588,   1041,   1584,  11865,\n",
            "           3066,   1278,   2832,   1307,  28342,   7520,  21834,   1046,   2409,\n",
            "          13335,   1317,  27094,   5444,   1046,  33440,   6231,  13664,   1307,\n",
            "           1593,   2832,   1044,  51040,   1584,   1605,   7655,  35801,   1435,\n",
            "           1593,  10045,   2405,   5282,   4616,  25392,  28069,   1307,  41530,\n",
            "           1338,   1051,   1046,   1603,   1069,  39472,  58285,   1321,  19966,\n",
            "          13240,   8713,   1438,   1462,  65874,   6354,   2405,  21294,   1455,\n",
            "          59489,   1032,   1055,   1395,   6298,   1321,  26376,   2782,   1317,\n",
            "           7873,   4527,   4036,   1046,   5646,  15786,   4945,  64624,   2314,\n",
            "           2246,   2019,  13167,   1046,   3886,   1044,   2481,   1402,  35801,\n",
            "           4057,   1408,   1794,   2158,   8686,  10674,   1046,  20398,   1927,\n",
            "           1115,   1044,   8673,  45489,   1435,   5124,  28061,   1505,  24368,\n",
            "           2210,  16902,  11696,   1338,   1052,   1046,   1603,  10696,   3571,\n",
            "           3983,   3795,  15050,  15730,  12606,   6967,  10739,  12694,  10982,\n",
            "           9698,   2832,  44868,   4289,   1317,   2034,  11546,   9620,   7667,\n",
            "           5444,   1044,  14954,  26662,   2481,  66159,   6967,   9916,  23965,\n",
            "          26187,   1046,   4493,  13664,   7444,   1317,   1402,  11090,  40660,\n",
            "          41530,  22802,   1338,   1053,   1046,   1603,  33111,   1302,   1748,\n",
            "          42743,  13920,  11279,   1271,   1093,   1505,   9086,   1603,  32116,\n",
            "           1438,   1704,  22356,  14620,   1408,   1693,   6330,  28061,  74375,\n",
            "          12178,  50487,   1044,   1505,   1278,  17718,  24277,   1046,   1531,\n",
            "          58841,   7693,   1307,  15449,   8164,   1307,   1429,  16539,  90716,\n",
            "           5548,   3039,  24263,  12353,   1398,   1395,   8017,   2613,  44258,\n",
            "          18891,  17718,  26877,  48001,  24850,   9664,  26187,   1626,   1060,\n",
            "          74045,   3318,   8032,   1044,   7283,   1513,   1278,   6960,  11100,\n",
            "           2535,   3988,   1748,  84612,   1317,  24124,   1848,   4597,   9576,\n",
            "           1294,   1278,  18106,  13335,   1317,   1420,  42528,  19190,   1307,\n",
            "           1278,   6594,  34195,  79012,   1307,  25342, 127870,   9044,   1877,\n",
            "         111436,   8516,   1044,   2156,   1584,  29439,   1394,   2991, 121042,\n",
            "           1532,   1307,  41530,  99862,   1261,  19101,   1525,   1311,   1356,\n",
            "           1626,  49766,   3880,   1505,   1605,  24013,  28697,   9750,   8033,\n",
            "           5561,  11696,  12585,   6683,  99862,  13035,  19190,   1626,   1060,\n",
            "          24613,   1062,   1048,   1046,   1050,   1053,   1885,  24613,   1062,\n",
            "              2,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-1.7549], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   6958,   1681,   1261,  68548,   5965,   1321,\n",
            "           3686,   4546,   7980,   3184,   1278,   5150,  24468,  14146,   3690,\n",
            "           1046,   1531,  18119,  10777,   1395,   1317,   3030,   1454,   5751,\n",
            "           1321,  18191,   1278,   2479,   8352,   7125,   1536,  10098,  41562,\n",
            "           1321,   2258,  51905,   4810,  38576,   1505,  17718,  38576,   1044,\n",
            "          11267,   1294,   1455,   3542,   1046,   1349,  70385,   3226,  61134,\n",
            "           1562,   1593,   1058,   1278,   2210,   1307,   1278,  11396,   2782,\n",
            "           2158,   1394,  12276,   1302,   3066,   7211,   2849,   1338,   4380,\n",
            "           1395,   4955,   4804,   1045,  19783,   6683,   3147,   7110, 117176,\n",
            "           1536,   5150,  24468,   4136,   1278,  19467,   1307,   1278,  10914,\n",
            "           8617,   3120,   1605,   3894,   6207,  98391,   3643,   1435,   1261,\n",
            "          10097,   1536,  40878,   1044,   2158,   1044,   6026,  41562,   1321,\n",
            "           2342,   2430,  39792,   6026,  93588,   3009,  93931,   1626,   1784,\n",
            "           9916,   2782,   5662,   2188,   1402,  36840,   1319,  55838,   8091,\n",
            "           1584,  10421,  24992,   2790,   1454,   1278, 125017,   6021,   1574,\n",
            "           1321,  93588,   4139,   5558,  40172,   1454,  30555,   1317,   1261,\n",
            "          14420,  13006,   1046,   1656,   2081,  41530,  35821,  15999,   1044,\n",
            "           1278,   7530,   1319,   1273, 112376,  13006,   1454,  18644,  17049,\n",
            "           3686,   1041,   1710,  14222,   7720,   3816,   1344,  98391,  11133,\n",
            "           2081,   5072,   1039,   3686,   1626,  14859,   1405,   1044,   3746,\n",
            "           3066,   1278,  24722,   1044,   1324,  34873,   2148,   5579,  89149,\n",
            "           1319,   1948,  17960,   5030,  17094,   1395,  18884,   1302,  44761,\n",
            "          44809,   4527,  11820,   1041,   3816,  19294,   1799, 103660,   3746,\n",
            "           1278,   5275,   7771,   2848,   2471,   7357,   6591,  73751,   1562,\n",
            "          10133,   1046,  38276,   1046,   9380,   5315,   3287, 107192,  49241,\n",
            "          10103,   4527,   1044,   2342,   1513,  95199,  24124,   7293,   4023,\n",
            "           1809,   1605,   8971,   4810,  24124,   7805,   1307,   8686,   5751,\n",
            "           4036,   2879,   1809,  13426,   8935,   1317,   1935,   2427,   1638,\n",
            "           6726,   1307,   4454,  89869,   1536,   4119,   3275,   1286,  14022,\n",
            "           2790,  34052,   1046,   1534,   1411,  34053,   1561,   1785,  25186,\n",
            "          23157,  14029,   3907,  21114,   1044,  28621, 111093,   1307,   9741,\n",
            "          50269,   5205,   1597,   2611,  11219,  13988,   1319,   1112,  69911,\n",
            "           8532,   4888,   1302,  15299,  34060,   1109,   5420,   2071,   1317,\n",
            "          12178,   4772,  11110,   3515,  22315,   1321,   7905, 103828,  64655,\n",
            "           2414,   2917,   7435,   1294,   1875,   4810,   2058,   8849,   1041,\n",
            "           2430,   1044,   2200, 109172,   5965,  13625,  16646,  16541,   1046,\n",
            "          12634,  32131,  16925,  63523,   3690,  49543,   1302,  29196,   9743,\n",
            "           1278,  14146,  85639,  35686,   1044,   1457, 107205,   5266,   1294,\n",
            "           2801,   4556,  91291,  37741,   1319,  96480,  26619,   1041,   1294,\n",
            "           8132,   1638,  10678,   2360,   4561,   1105,   1307,   6089,   2087,\n",
            "           2782,   1317,   1639,   1505,   8491,   1605,  15851,   3780,  26840,\n",
            "           9077,   1733,   1338,  93277,   1044,   1278,   2667,  28342,   1536,\n",
            "           2165,   1934,   2019,   1532,   4773,   3305,   8119,  54149,   1302,\n",
            "          12026,  49350,  39943,   1435,  48500,  90825,  17959,   6309,   3145,\n",
            "           1046,   2159,  31562,   1760,   7873,  27094,   1321,  13006,   6410,\n",
            "           1044,  26304,  16614,  12319,   1605,  19794,   1338,  24877,   7415,\n",
            "           1044,   6580,  15412,   1317,   4206,   1259,  11489,   3686,   3323,\n",
            "           1044,   2127,   2534,  12296,   3884,  29652,   1115,   2744,   4036,\n",
            "          19004,  11692,   1121,   2744,   3330,   1408,   2246,   1319,   1102,\n",
            "          17436,   1302,   1044, 105031,  15299,   2102,  61957,  22214,   1338,\n",
            "         118589,   7607,  26021,  87313,   9134,  17094,   2487,   1319,   1112,\n",
            "          40582,   5370,   1853,   5807,  32449,   1041,  13294,   7796,  12921,\n",
            "           5711,  95511,   6565,  21269,   1278,  14146,   1435,  14183,   2767,\n",
            "           3421,   1357,   1501,   5032,   1046,  12431,   8720,  38276,   1681,\n",
            "          17353,  80046,   1044,   1344,   1411,  48231,  28251,   3642,   4491,\n",
            "          15148,  23568,  16388,   6021,  70468,  29196,  41530,   1747,   1562,\n",
            "          17597,  47821,   3769,  15342,  74045,   3318,   1060,  24613,   1062,\n",
            "           1048,   1046,   1055,   1053,   1885,  24613,   1062,      2]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'advantages': tensor([-0.1950], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1784,  21166,   1562,   2960,  15819,   4395,\n",
            "          22809,   1046,   1531,  14146,  11865,   1278,   5751,   1536,  23288,\n",
            "           1278,   5451,   1307,  11573,   3066,  25217,   5250,  67541,   1505,\n",
            "          59218,   1278,   3686,   2314,   1278,   3804,   3946,  35515,   1044,\n",
            "          86688,   2424,   5029,  51905,  33396,   1046,  58271,   1593,   1044,\n",
            "           2127,   4983,   1261,  41562,   6983,   4108,   1420,  54030,   1044,\n",
            "           1799,   2127,   2715,   2012,   1294,   1278,  10910,   2142,   1046,\n",
            "           1531,   3831,  12334,  72219,   1944,  24511,   1278,   4546,   3816,\n",
            "          57363,  67545,   1505,  40812,  93851,  25157,   1059,   2147,   2224,\n",
            "           1455,  96032,  15202,   1044,   1420,  29025,  10613,  18964,   1278,\n",
            "          18106,   1681,   5965,   1729,  53515,   3066,   1046,  51506,   1513,\n",
            "           2576,   5305,   1044,   1494,  28594,   5349,   1394,  52819,   3675,\n",
            "           1278,  14146,   1626,   4393,   1261,  41530,   5032,   1317,  31544,\n",
            "           1278,   2663,   1044,   2127,   2168,   2629,   2269,   2005,  88251,\n",
            "           1307,   1324,   3890,   1494,   1486,  54237,   1626,  35957,   1408,\n",
            "          40281,   1681,  17919,  11137,   1454,  25636,  13307,  28524,   1044,\n",
            "           2156,   1395,   6727,   1317,   1402,  16232,   7259,   1394,  38576,\n",
            "           1289,   3326,   3403,   1302,   2424,   1505,   1536,   8385,   6369,\n",
            "          50221,   3226,   1058,  16967,   1681,  38528,   5662,   1278,  55907,\n",
            "          22428,   6610,  38669, 110736,   1278,   4127,   1046,   4925,  18964,\n",
            "           1278,   6960,  18106,   1799,  10249,   1317, 112859,   8119,  10235,\n",
            "           1261,  18119,   5216,  17008,  10197,   1454,  74843,   2181,  66505,\n",
            "          45917,   3522,   4837,   1454,  11696,   1394,  41562,  24184,  96048,\n",
            "           1044,   1494,  61050,   1394,   1383,  38394,   2282,   1046,   4493,\n",
            "           1278,  14146,   4139,   1402,  44761,   1294,  18119,   6856,   1626,\n",
            "           1885,  74045,   1561,   1060,  24613,   1062,   1048,   1046,   1053,\n",
            "           1885,  24613,   1062,      2,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5850], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 75263,  74045,   1062,  35322,   1934,   2151,   6908,   1454,   1794,\n",
            "           5449,   1044,  24130,   1261,   6165,   4036,   1317,   1794, 114341,\n",
            "           5751,   1044,   1321,   5662,   7924,   3686,   1394,  41562,   1046,\n",
            "           2182,   2095,   7444,   1317,   1402,   1261,  90122,   4548,   3330,\n",
            "           1435,  20702,   1562,   1794,   4546,   1317,   5807,   1794,   3519,\n",
            "           6309,   1321,   6726,  54030,  93588,   1046,   3730,   1681,   1836,\n",
            "          28069,   1307,  78694,   1505,  41530,  35821,   8033,   1046,   2182,\n",
            "          64897,  16157,  26840,   5305,   2414,   8994,   1261,   3683,   4274,\n",
            "          34745,   1455, 100269,   7924, 111191,  40933,   3285,   1561,   2182,\n",
            "          11383,   1747,   7357,   2181,   2314,   2414,  26873,   1405,   3016,\n",
            "          16798,   1394,   7924,   5266,   1044,   8154,   5384,  74045,   1062,\n",
            "          17061,  13833,   1060,  24613,   1062,   1048,   1046,   1048,   1885,\n",
            "          24613,   1062,      2,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-0.9749], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[  2293,   9825,   4832,   1877,  49250,   2077,   1561,  25280,  33352,\n",
            "           1278,   9614,  10636,   2645,   1261,   5735,  14013,   5125,   2100,\n",
            "           1049,   1046,   1603,   4967,   1394,  36121,   1302,  28263,  16104,\n",
            "          24185,   1256,   1462,   9970, 122922,  17365,  14987,   4036,   2034,\n",
            "          26662,   1394,   5561,  12738,   1046,   4159,   2933,   2034,  20089,\n",
            "           1914,   4312,   1317,   1278,   6298,   5751,   1338,   1050,   1046,\n",
            "           1603, 102282,   1307,  73382,  20317,  24185,   1256,   1462,  32505,\n",
            "          21385,   1317,   5234,  16544,   1032,   1052,  48044,   2383,   1044,\n",
            "           8686,   1044,  21478,   1066,   1044,   1321,   8686,   1747,   6274,\n",
            "           5990,   1046,   8720,  11495,   1593,  27899,   4139,  10982,   5270,\n",
            "           8453,   1338,   1051,   1046,   1603,   9334,  18926,  28263,  24185,\n",
            "           1256,   1462,   8720,   1395,  49410,   1317,   6726,   1794, 114341,\n",
            "           5751,   1317,   1576,  32111,   1032,   1057,   1056,   1049,   1048,\n",
            "           1057,   9528,   2409,  40791,   4878,  11696,   1307,  37474,  26840,\n",
            "           1338,   1052,   1046,   1603,  13958,  27339,   1261,  52546,  12460,\n",
            "          13920,  24185,   1256,   1462,  88258,   9780,   4546,   1317,   8214,\n",
            "           1454,   1278,  10430,   6309,   2782,  11701,   1115,   1454,   6170,\n",
            "           1435,  18119,   7560,   1046,   3886,   1044,   1593,  58254,   7357,\n",
            "          41562,   1044,   1435,   2147,   7513,  11279,   3174,   2181,   1722,\n",
            "           2342,  24130,   1394,   5751,  41562,   1044,   7754,   3147,   8720,\n",
            "           5314,  60199,   1278,   9048,   1454,  57351,  11820,   1338,   1256,\n",
            "          10228,   1317,   4878,  41530,  11696,   1044, 113894,   2725,   6906,\n",
            "           5314,   1736,   7357,   3686,   5059,   2181,   3200,  20964,   1338,\n",
            "           1053,   1046,   1603,   1083,   7985,  38751,   1115,  18244,  24185,\n",
            "           1256,   1462,   9970, 122922,   8616,   4139,   2012,  17656,   2314,\n",
            "          10098,   1809,  16798,   1317,   2229,  54030,  93588,   1395,   3435,\n",
            "           1573,   1290,   2440,   1321,  10098,   4884,   1420,  54030,   2168,\n",
            "           5234,  11915,   9576,   1626,   1885,  74045,   1062,   1534,  24613,\n",
            "           1062,   1048,   1046,   1053,   1885,  24613,   1062,      2,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5850], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1062,   2409,   1395,   1278,   6334,  18106,   1046,\n",
            "           1531,  14146,  73845,   1747,   1278,   8520,   1321,  26840,   1317,\n",
            "           5751,   1321,   3686,   1408,   6245,  34854,   1877,  35853, 114341,\n",
            "           5751,   1520,   2596,  48708,   6309,  26840,   1321,  38576,   1520,\n",
            "           4998,   7867,   1278,  12220,   2782,   2478,  93588,   1974,   1044,\n",
            "           3199,   2453,  13471,   9781,   1435,   2903,   1626,   2892,   1402,\n",
            "          41530,   5032,   1505,   1605,   2342,   1294,   1593,   8516,  89458,\n",
            "          74045,   1561,   1060,  24613,   1062,   1032,   1048,   1046,   1053,\n",
            "           1885,  24613,   1062,      2,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5850], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}]\n",
            "[2025-10-28 10:52:47 IST] inputs are , {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[  2293,   9825,   4832,   1877,  49250,   2077,   1561,  25280,  33352,\n",
            "           1278,   9614,  10636,   2645,   1261,   5735,  14013,   5125,   2100,\n",
            "           1049,   1046,   1603,   4967,   1394,  36121,   1302,  28263,  16104,\n",
            "          24185,   1256,   1462,   9970, 122922,  17365,  14987,   4036,   2034,\n",
            "          26662,   1394,   5561,  12738,   1046,   4159,   2933,   2034,  20089,\n",
            "           1914,   4312,   1317,   1278,   6298,   5751,   1338,   1050,   1046,\n",
            "           1603, 102282,   1307,  73382,  20317,  24185,   1256,   1462,  32505,\n",
            "          21385,   1317,   5234,  16544,   1032,   1052,  48044,   2383,   1044,\n",
            "           8686,   1044,  21478,   1066,   1044,   1321,   8686,   1747,   6274,\n",
            "           5990,   1046,   8720,  11495,   1593,  27899,   4139,  10982,   5270,\n",
            "           8453,   1338,   1051,   1046,   1603,   9334,  18926,  28263,  24185,\n",
            "           1256,   1462,   8720,   1395,  49410,   1317,   6726,   1794, 114341,\n",
            "           5751,   1317,   1576,  32111,   1032,   1057,   1056,   1049,   1048,\n",
            "           1057,   9528,   2409,  40791,   4878,  11696,   1307,  37474,  26840,\n",
            "           1338,   1052,   1046,   1603,  13958,  27339,   1261,  52546,  12460,\n",
            "          13920,  24185,   1256,   1462,  88258,   9780,   4546,   1317,   8214,\n",
            "           1454,   1278,  10430,   6309,   2782,  11701,   1115,   1454,   6170,\n",
            "           1435,  18119,   7560,   1046,   3886,   1044,   1593,  58254,   7357,\n",
            "          41562,   1044,   1435,   2147,   7513,  11279,   3174,   2181,   1722,\n",
            "           2342,  24130,   1394,   5751,  41562,   1044,   7754,   3147,   8720,\n",
            "           5314,  60199,   1278,   9048,   1454,  57351,  11820,   1338,   1256,\n",
            "          10228,   1317,   4878,  41530,  11696,   1044, 113894,   2725,   6906,\n",
            "           5314,   1736,   7357,   3686,   5059,   2181,   3200,  20964,   1338,\n",
            "           1053,   1046,   1603,   1083,   7985,  38751,   1115,  18244,  24185,\n",
            "           1256,   1462,   9970, 122922,   8616,   4139,   2012,  17656,   2314,\n",
            "          10098,   1809,  16798,   1317,   2229,  54030,  93588,   1395,   3435,\n",
            "           1573,   1290,   2440,   1321,  10098,   4884,   1420,  54030,   2168,\n",
            "           5234,  11915,   9576,   1626,   1885,  74045,   1062,   1534,  24613,\n",
            "           1062,   1048,   1046,   1053,   1885,  24613,   1062,      2,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5850], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}\n",
            "[2025-10-28 10:52:47 IST] END _prepare_inputs, keys=['prompt_ids', 'prompt_mask', 'completion_ids', 'completion_mask', 'advantages', 'num_items_in_batch'], prompt_ids.shape=(1, 731), completion_ids.shape=(1, 521)\n",
            "[2025-10-28 10:52:47 IST] ENTER compute_loss, use_liger_loss=False\n",
            "[2025-10-28 10:52:47 IST] ENTER _compute_loss, prompt_ids.shape=(1, 731), completion_ids.shape=(1, 521), loss_type=dapo, beta=0.0, importance_sampling_level=token\n",
            "[2025-10-28 10:52:47 IST] ENTER _get_per_token_logps_and_entropies, input_ids.shape=(1, 1252), attention_mask.shape=(1, 1252), logits_to_keep=521, batch_size=None, compute_entropy=True\n",
            "[2025-10-28 10:52:47 IST] END _get_per_token_logps_and_entropies, logps.shape=(1, 521), entropies=(1, 521)\n",
            "[2025-10-28 10:52:47 IST] END _compute_loss, loss=-0.07187593728303909\n",
            "[2025-10-28 10:52:47 IST] END compute_loss (standard)\n",
            "[2025-10-28 10:52:48 IST] ENTER _prepare_inputs, training=True, _step=1959, len_batch=n/a, si_2\n",
            "[2025-10-28 10:52:48 IST] mode is , train\n",
            "[2025-10-28 10:52:48 IST] generate_every 8 = self.args.steps_per_generation 8 * self.num_iterations 1\n",
            "[2025-10-28 10:52:48 IST] self._step is , 1959\n",
            "[2025-10-28 10:52:48 IST] self._buffered_inputs , [{'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1062,  10107,   1405,   1044,   1278,  18106,   1486,\n",
            "           8031,   1294,  15115,  48065,   2314,   4590,   5751,   1044,   6309,\n",
            "          10317,   1044,   1321,  62183,   3816,   7481,  41530,  33649,  15342,\n",
            "           1411,   2077,   1561,   1060,  74045,   1062,   4393,  11618,  41562,\n",
            "           2479,  10098,   8352,   1321,   4811,   9576,   1044,   1729,   1710,\n",
            "           4150,   1494,   1681,   3683,   1317,  17898,  15342,   1411,   2077,\n",
            "           1561,   1060,  74045,   1062,   7651,   1486,   1278,  30179,  41530,\n",
            "           1046,   2898,   1639,   1044,   1278,  18106,   5978,   1261,  25052,\n",
            "           1321,  25052,   2721,   8070,   1278,  76249,  27223,   1505,   1261,\n",
            "         113940,  21490,   7211,  15342,   1411,   2077,   1062,   1319,  16860,\n",
            "           1044,   1514,   2697,   1605,   4237,   2081,   3686,   2479, 113940,\n",
            "           1681,   2564,   1505,  13591,   3686,   1577,   1885,  74045,   1561,\n",
            "           1060,  24613,   1062,   1048,   1046,   1050,   1053,   1885,  24613,\n",
            "           1062,      2,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([1.3649], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[  1975,   1123,  60087,   2002,  28932,   1054,   4453,   1622,   5764,\n",
            "           1058,  23493,  39893,  32213,   1748,  72191,  39319,   1370,   1885,\n",
            "           1104,   1054,   1561,   1060,   2132,   1062,   1534,   1098,   1062,\n",
            "          25413,   1058,   2259,   1098,   1062,  12082,   1455,   1362,   1736,\n",
            "          12220,   2036,   5751,   1044,   2606,   2168,   1362,   1653,   1317,\n",
            "           9168,   1593,   1875,   5751,   1454,   2036,  24527,   5449,   1063,\n",
            "           3797,   2036,   9150,   2715,   8848,   1317,   2036,   1875,   5751,\n",
            "           1435,  11564,  15342,   2132,   1561,   1060,   2132,   4453,   1622,\n",
            "           5764,   1058,  23493, 101018,   1098,   1062,  25413,  17697,  44119,\n",
            "          23779,   1098,   1062,  84331,   1934,   2586,   4108,   1420,   6726,\n",
            "          12522,  28106,   1294,   5751,   7981,   1046,   3367,   2143,   9150,\n",
            "           7560,   1584,  13330,   1044,   2127,   4139,   1402,   5083,   1317,\n",
            "           7782,   1278,  94892,   1307,   9150,   2586,   1317,   2143,   1875,\n",
            "           5751,  15342,   2132,   1561,   1885,   3285,   1561,   2731,   1975,\n",
            "          18154,   1010,   1060,  74045,   1561,   1060,   1336,   1561,  24187,\n",
            "           1062,   4268,   1722,   4265,   1278,  18106,   2396,   8720,   1321,\n",
            "           1261,  32868,  17697,  19833,   1394,   1278,   5150,  24468,  12460,\n",
            "           3016,  12327,   1261,   1875,  21114,   5751,  15342,   1978,   1561,\n",
            "          24187,   1062,   4268,   8178,   1455,   1278,  32868,   3831,  19833,\n",
            "           1536,   2269, 107209,   1741,   8942,   1278,   3148,  13006,  41562,\n",
            "           1536,  16798,   1394,  16544,   3946,  35515,   1044,  18926,   8686,\n",
            "           1321,   7600,   1307,  11573,   1044,   1321,   2430,  12327,  54030,\n",
            "          93588,  37490,  15342,   1978,   1561,  24187,   1062,   4268,   2224,\n",
            "           3219,   1455,  32868,   1319,   1349,   2667,   1875,  14146,   1041,\n",
            "          25747,   1394,  94892,   1307,   9150,   1317,   1261,   1875,   5751,\n",
            "           1394,  95449,   1794,  68415,   3754,  24527,   5449,   3016,   1494,\n",
            "           2342,  29036,   1317,   6309,   5751,   7981,  15342,   1978,   1561,\n",
            "          24187,   1062,   4668,   1593,   1044,  21622,   1261,  52819,   1455,\n",
            "           1261,   1875,   2965,   6906,  38953,   1435,   1420,  24527,  19833,\n",
            "           1317,   2016,   2015,   1278,  13006, 118808,   9576,   2479,  11573,\n",
            "          18814,   1044,   8686,  42281,   2247,  12431,   1044,   1278,   1875,\n",
            "           2965,  25747,   1394,  94892,   1307,   1747,  24600,   1435,   2903,\n",
            "           1046,   3886,   1044,   1278,   5719,  10103,   7444,   1317,   1402,\n",
            "           1261,  13392,   2108,   2396,  17275,   1317, 124382,   2012,   9576,\n",
            "          15342,   1978,   1561,  24187,   1062,   1073,   1855,  12857,   5257,\n",
            "           1455,   1593,   6836,  14146,   2564,   1321,   5263,   1302,   1395,\n",
            "          32323,   1374,   1317,   2012,   1278,  13006,  35801,   9576,   2479,\n",
            "          18814,   1321,   8686,   1317,   1402,   5949,   1317,   1278,   6309,\n",
            "           1044,   7655,   1047, 104676,   1536,  72144,   2147,  24995,   1047,\n",
            "          18194,   5200,   1046,   1531,  33871,  39852,   1395,   1420,  14183,\n",
            "           1272,  10414,   1307,   2269,   2516,  24527,   1321,   1395,   3226,\n",
            "           1317,  21294,   2269,  17676,  15342,   1978,   1561,   1885,   1336,\n",
            "           1561,   1885,  74045,   1561,   1060,  24613,   1062,   1048,   1046,\n",
            "           1055,   1053,   1885,  24613,   1561,   1975,      2,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-0.1950], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1049,   1046,   1603,  10587,   3711,   3643,\n",
            "           1438,   1462,   1531,  14146,   8720,  38276,   5662,   1261,   1875,\n",
            "           5751,   1321,  11865,   2034,  10098,   9576,   2516,   1435,   1261,\n",
            "           3519,   8686,   1321,  11573,   5451,   1046,   2157,   1681,  41494,\n",
            "           1455,   2127,   2715,   2840,   1278,   3804,   3946,  35515,   1307,\n",
            "           2034,   6309,   1321,   9576,   2314,   2147,   5266,   1338,   1050,\n",
            "           1046,   1603,  11765,  22402,   1438,   1462,  56102,   1044,   1278,\n",
            "           6334,  18106,  79388,   1836,   8686,   4036,   1046,   3626,   1294,\n",
            "           1593,  18106,   1044,   8720,  58568,   1317,  65874,   1044,   1794,\n",
            "          68415,   9705,   1455,   1576,   1055,  10126,   1398,  51615,   1395,\n",
            "          39095,   1454,   1278,   6309,   9528,   3886,   1044,   1875,   9576,\n",
            "           1408,  10098,   1319,   1083,   7985,  93588,   1041,   1584,  11865,\n",
            "           3066,   1278,   2832,   1307,  28342,   7520,  21834,   1046,   2409,\n",
            "          13335,   1317,  27094,   5444,   1046,  33440,   6231,  13664,   1307,\n",
            "           1593,   2832,   1044,  51040,   1584,   1605,   7655,  35801,   1435,\n",
            "           1593,  10045,   2405,   5282,   4616,  25392,  28069,   1307,  41530,\n",
            "           1338,   1051,   1046,   1603,   1069,  39472,  58285,   1321,  19966,\n",
            "          13240,   8713,   1438,   1462,  65874,   6354,   2405,  21294,   1455,\n",
            "          59489,   1032,   1055,   1395,   6298,   1321,  26376,   2782,   1317,\n",
            "           7873,   4527,   4036,   1046,   5646,  15786,   4945,  64624,   2314,\n",
            "           2246,   2019,  13167,   1046,   3886,   1044,   2481,   1402,  35801,\n",
            "           4057,   1408,   1794,   2158,   8686,  10674,   1046,  20398,   1927,\n",
            "           1115,   1044,   8673,  45489,   1435,   5124,  28061,   1505,  24368,\n",
            "           2210,  16902,  11696,   1338,   1052,   1046,   1603,  10696,   3571,\n",
            "           3983,   3795,  15050,  15730,  12606,   6967,  10739,  12694,  10982,\n",
            "           9698,   2832,  44868,   4289,   1317,   2034,  11546,   9620,   7667,\n",
            "           5444,   1044,  14954,  26662,   2481,  66159,   6967,   9916,  23965,\n",
            "          26187,   1046,   4493,  13664,   7444,   1317,   1402,  11090,  40660,\n",
            "          41530,  22802,   1338,   1053,   1046,   1603,  33111,   1302,   1748,\n",
            "          42743,  13920,  11279,   1271,   1093,   1505,   9086,   1603,  32116,\n",
            "           1438,   1704,  22356,  14620,   1408,   1693,   6330,  28061,  74375,\n",
            "          12178,  50487,   1044,   1505,   1278,  17718,  24277,   1046,   1531,\n",
            "          58841,   7693,   1307,  15449,   8164,   1307,   1429,  16539,  90716,\n",
            "           5548,   3039,  24263,  12353,   1398,   1395,   8017,   2613,  44258,\n",
            "          18891,  17718,  26877,  48001,  24850,   9664,  26187,   1626,   1060,\n",
            "          74045,   3318,   8032,   1044,   7283,   1513,   1278,   6960,  11100,\n",
            "           2535,   3988,   1748,  84612,   1317,  24124,   1848,   4597,   9576,\n",
            "           1294,   1278,  18106,  13335,   1317,   1420,  42528,  19190,   1307,\n",
            "           1278,   6594,  34195,  79012,   1307,  25342, 127870,   9044,   1877,\n",
            "         111436,   8516,   1044,   2156,   1584,  29439,   1394,   2991, 121042,\n",
            "           1532,   1307,  41530,  99862,   1261,  19101,   1525,   1311,   1356,\n",
            "           1626,  49766,   3880,   1505,   1605,  24013,  28697,   9750,   8033,\n",
            "           5561,  11696,  12585,   6683,  99862,  13035,  19190,   1626,   1060,\n",
            "          24613,   1062,   1048,   1046,   1050,   1053,   1885,  24613,   1062,\n",
            "              2,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-1.7549], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   6958,   1681,   1261,  68548,   5965,   1321,\n",
            "           3686,   4546,   7980,   3184,   1278,   5150,  24468,  14146,   3690,\n",
            "           1046,   1531,  18119,  10777,   1395,   1317,   3030,   1454,   5751,\n",
            "           1321,  18191,   1278,   2479,   8352,   7125,   1536,  10098,  41562,\n",
            "           1321,   2258,  51905,   4810,  38576,   1505,  17718,  38576,   1044,\n",
            "          11267,   1294,   1455,   3542,   1046,   1349,  70385,   3226,  61134,\n",
            "           1562,   1593,   1058,   1278,   2210,   1307,   1278,  11396,   2782,\n",
            "           2158,   1394,  12276,   1302,   3066,   7211,   2849,   1338,   4380,\n",
            "           1395,   4955,   4804,   1045,  19783,   6683,   3147,   7110, 117176,\n",
            "           1536,   5150,  24468,   4136,   1278,  19467,   1307,   1278,  10914,\n",
            "           8617,   3120,   1605,   3894,   6207,  98391,   3643,   1435,   1261,\n",
            "          10097,   1536,  40878,   1044,   2158,   1044,   6026,  41562,   1321,\n",
            "           2342,   2430,  39792,   6026,  93588,   3009,  93931,   1626,   1784,\n",
            "           9916,   2782,   5662,   2188,   1402,  36840,   1319,  55838,   8091,\n",
            "           1584,  10421,  24992,   2790,   1454,   1278, 125017,   6021,   1574,\n",
            "           1321,  93588,   4139,   5558,  40172,   1454,  30555,   1317,   1261,\n",
            "          14420,  13006,   1046,   1656,   2081,  41530,  35821,  15999,   1044,\n",
            "           1278,   7530,   1319,   1273, 112376,  13006,   1454,  18644,  17049,\n",
            "           3686,   1041,   1710,  14222,   7720,   3816,   1344,  98391,  11133,\n",
            "           2081,   5072,   1039,   3686,   1626,  14859,   1405,   1044,   3746,\n",
            "           3066,   1278,  24722,   1044,   1324,  34873,   2148,   5579,  89149,\n",
            "           1319,   1948,  17960,   5030,  17094,   1395,  18884,   1302,  44761,\n",
            "          44809,   4527,  11820,   1041,   3816,  19294,   1799, 103660,   3746,\n",
            "           1278,   5275,   7771,   2848,   2471,   7357,   6591,  73751,   1562,\n",
            "          10133,   1046,  38276,   1046,   9380,   5315,   3287, 107192,  49241,\n",
            "          10103,   4527,   1044,   2342,   1513,  95199,  24124,   7293,   4023,\n",
            "           1809,   1605,   8971,   4810,  24124,   7805,   1307,   8686,   5751,\n",
            "           4036,   2879,   1809,  13426,   8935,   1317,   1935,   2427,   1638,\n",
            "           6726,   1307,   4454,  89869,   1536,   4119,   3275,   1286,  14022,\n",
            "           2790,  34052,   1046,   1534,   1411,  34053,   1561,   1785,  25186,\n",
            "          23157,  14029,   3907,  21114,   1044,  28621, 111093,   1307,   9741,\n",
            "          50269,   5205,   1597,   2611,  11219,  13988,   1319,   1112,  69911,\n",
            "           8532,   4888,   1302,  15299,  34060,   1109,   5420,   2071,   1317,\n",
            "          12178,   4772,  11110,   3515,  22315,   1321,   7905, 103828,  64655,\n",
            "           2414,   2917,   7435,   1294,   1875,   4810,   2058,   8849,   1041,\n",
            "           2430,   1044,   2200, 109172,   5965,  13625,  16646,  16541,   1046,\n",
            "          12634,  32131,  16925,  63523,   3690,  49543,   1302,  29196,   9743,\n",
            "           1278,  14146,  85639,  35686,   1044,   1457, 107205,   5266,   1294,\n",
            "           2801,   4556,  91291,  37741,   1319,  96480,  26619,   1041,   1294,\n",
            "           8132,   1638,  10678,   2360,   4561,   1105,   1307,   6089,   2087,\n",
            "           2782,   1317,   1639,   1505,   8491,   1605,  15851,   3780,  26840,\n",
            "           9077,   1733,   1338,  93277,   1044,   1278,   2667,  28342,   1536,\n",
            "           2165,   1934,   2019,   1532,   4773,   3305,   8119,  54149,   1302,\n",
            "          12026,  49350,  39943,   1435,  48500,  90825,  17959,   6309,   3145,\n",
            "           1046,   2159,  31562,   1760,   7873,  27094,   1321,  13006,   6410,\n",
            "           1044,  26304,  16614,  12319,   1605,  19794,   1338,  24877,   7415,\n",
            "           1044,   6580,  15412,   1317,   4206,   1259,  11489,   3686,   3323,\n",
            "           1044,   2127,   2534,  12296,   3884,  29652,   1115,   2744,   4036,\n",
            "          19004,  11692,   1121,   2744,   3330,   1408,   2246,   1319,   1102,\n",
            "          17436,   1302,   1044, 105031,  15299,   2102,  61957,  22214,   1338,\n",
            "         118589,   7607,  26021,  87313,   9134,  17094,   2487,   1319,   1112,\n",
            "          40582,   5370,   1853,   5807,  32449,   1041,  13294,   7796,  12921,\n",
            "           5711,  95511,   6565,  21269,   1278,  14146,   1435,  14183,   2767,\n",
            "           3421,   1357,   1501,   5032,   1046,  12431,   8720,  38276,   1681,\n",
            "          17353,  80046,   1044,   1344,   1411,  48231,  28251,   3642,   4491,\n",
            "          15148,  23568,  16388,   6021,  70468,  29196,  41530,   1747,   1562,\n",
            "          17597,  47821,   3769,  15342,  74045,   3318,   1060,  24613,   1062,\n",
            "           1048,   1046,   1055,   1053,   1885,  24613,   1062,      2]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'advantages': tensor([-0.1950], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1561,   1784,  21166,   1562,   2960,  15819,   4395,\n",
            "          22809,   1046,   1531,  14146,  11865,   1278,   5751,   1536,  23288,\n",
            "           1278,   5451,   1307,  11573,   3066,  25217,   5250,  67541,   1505,\n",
            "          59218,   1278,   3686,   2314,   1278,   3804,   3946,  35515,   1044,\n",
            "          86688,   2424,   5029,  51905,  33396,   1046,  58271,   1593,   1044,\n",
            "           2127,   4983,   1261,  41562,   6983,   4108,   1420,  54030,   1044,\n",
            "           1799,   2127,   2715,   2012,   1294,   1278,  10910,   2142,   1046,\n",
            "           1531,   3831,  12334,  72219,   1944,  24511,   1278,   4546,   3816,\n",
            "          57363,  67545,   1505,  40812,  93851,  25157,   1059,   2147,   2224,\n",
            "           1455,  96032,  15202,   1044,   1420,  29025,  10613,  18964,   1278,\n",
            "          18106,   1681,   5965,   1729,  53515,   3066,   1046,  51506,   1513,\n",
            "           2576,   5305,   1044,   1494,  28594,   5349,   1394,  52819,   3675,\n",
            "           1278,  14146,   1626,   4393,   1261,  41530,   5032,   1317,  31544,\n",
            "           1278,   2663,   1044,   2127,   2168,   2629,   2269,   2005,  88251,\n",
            "           1307,   1324,   3890,   1494,   1486,  54237,   1626,  35957,   1408,\n",
            "          40281,   1681,  17919,  11137,   1454,  25636,  13307,  28524,   1044,\n",
            "           2156,   1395,   6727,   1317,   1402,  16232,   7259,   1394,  38576,\n",
            "           1289,   3326,   3403,   1302,   2424,   1505,   1536,   8385,   6369,\n",
            "          50221,   3226,   1058,  16967,   1681,  38528,   5662,   1278,  55907,\n",
            "          22428,   6610,  38669, 110736,   1278,   4127,   1046,   4925,  18964,\n",
            "           1278,   6960,  18106,   1799,  10249,   1317, 112859,   8119,  10235,\n",
            "           1261,  18119,   5216,  17008,  10197,   1454,  74843,   2181,  66505,\n",
            "          45917,   3522,   4837,   1454,  11696,   1394,  41562,  24184,  96048,\n",
            "           1044,   1494,  61050,   1394,   1383,  38394,   2282,   1046,   4493,\n",
            "           1278,  14146,   4139,   1402,  44761,   1294,  18119,   6856,   1626,\n",
            "           1885,  74045,   1561,   1060,  24613,   1062,   1048,   1046,   1053,\n",
            "           1885,  24613,   1062,      2,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5850], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 75263,  74045,   1062,  35322,   1934,   2151,   6908,   1454,   1794,\n",
            "           5449,   1044,  24130,   1261,   6165,   4036,   1317,   1794, 114341,\n",
            "           5751,   1044,   1321,   5662,   7924,   3686,   1394,  41562,   1046,\n",
            "           2182,   2095,   7444,   1317,   1402,   1261,  90122,   4548,   3330,\n",
            "           1435,  20702,   1562,   1794,   4546,   1317,   5807,   1794,   3519,\n",
            "           6309,   1321,   6726,  54030,  93588,   1046,   3730,   1681,   1836,\n",
            "          28069,   1307,  78694,   1505,  41530,  35821,   8033,   1046,   2182,\n",
            "          64897,  16157,  26840,   5305,   2414,   8994,   1261,   3683,   4274,\n",
            "          34745,   1455, 100269,   7924, 111191,  40933,   3285,   1561,   2182,\n",
            "          11383,   1747,   7357,   2181,   2314,   2414,  26873,   1405,   3016,\n",
            "          16798,   1394,   7924,   5266,   1044,   8154,   5384,  74045,   1062,\n",
            "          17061,  13833,   1060,  24613,   1062,   1048,   1046,   1048,   1885,\n",
            "          24613,   1062,      2,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([-0.9749], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[  2293,   9825,   4832,   1877,  49250,   2077,   1561,  25280,  33352,\n",
            "           1278,   9614,  10636,   2645,   1261,   5735,  14013,   5125,   2100,\n",
            "           1049,   1046,   1603,   4967,   1394,  36121,   1302,  28263,  16104,\n",
            "          24185,   1256,   1462,   9970, 122922,  17365,  14987,   4036,   2034,\n",
            "          26662,   1394,   5561,  12738,   1046,   4159,   2933,   2034,  20089,\n",
            "           1914,   4312,   1317,   1278,   6298,   5751,   1338,   1050,   1046,\n",
            "           1603, 102282,   1307,  73382,  20317,  24185,   1256,   1462,  32505,\n",
            "          21385,   1317,   5234,  16544,   1032,   1052,  48044,   2383,   1044,\n",
            "           8686,   1044,  21478,   1066,   1044,   1321,   8686,   1747,   6274,\n",
            "           5990,   1046,   8720,  11495,   1593,  27899,   4139,  10982,   5270,\n",
            "           8453,   1338,   1051,   1046,   1603,   9334,  18926,  28263,  24185,\n",
            "           1256,   1462,   8720,   1395,  49410,   1317,   6726,   1794, 114341,\n",
            "           5751,   1317,   1576,  32111,   1032,   1057,   1056,   1049,   1048,\n",
            "           1057,   9528,   2409,  40791,   4878,  11696,   1307,  37474,  26840,\n",
            "           1338,   1052,   1046,   1603,  13958,  27339,   1261,  52546,  12460,\n",
            "          13920,  24185,   1256,   1462,  88258,   9780,   4546,   1317,   8214,\n",
            "           1454,   1278,  10430,   6309,   2782,  11701,   1115,   1454,   6170,\n",
            "           1435,  18119,   7560,   1046,   3886,   1044,   1593,  58254,   7357,\n",
            "          41562,   1044,   1435,   2147,   7513,  11279,   3174,   2181,   1722,\n",
            "           2342,  24130,   1394,   5751,  41562,   1044,   7754,   3147,   8720,\n",
            "           5314,  60199,   1278,   9048,   1454,  57351,  11820,   1338,   1256,\n",
            "          10228,   1317,   4878,  41530,  11696,   1044, 113894,   2725,   6906,\n",
            "           5314,   1736,   7357,   3686,   5059,   2181,   3200,  20964,   1338,\n",
            "           1053,   1046,   1603,   1083,   7985,  38751,   1115,  18244,  24185,\n",
            "           1256,   1462,   9970, 122922,   8616,   4139,   2012,  17656,   2314,\n",
            "          10098,   1809,  16798,   1317,   2229,  54030,  93588,   1395,   3435,\n",
            "           1573,   1290,   2440,   1321,  10098,   4884,   1420,  54030,   2168,\n",
            "           5234,  11915,   9576,   1626,   1885,  74045,   1062,   1534,  24613,\n",
            "           1062,   1048,   1046,   1053,   1885,  24613,   1062,      2,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5850], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}, {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1062,   2409,   1395,   1278,   6334,  18106,   1046,\n",
            "           1531,  14146,  73845,   1747,   1278,   8520,   1321,  26840,   1317,\n",
            "           5751,   1321,   3686,   1408,   6245,  34854,   1877,  35853, 114341,\n",
            "           5751,   1520,   2596,  48708,   6309,  26840,   1321,  38576,   1520,\n",
            "           4998,   7867,   1278,  12220,   2782,   2478,  93588,   1974,   1044,\n",
            "           3199,   2453,  13471,   9781,   1435,   2903,   1626,   2892,   1402,\n",
            "          41530,   5032,   1505,   1605,   2342,   1294,   1593,   8516,  89458,\n",
            "          74045,   1561,   1060,  24613,   1062,   1032,   1048,   1046,   1053,\n",
            "           1885,  24613,   1062,      2,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5850], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}]\n",
            "[2025-10-28 10:52:48 IST] inputs are , {'prompt_ids': tensor([[     1,      3,     25,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "             24,     24,     24,     24,     24,     24,     24,     24,     24,\n",
            "           4568,   1584,   4265,   1420,  16023,  18106,   1321,   6334,  18106,\n",
            "          24300,   2396,   1420,  47386,   5700,  14146,   3831,  12334,   1321,\n",
            "           1261,  14146,   1626,   4380,  14146,   1710,   1402,   5250,   1261,\n",
            "          44761,  14146,   1505,   1261,  41530,   5032,   1338,   1358,   9825,\n",
            "          14256,   1032,   1010, 113873,   1261,  14381,   1455,   1278,  14146,\n",
            "           1395,   1261,  41530,   5032,   1267,   1785,   3542,   1317,   7137,\n",
            "           1278,  14381,   1307,  41530,   1636,   2715,   3648,   1321,  26812,\n",
            "           1278,   8516,   1321,   4305,   1261,  38528,   1626,  23269,   5257,\n",
            "           1636,   3219,   2744,   1321,   3387,   7900,   1307,   1278,   2937,\n",
            "           1321,   4305,   1261,   2937,   3463,   3016,  38528,   2314,   1278,\n",
            "           2937,   1626,  12791,   1455,   1278, 119291,   4213,   1307,  14381,\n",
            "           1584,   1032,   1048,   1046,   1048,   1044,   1032,   1048,   1046,\n",
            "           1050,   1053,   1044,   1032,   1048,   1046,   1053,   1044,   1032,\n",
            "           1048,   1046,   1055,   1053,   1044,   1032,   1049,   1046,   1048,\n",
            "           1267,   1784,  38528,   2832,   2715,   1402,  56249,   3746,   1534,\n",
            "          74045,   1062,   2259,  74045,   1062,  19762,   1010,  16734,   1278,\n",
            "           2778,   4832,   2715,   1402,  56249,   1294,   1534,  24613,   1062,\n",
            "           2259,  24613,   1062,  19762,   1267,  20396,  15050,   1737,   1032,\n",
            "           1010,  49250,   2077,   1062,   4380,   1395,   2036,  38528,   1885,\n",
            "          74045,   1561,   1060,  24613,   1062,   1048,   1046,   1055,   1053,\n",
            "           1885,  24613,   3318,  94883,  39319,   1370,   1737,   5150,  24468,\n",
            "           1044,  65874,  21371,   1046,  24665,   1044,  65874,   1046,   8720,\n",
            "          38276,   3226,   1046,   1362,   8628,   1321,   2534,   1317,   6726,\n",
            "           2036, 114341,   5751,   1809,   5807,   7873,   4527,  21166,   1046,\n",
            "          22977, 111742,   1046,   2898,  10098,   1044,  10678,  10500,   3804,\n",
            "           3946,  35515,   1044,   3519,   8686,   1044,   1321,   5451,   1307,\n",
            "          11573,   1046,   1032,   1053,   1052,   1055,   6193,   3152,  43122,\n",
            "           1117,   1270,   1046,   3711,   3205,   1046,  16431,   1636,   1046,\n",
            "           5675,   1681,   2143,   1875,   5751,   1063,  59489,   1032,   1057,\n",
            "           1056,   1049,   1048,   1057,   1046,  28263,  12220,   1046,  31334,\n",
            "           1636,   2479,   1261,  21194,   6309,  70270,   2156,   1505,   5807,\n",
            "           2143,   3519,   1925,   1063,  40659,   1278,   3519,   1925,   1046,\n",
            "           7490,   3180,   5257,  93588,   1974,   1317,   2036,  11396,   1032,\n",
            "           1050,   1048,   1054,   1045,   1053,   1053,   1053,   1045,   1048,\n",
            "           1049,   1052,   1050,   1046,   1362,   6483,   5949,  54030,  93588,\n",
            "           1321,  11865,   2143,   8686,  52671,   1278,   2879,   1046,   3213,\n",
            "           7534,  10477,   1261,  38576,   1394,   1278,   5751,   4036,   3746,\n",
            "           1261,   4517,   7334,   1046,  11560,   1046,   9076,   1729,   6185,\n",
            "           3226,   1044,   2481,   1636,  10500,   2036,   7873,   4527,  65342,\n",
            "           1063,      4]], device='cuda:0'), 'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'completion_ids': tensor([[ 49250,   2077,   1062,   2409,   1395,   1278,   6334,  18106,   1046,\n",
            "           1531,  14146,  73845,   1747,   1278,   8520,   1321,  26840,   1317,\n",
            "           5751,   1321,   3686,   1408,   6245,  34854,   1877,  35853, 114341,\n",
            "           5751,   1520,   2596,  48708,   6309,  26840,   1321,  38576,   1520,\n",
            "           4998,   7867,   1278,  12220,   2782,   2478,  93588,   1974,   1044,\n",
            "           3199,   2453,  13471,   9781,   1435,   2903,   1626,   2892,   1402,\n",
            "          41530,   5032,   1505,   1605,   2342,   1294,   1593,   8516,  89458,\n",
            "          74045,   1561,   1060,  24613,   1062,   1032,   1048,   1046,   1053,\n",
            "           1885,  24613,   1062,      2,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11,     11,\n",
            "             11,     11,     11,     11,     11,     11,     11,     11]],\n",
            "       device='cuda:0'), 'completion_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'advantages': tensor([0.5850], device='cuda:0'), 'num_items_in_batch': tensor(2116, device='cuda:0')}\n",
            "[2025-10-28 10:52:48 IST] END _prepare_inputs, keys=['prompt_ids', 'prompt_mask', 'completion_ids', 'completion_mask', 'advantages', 'num_items_in_batch'], prompt_ids.shape=(1, 731), completion_ids.shape=(1, 521)\n",
            "[2025-10-28 10:52:48 IST] ENTER compute_loss, use_liger_loss=False\n",
            "[2025-10-28 10:52:48 IST] ENTER _compute_loss, prompt_ids.shape=(1, 731), completion_ids.shape=(1, 521), loss_type=dapo, beta=0.0, importance_sampling_level=token\n",
            "[2025-10-28 10:52:48 IST] ENTER _get_per_token_logps_and_entropies, input_ids.shape=(1, 1252), attention_mask.shape=(1, 1252), logits_to_keep=521, batch_size=None, compute_entropy=True\n",
            "[2025-10-28 10:52:49 IST] END _get_per_token_logps_and_entropies, logps.shape=(1, 521), entropies=(1, 521)\n",
            "[2025-10-28 10:52:49 IST] END _compute_loss, loss=-0.021009890362620354\n",
            "[2025-10-28 10:52:49 IST] END compute_loss (standard)\n",
            "[2025-10-28 10:52:49 IST] ENTER log, keys=['loss', 'grad_norm', 'learning_rate']\n",
            "[2025-10-28 10:52:49 IST] END log\n",
            "[2025-10-28 10:52:49 IST] ENTER _save_checkpoint\n",
            "[2025-10-28 10:52:49 IST] _save_checkpoint created model card, model_name=Voxtral-Mini-3B-2507\n",
            "[2025-10-28 10:52:51 IST] END _save_checkpoint\n",
            "[2025-10-28 10:52:51 IST] ENTER log, keys=['train_runtime', 'train_samples_per_second', 'train_steps_per_second', 'total_flos', 'train_loss']\n",
            "[2025-10-28 10:52:51 IST] END log\n"
          ]
        }
      ],
      "source": [
        "user_confirm = input(\"enter y or n \")\n",
        "if user_confirm==\"y\":\n",
        "  op = trainer.train()\n",
        "else:\n",
        "  op = \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()  # finalize card/metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229,
          "referenced_widgets": [
            "82c076099c844d26b3f131734db2e1cd",
            "06a51c8984fb4679974a63d0c8a8d141",
            "9a03d411cb9547f3a14dc8a3b9a887e1",
            "8af14d7c14f146ffb0c2fe8e76a142f9",
            "696bf120d98a4f3fa47b877ead0f4dd7",
            "f49ec2b775bb4fb9a979ff8b9b8e80a0",
            "70fa49fc3bcc4f219c1704a85de60015",
            "ec54189f66fa4aa6a9ed9936ab86c503",
            "8b01d5564f044c4593358aa66a6749bd",
            "a5ce303dccd347d5aca0176134a88cc2",
            "bd1d24425d254bb9a87591a5b82f8303",
            "d0054d1589004be3abe9ff041de4cf20",
            "c18addc607a14abda767aaf0fb1b2a15",
            "29a75476d22e42b293f2f68a7ce2cfe5",
            "11afb20ccef446188dcb6deeaa489eed",
            "cb5ba2ec76db45539bc6287e83e118b4",
            "e27d827e54ad4e738dcd00d02b8b74b6",
            "06ebc0afde74427d8c48059ab8c3c10d",
            "1bf922ae9346419a836097c4674c890c",
            "e4fccd58a33b4b4083dafb53b74115f1",
            "2d0929ba118c4b43b777fb8ff5b5047a",
            "ed521adb81114ad2b718571873c91068",
            "ac82d77fb4a94b73b0805db452f05b95",
            "8d45f0d8cb5d4e2fa23be4674e73efba",
            "e70270e412e646b3a365671af9d8ecac",
            "ad555aa3c1a64ef0930edbf9dae90b14",
            "09a732e4bbf04299b7f4b63b441a9208",
            "e75d68595d7740c7a6693ec1f545823a",
            "a084dbcc785745cb978c5be1e22164df",
            "2fd40a9fc6fb4d2781218838e5158f2f",
            "c1c6e8b059404bd7b9e437a24ae5009e",
            "901319be1f454497adb0ef55315fb064",
            "4eff85e822b64c1bb587466d42a0b61d",
            "f844135771b043318f205ba36febcff3",
            "5381d40b628f4699bcef5c117f4a899b",
            "851096000b33496f8acbd434e8af1e4b",
            "4e814df01f2d4e7cac77bf795f3427b6",
            "9cfb2011b98741cb99d59a723db8b258",
            "1cd7223b6c744deaa7d920e1775bf7ae",
            "b12933bcf4694a1f9632fd264bfb1691",
            "f915512e59c843b285ccc8d23afc96c4",
            "f556854e4b1240739f91b7ecf3317185",
            "0265ce82cd0744af816fd4a08e0c402c",
            "57b5196c64324c70a51ad2098b2c3081",
            "2372d7a26f9f4f818e0b9f27caedd73c",
            "1b08d91ac08f40dd8bd0c6947830dbc8",
            "06799b01fa5d44939cf8fb928cbf74d8",
            "a3a4844289004bc8ba03105ae46c0e0f",
            "41a677140b3e40a1888c01cb130a6f21",
            "84a8392ca05d416ba3a0167b7ebc0f1e",
            "5270fa41350440d5abcd402414cbc2d9",
            "35c80f1eb3ea455f80c3ac77252edfc1",
            "4a46921da5564dfc85366d4be163c268",
            "c1f981d31b6e4dc8ba1eb229defb71f5",
            "c89751bafb87438ea473380472e805d7"
          ]
        },
        "id": "elDpzUDMV30I",
        "outputId": "bd8aa801-49cd-4b58-bf0f-6363502b1a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82c076099c844d26b3f131734db2e1cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0054d1589004be3abe9ff041de4cf20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...-Mini-3B-2507/tekken.json: 100%|##########| 14.9MB / 14.9MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac82d77fb4a94b73b0805db452f05b95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...adapter_model.safetensors:  56%|#####5    | 16.5MB / 29.6MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f844135771b043318f205ba36febcff3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...3B-2507/training_args.bin: 100%|##########| 7.25kB / 7.25kB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2372d7a26f9f4f818e0b9f27caedd73c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/amritansh/Voxtral-Mini-3B-2507/commit/a2991f99db6b07364788f151bfe93740cdde4643', commit_message='End of training', commit_description='', oid='a2991f99db6b07364788f151bfe93740cdde4643', pr_url=None, repo_url=RepoUrl('https://huggingface.co/amritansh/Voxtral-Mini-3B-2507', endpoint='https://huggingface.co', repo_type='model', repo_id='amritansh/Voxtral-Mini-3B-2507'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "op"
      ],
      "metadata": {
        "id": "5VKRo3te72xS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86d45349-248a-4790-9020-a3994a9e1ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=245, training_loss=0.05613947884768856, metrics={'train_runtime': 12398.112, 'train_samples_per_second': 0.02, 'train_steps_per_second': 0.02, 'total_flos': 0.0, 'train_loss': 0.05613947884768856})"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## pushing model to hub"
      ],
      "metadata": {
        "id": "05JYeO2YRkq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model and processor\n",
        "save_model_dir = \"/content/save_model_dir/\"\n",
        "model.save_pretrained(save_model_dir)\n",
        "processor.save_pretrained(save_model_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaWIKvmlTzjP",
        "outputId": "b38013ec-bc99-4a27-9a4b-02fe86a2f57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_sanitize = model_name.replace(\"/\",\"_\").replace(\"-\",\"_\")"
      ],
      "metadata": {
        "id": "908rHIDYUQVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_name = f\"amritansh/grpo_{model_name_sanitize}_v1\"  # e.g. \"alice/my-llm-lora\""
      ],
      "metadata": {
        "id": "4nL2fLybUIhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model"
      ],
      "metadata": {
        "id": "eS9USbWTU4o9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor.push_to_hub(repo_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182,
          "referenced_widgets": [
            "c5c1c5ae8eef462ba1ab4ce3c6f281bf",
            "2db255e47faa4a159d36170e2117fb5a",
            "96f1f16df9544ab2b00c67af9268897d",
            "f3af186f537a4784b4fb2816459a5878",
            "f65315c670b84be49d5801c3fc601b3e",
            "1d67f2f3e1334004b701e098e326c093",
            "1e502b92f9b846c9a61b8f2f8dd04882",
            "d6bd979179304d67b0ea506c9636d53f",
            "ee62cd7249f14cad9c50bd7f19707790",
            "a643c9495a214c3cadd105b47f028330",
            "e33669c44d9547409d9af80a64fb0995",
            "c8ea0821eaa444f1868a66665f35b139",
            "2c760ee00e04454aa8de3179551bf02c",
            "dddf7f3d877a45dfb0a095d9ebde3f6f",
            "476dbc9b146341088f18efbcd60918d6",
            "f9e9ecae22214b7d8fddc014ee5e9077",
            "7de71471abfe41169142bcb45809f2a0",
            "3137090f3fe148279a2cf88fc45fcc56",
            "ca87287650a3449785f8a78b65d3f365",
            "9ed0ebd734e0403ab1eaedfdc96acdfd",
            "a4c7581555bd4ecbbc286317b066fc64",
            "1b12ae0da2c94060bd759e055208ccf1",
            "0a2ce5cc11d84baab07a2b2920a821b1",
            "ee01eed854284bc79c01095c9f639566",
            "6cf08bfa102249519cff858c9174adc2",
            "222b9bc718e642028ba8965f39e5bb66",
            "4bc62fdf0b834ba1a53a3adb1f883778",
            "f72634e4185146039767b9c467a52389",
            "d5d9fc8eae004be7bd3949e780f0e94f",
            "1dbf0534aaf244b4bd98ee399a7dbf2a",
            "06cd2539e58546f9b5070376a8e26221",
            "78659ab790234d31ae8061a160ccb5c8",
            "803f4c48788949acab6e0e432829b353"
          ]
        },
        "id": "ut5r8MhoUXw8",
        "outputId": "4f3ce8f0-38bc-4e11-8b14-0ac7cd3202b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5c1c5ae8eef462ba1ab4ce3c6f281bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8ea0821eaa444f1868a66665f35b139"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  /tmp/tmpclavfn63/tekken.json:  92%|#########2| 13.7MB / 14.9MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a2ce5cc11d84baab07a2b2920a821b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/amritansh/grpo_mistralai_Voxtral_Mini_3B_2507_v1/commit/c698010fd29c5fe0545ed168095198aa20b00a3f', commit_message='Upload processor', commit_description='', oid='c698010fd29c5fe0545ed168095198aa20b00a3f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/amritansh/grpo_mistralai_Voxtral_Mini_3B_2507_v1', endpoint='https://huggingface.co', repo_type='model', repo_id='amritansh/grpo_mistralai_Voxtral_Mini_3B_2507_v1'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(repo_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "abadce50c81e40eda60df822303f8534",
            "248b6c541c6243f686861b2b62bea23d",
            "4bfb9c0353f4489b8ddbdd45b52b61b9",
            "66676831ccf44f13a669fad0803c508e",
            "7f65fb1642144cb382830d0b95d7d362",
            "da00ffcae94247df9d919d49a96d0a12",
            "111d79f268654472847f0d9044316c57",
            "68d2a66a47df4d6a818a268dfa4400c3",
            "21b4afe189fc40abb1c8997a9a3f6c58",
            "d69977cde88543fcb3a2a69d844107b9",
            "f30e95e458294fe49f53f113f725f217",
            "a40ff558992c4b0ea6aef13d4fdafda5",
            "d4a4bd3eb7f141c18813d868ddcf7b51",
            "c7676629db1147b58b288fd797fdf4ab",
            "5e106a5754d94831b2746f5264fb444e",
            "c334f2a9824c41258e4e993e3aa46656",
            "37860c269add40d7ba70b133717f092a",
            "ba927acc95c44fbca915ae762b0b0f2b",
            "da24711c238440e098f058253531f41a",
            "3c0c69fc2be04419b7d863844d05a33d",
            "09403815db554310aa2ffcfea05b5986",
            "2077ae72f0084258a474a06274a9a653",
            "8ee706a6e4084e2799e28fc157ba8b10",
            "e445d6097de847ffac154d0f8498f3f4",
            "f8a51965fc4d4c97aa6d6ba87b420707",
            "dd22a828590148d48e1e9120ef0b2e32",
            "336ba06fc2284275aa02264c68f6579c",
            "1cff95d7484a4a21ba878d36b40d30fa",
            "ec9ff78b3d7f42e1a08d1a5e3d8c798e",
            "b827eab8ef3d41f390c93ad1fec2ad69",
            "61ace05b85b441c6b1dff84865b7fcf8",
            "442f49e77dd24302a5206c732852d1fc",
            "fed65c292894413797ec0bcef4f00755",
            "c9176756727041a2875df69ec861d57e",
            "8688cfe1de5b4264a24a599ed588355a",
            "1243b6eeed0f403f9d6df30a28136083",
            "adc6fe8d692d46b384ad02050047b4c9",
            "d4f9e61fbbfd4cfaab78c41129584d8e",
            "336debe4d0a644898a013767f7b52790",
            "d922b4f2bf8d423b9e2b5842c957ad1b",
            "8164ab8606384a4988910b07475e7248",
            "36e9197d3b6b4f339134d740cdd0a5f2",
            "f9ef047383cf4b97a77b5a3c4a1cbb3b",
            "cb0c4167976b452487a37af5729be8a1",
            "75b7232e0607431bb6704d9156bfaf40",
            "15aa92076c8a450a88d6382976848996",
            "abe429e30ea646cda6438024013d307f",
            "a57bd0940f534970a5af8324a872623f",
            "795c8e94adcb48a392a6fbe096d5315f",
            "1f73dbc6328244e08f21c13353a8771a",
            "8fbe06cbdc444c919a368f6e22933e28",
            "f3c3bd19827949ad9a20234e519da78a",
            "0353a8c2832d420f8b50146c8758ffc7",
            "e9eb793dc676492b8ba2b71f626e8234",
            "aa04e123abc744dd9dd404870e1380f5"
          ]
        },
        "id": "owwoy0z-VIdR",
        "outputId": "f08c5001-932b-4cf6-d0fb-49dd5fdf06e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abadce50c81e40eda60df822303f8534"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a40ff558992c4b0ea6aef13d4fdafda5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ee706a6e4084e2799e28fc157ba8b10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...0001-of-00002.safetensors:   0%|          |  647kB / 5.00GB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9176756727041a2875df69ec861d57e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...0002-of-00002.safetensors:   0%|          | 8.37MB / 4.39GB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75b7232e0607431bb6704d9156bfaf40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/amritansh/grpo_mistralai_Voxtral_Mini_3B_2507_v1/commit/5851b47a46dd24a6129a59ac4e92fe2e7cc05a09', commit_message='Upload VoxtralForConditionalGeneration', commit_description='', oid='5851b47a46dd24a6129a59ac4e92fe2e7cc05a09', pr_url=None, repo_url=RepoUrl('https://huggingface.co/amritansh/grpo_mistralai_Voxtral_Mini_3B_2507_v1', endpoint='https://huggingface.co', repo_type='model', repo_id='amritansh/grpo_mistralai_Voxtral_Mini_3B_2507_v1'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "uh61gHPFSNTa",
        "outputId": "c5c0baf8-c23c-4f48-bc1a-e9c9654da518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.voxtral.modeling_voxtral.VoxtralForConditionalGeneration"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>transformers.models.voxtral.modeling_voxtral.VoxtralForConditionalGeneration</b><br/>def _wrapped_call_impl(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/transformers/models/voxtral/modeling_voxtral.py</a>The Voxtral model, which consists of Whisper encoder, a multi-modal projector and a LLama language model.\n",
              "\n",
              "This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the\n",
              "library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads\n",
              "etc.)\n",
              "\n",
              "This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass.\n",
              "Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage\n",
              "and behavior.\n",
              "\n",
              "Parameters:\n",
              "    config ([`VoxtralForConditionalGeneration`]):\n",
              "        Model configuration class with all the parameters of the model. Initializing with a config file does not\n",
              "        load the weights associated with the model, only the configuration. Check out the\n",
              "        [`~PreTrainedModel.from_pretrained`] method to load the model weights.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 396);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "isinstance(model, PeftModel)   # True => adapters are active"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrsJHLD5YkSw",
        "outputId": "254a3a0e-be6b-411c-d106-a290f590c099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "any(\"lora_\" in n for n, p in model.named_parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evIRY6d_Yopw",
        "outputId": "23c78668-bd59-4911-c9d5-156ca14b8fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"Saving model to {save_model_dir}\")\n",
        "trainer.save_model()\n",
        "processor.save_pretrained(save_model_dir)"
      ],
      "metadata": {
        "id": "8uUiD-cETD-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Colxz9TAVMsi"
      },
      "source": [
        "And now with the LoRA we just trained with GRPO - we first save the LoRA first!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL-BcuB1VLIv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "489abee7-8c76-4759-c219-ec5909d610ee"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'VoxtralForConditionalGeneration' object has no attribute 'save_lora'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1839700272.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_lora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"grpo_{model_name_sanitize }\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1961\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1962\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1963\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'VoxtralForConditionalGeneration' object has no attribute 'save_lora'"
          ]
        }
      ],
      "source": [
        "model.save_lora(f\"grpo_{model_name_sanitize }\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Verify LoRA is actually trained!\n",
        "\n",
        "from safetensors import safe_open\n",
        "\n",
        "tensors = {}\n",
        "with safe_open(\"grpo_saved_lora/adapter_model.safetensors\", framework = \"pt\") as f:\n",
        "    # Verify both A and B are non zero\n",
        "    for key in f.keys():\n",
        "        tensor = f.get_tensor(key)\n",
        "        n_zeros = (tensor == 0).sum() / tensor.numel()\n",
        "        assert(n_zeros.item() != tensor.numel())"
      ],
      "metadata": {
        "id": "oYEGorvaR62p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " model.save_pretrained_merged(\"finetuned_model\", tokenizer, save_method = \"mxfp4\")"
      ],
      "metadata": {
        "id": "GBA84cPpRwf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge and push to hub in mxfp4 4bit format\n",
        "if Fa:\n",
        "\n",
        "if False: model.push_to_hub_merged(\"repo_id/repo_name\", tokenizer, token = \"hf...\", save_method = \"mxfp4\")\n",
        "\n",
        "# Merge and push to hub in 16bit\n",
        "if False:\n",
        "    model.save_pretrained_merged(\"finetuned_model\", tokenizer, save_method = \"merged_16bit\")\n",
        "if False: # Pushing to HF Hub\n",
        "    model.push_to_hub_merged(\"hf/gpt-oss-finetune\", tokenizer, save_method = \"merged_16bit\", token = \"\")"
      ],
      "metadata": {
        "id": "Eo2Ege5SRl-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gen_ip[0])"
      ],
      "metadata": {
        "id": "jZppxKFe8ICa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87bRzIiVoXwS"
      },
      "outputs": [],
      "source": [
        "### replicating GRPO trainer function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMGA1vIgLgRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4462d6ac-f3bf-467c-a47a-d27b7e787b73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['audio', 'answer', 'prompt'],\n",
              "    num_rows: 3\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "daudio_new_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw7dEt8sZTnG"
      },
      "outputs": [],
      "source": [
        "prompts = [x for x in daudio_new_dataset['prompt']][0:2]\n",
        "images = None\n",
        "audios = [x for x in daudio_new_dataset['audio']][0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhsscBmKpyaA"
      },
      "outputs": [],
      "source": [
        "from itertools import takewhile\n",
        "from typing import Any, Callable, Optional, TypeVar, Union\n",
        "from transformers import PreTrainedTokenizerBase, ProcessorMixin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40ffO2dPaguo"
      },
      "outputs": [],
      "source": [
        "max_prompt_length=128*3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_completion_length = 128*5\n",
        "generation_kwargs = {\n",
        "    \"max_new_tokens\": max_completion_length,\n",
        "    \"do_sample\": True,\n",
        "    \"pad_token_id\": processor.tokenizer.pad_token_id,\n",
        "    \"bos_token_id\": processor.tokenizer.bos_token_id,\n",
        "    \"eos_token_id\": processor.tokenizer.eos_token_id,\n",
        "    #\"temperature\" : temperature,\n",
        "    #\"top_p\": top_p,\n",
        "    #\"top_k\":top_k,\n",
        "    #\"min_p\": min_p,\n",
        "    #\"repetition_penalty\": repetition_penalty,\n",
        "    #\"cache_implementation\": cache_implementation,\n",
        "}\n",
        "from transformers import GenerationConfig\n",
        "generation_config = GenerationConfig(**generation_kwargs)\n"
      ],
      "metadata": {
        "id": "3kPH4joIhtL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoYZNOkILlwR",
        "outputId": "eed3b46b-8fb4-4f60-ef7e-63fe95e9283c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': [{'path': '/content/output/Phone call with HMRC fraudster in UK 2021.wav/chunk_0000.wav',\n",
              "    'text': None,\n",
              "    'type': 'audio'},\n",
              "   {'path': None,\n",
              "    'text': 'Based on the given audio predict the probability of fraudlant activity.\\nBefore predicting the probability of fraud you should think about the reasoning process.\\nMake sure you see each aspect of the case and create a case report while reasoning about the case.\\nThe reasoning process should be enclosed within <think></think> tags\\nWhile the final answer should be enclosed in <answer></answer> tags\\n\\neg <think>This is my reasoning</think>\\n<answer>0.7</answer>',\n",
              "    'type': 'text'}],\n",
              "  'role': 'user'}]"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_pp[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um9IivNPRgHv",
        "outputId": "89b603dd-f96c-4d75-a848-7975f63df025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': [{'path': '/content/output/Phone call with HMRC fraudster in UK 2021.wav/chunk_0000.wav',\n",
              "    'type': 'audio'},\n",
              "   {'text': 'Based on the given audio predict the probability of fraudlant activity.\\nBefore predicting the probability of fraud you should think about the reasoning process.\\nMake sure you see each aspect of the case and create a case report while reasoning about the case.\\nThe reasoning process should be enclosed within <think></think> tags\\nWhile the final answer should be enclosed in <answer></answer> tags\\n\\neg <think>This is my reasoning</think>\\n<answer>0.7</answer>',\n",
              "    'type': 'text'}],\n",
              "  'role': 'user'}]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_pp = [remove_none_fields(prompt) for prompt in prompts ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThzmjnDkNy4O",
        "outputId": "fa856786-1210-4f81-ec9f-df73caf948b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pL  {'content': [{'path': '/content/output/Phone call with HMRC fraudster in UK 2021.wav/chunk_0000.wav', 'text': None, 'type': 'audio'}, {'path': None, 'text': 'Based on the given audio predict the probability of fraudlant activity.\\nBefore predicting the probability of fraud you should think about the reasoning process.\\nMake sure you see each aspect of the case and create a case report while reasoning about the case.\\nThe reasoning process should be enclosed within <think></think> tags\\nWhile the final answer should be enclosed in <answer></answer> tags\\n\\neg <think>This is my reasoning</think>\\n<answer>0.7</answer>', 'type': 'text'}], 'role': 'user'}\n",
            "pLc  {'path': '/content/output/Phone call with HMRC fraudster in UK 2021.wav/chunk_0000.wav', 'text': None, 'type': 'audio'}\n",
            "pLc  {'path': None, 'text': 'Based on the given audio predict the probability of fraudlant activity.\\nBefore predicting the probability of fraud you should think about the reasoning process.\\nMake sure you see each aspect of the case and create a case report while reasoning about the case.\\nThe reasoning process should be enclosed within <think></think> tags\\nWhile the final answer should be enclosed in <answer></answer> tags\\n\\neg <think>This is my reasoning</think>\\n<answer>0.7</answer>', 'type': 'text'}\n",
            "pL  {'content': [{'path': '/content/output/Sales Call example 1.wav/chunk_0000.wav', 'text': None, 'type': 'audio'}, {'path': None, 'text': 'Based on the given audio predict the probability of fraudlant activity.\\nBefore predicting the probability of fraud you should think about the reasoning process.\\nMake sure you see each aspect of the case and create a case report while reasoning about the case.\\nThe reasoning process should be enclosed within <think></think> tags\\nWhile the final answer should be enclosed in <answer></answer> tags\\n\\neg <think>This is my reasoning</think>\\n<answer>0.7</answer>', 'type': 'text'}], 'role': 'user'}\n",
            "pLc  {'path': '/content/output/Sales Call example 1.wav/chunk_0000.wav', 'text': None, 'type': 'audio'}\n",
            "pLc  {'path': None, 'text': 'Based on the given audio predict the probability of fraudlant activity.\\nBefore predicting the probability of fraud you should think about the reasoning process.\\nMake sure you see each aspect of the case and create a case report while reasoning about the case.\\nThe reasoning process should be enclosed within <think></think> tags\\nWhile the final answer should be enclosed in <answer></answer> tags\\n\\neg <think>This is my reasoning</think>\\n<answer>0.7</answer>', 'type': 'text'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k6mA071CNMB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWrM-vhdqC-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "385b2ccc-6317-4468-f30f-8cd9df06b910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-28 01:45:59 IST] _generate_single_turn prompts_text, prompts_text=[]\n",
            "[2025-10-28 01:45:59 IST] _generate_single_turn no images\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\"\n",
        "processing_class = processor\n",
        "# If the prompts are conversational and the inputs contain images, we need to convert the prompts from\n",
        "# [{\"role\": \"user\", \"content\": \"What color is the sky?\"}] to\n",
        "# [{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": \"What color is the sky?\"}]}]\n",
        "kwargs = {}\n",
        "\n",
        "#clog( f\"self.processing_class={self.processing_class}\")\n",
        "prompt_text = []\n",
        "generate_inputs = processor.apply_chat_template(prompts_pp).to(\"cuda\")\n",
        "\n",
        "  #[\n",
        "  #  maybe_apply_chat_template({\"prompt\": prompt}, processing_class)[\n",
        "  #      \"prompt\"\n",
        "  #  ]\n",
        "  #  for prompt in prompts_pp\n",
        "\n",
        "clog(\"_generate_single_turn prompts_text\", f\"prompts_text={prompt_text}\")\n",
        "\n",
        "clog(\"_generate_single_turn no images\")\n",
        "forward_kwargs = {}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation = model.generate(\n",
        "                    **generate_inputs,\n",
        "                    generation_config=generation_config,\n",
        "                    disable_compile=True,\n",
        "                )"
      ],
      "metadata": {
        "id": "y6BqXcjp3Jrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = processor.batch_decode(generation, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "yL_gaohM3HFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoded[1])"
      ],
      "metadata": {
        "id": "7_mgI6fB5fm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d68f3350-2c37-4745-864e-3905d2820248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the given audio predict the probability of fraudlant activity.\n",
            "Before predicting the probability of fraud you should think about the reasoning process.\n",
            "Make sure you see each aspect of the case and create a case report while reasoning about the case.\n",
            "The reasoning process should be enclosed within <think></think> tags\n",
            "While the final answer should be enclosed in <answer></answer> tags\n",
            "\n",
            "eg <think>This is my reasoning</think>\n",
            "<answer>0.7</answer>To reason about the probability of fraudulent activity from the given audio, let's go through different aspects and assign probabilities based on whether they're typical, suspicious, or indicative of fraud.\n",
            "\n",
            "```markdown\n",
            "<think>\n",
            "**Aspects to consider:**\n",
            "1. **Call Details**: Typical calls tend to be straightforward and focused.\n",
            "2. **Introductions**: The customer's immediate sharing of personal information can be flagged, though is not always indicative of fraud.\n",
            "3. **Intent**: The customer mentions they are planning to upgrade their vehicle's map, which is a common but potentially manipulative intent if done so by a third party.\n",
            "4. **Customer History**: The customer has previously interacted with Nissan, but there's no mention of any previous issues which could indicate a previous conflict.\n",
            "5. **Customer's Behavior**: Seeking information about cost before getting customer ID/number can seem prudent or manipulative.\n",
            "6. **Agent Behavior**: The agent appears polite and helpful, yet this too can be manipulated by fraudsters to gain personal information.\n",
            "7. **Customer Confidence**: John’s name itself is not too indicative, but the context and information requested could be a red flag if not handled carefully.\n",
            "</think>\n",
            "\n",
            "Let's assign probabilities to see if the probability approaches 0.5 (indicating common, everyday interaction)\n",
            "- Typical Call: 0.6 (call to inquire about a service)\n",
            "- Sharing of Personal Information: 0.4 (not suspicious, but can be)\n",
            "- Intent to Upgrade: 0.5\n",
            "- Previous Interaction: 0.5 (not always indicative, might be a repeat customer)\n",
            "- Customer Behavior on Information Request: 0.7 (manipulative to ask for customer details immediately could be a hint of fraud as per the context.)\n",
            "- Agent's Politeness/Helpfulness: 0.8 (should be typical, but if it's not)\n",
            "- Name Shown in Public: 0.5\n",
            "\n",
            "After calculating a weighted average considering all the aspects mentioned:\n",
            "<probability>\n",
            "0.6 + 0.4 + 0.5 +\n",
            "    (0.5 + 0.5 ) * 0.5 * (0.5*0.75) + (1 -0.8)\n",
            "=3.23 which gives probability of fraudulent activity\n",
            "</probability>\n",
            "\n",
            "This is indicative of fraudulent activity, yet it's not certain.\n",
            "<answer>\n",
            "0.7\n",
            "</answer>\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoded[0])"
      ],
      "metadata": {
        "id": "oIlv3u9z3Wbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e640748-be85-40b2-ebd9-09df604e0878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the given audio predict the probability of fraudlant activity.\n",
            "Before predicting the probability of fraud you should think about the reasoning process.\n",
            "Make sure you see each aspect of the case and create a case report while reasoning about the case.\n",
            "The reasoning process should be enclosed within <think></think> tags\n",
            "While the final answer should be enclosed in <answer></answer> tags\n",
            "\n",
            "eg <think>This is my reasoning</think>\n",
            "<answer>0.7</answer><think>Based on the case report, let's analyze the given audio step by step to make a rational decision.\n",
            "\n",
            "- The audio states that a criminal case for tax fraud and tax evasion has been registered in my name.\n",
            "- In addition, there is a warrant out for my arrest. This suggests a high level of suspicion or concrete evidence pointing towards tax-related crimes.\n",
            "- There is also mention of a \"recordable line,\" which implies that any conversation, including this one, is being documented and potentially used as evidence during the case.\n",
            "- A significant amount of back debt of £1,693 is mentioned, which can be a strong pointer of financial irregularities if not managed properly.\n",
            "- The mention of warranting my arrest heightens the suspicion levels since legal actions have already been taken against me.\n",
            "- Given the seriousness of the charges and the legal actions taken, the likelihood of fraudulent activities seems high.\n",
            "</think>\n",
            "\n",
            "<answer>78%</answer>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################"
      ],
      "metadata": {
        "id": "-smQLtDt3DFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### case 1"
      ],
      "metadata": {
        "id": "_SxeudQDxMRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_inputs_2 = processor.apply_chat_template(\n",
        "                prompts, tokenize=False, add_generation_prompt=True\n",
        "            )#.strip()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qpyAsM36iyrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_inputs_2"
      ],
      "metadata": {
        "id": "gKXbaVp7xqb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audios_pp =[np.array(aud) for aud in audios]"
      ],
      "metadata": {
        "id": "GzK3hbNzklPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(audios_pp[0])"
      ],
      "metadata": {
        "id": "JMeXc907kmEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_inputs_3 =  processor(\n",
        "                   text=prompts_text,\n",
        "                    padding_side=\"left\",\n",
        "                  # max_length=max_prompt_length,\n",
        "                #    max_length=64*10,\n",
        "                 #   truncation=True,\n",
        "                  #  add_special_tokens=False,\n",
        "                   audio=audios_pp,\n",
        "                   return_tensors=\"pt\",\n",
        "                   padding=True,\n",
        "            #        **kwargs,\n",
        "                ).to(\"cuda\")\n",
        "'''\n",
        "  generate_inputs = processing_class(\n",
        "    text=prompts_text,\n",
        "    return_tensors=\"pt\",\n",
        "    padding=True,\n",
        "    padding_side=\"left\",\n",
        "    max_length=max_prompt_length,\n",
        "    truncation=True,\n",
        "    add_special_tokens=False,\n",
        "    audio=audios_pp,\n",
        " #   **kwargs,\n",
        ").to(\"cuda\")'''"
      ],
      "metadata": {
        "id": "LdSfAGBbXvXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_inputs_3"
      ],
      "metadata": {
        "id": "j5WBbHaOxkxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "outputs_2 = model.generate(**generate_inputs_3, max_new_tokens=64*10)\n",
        "\n",
        "text_2 = processor.batch_decode(\n",
        "    outputs_2,\n",
        "    skip_special_tokens=False,\n",
        "  #  clean_up_tokenization_spaces=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "7ExG__JDX1fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_2[0])"
      ],
      "metadata": {
        "id": "tw3qR_jzjjGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_2[1])"
      ],
      "metadata": {
        "id": "TevBCDnYjiae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_2[1])"
      ],
      "metadata": {
        "id": "SJ7ZBRnDZKaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate_inputs[1]['input_ids']"
      ],
      "metadata": {
        "id": "byiGvy_jhkR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate_inputs[0]['input_ids']"
      ],
      "metadata": {
        "id": "XdB2hnO0gr4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_inputs_ = [ids['input_ids'] for ids in generate_inputs]"
      ],
      "metadata": {
        "id": "4IMA-h_jZXrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_inputs = processor(text=prompts, images=audios, return_tensors=\"pt\").to(model.device)"
      ],
      "metadata": {
        "id": "NcWzTSwfiZ_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "outputs = model.generate(**(generate_inputs[1].to(\"cuda\")), max_new_tokens=64*10)\n",
        "\n",
        "text = processor.batch_decode(\n",
        "    outputs,\n",
        "    skip_special_tokens=False,\n",
        "    clean_up_tokenization_spaces=False\n",
        ")\n",
        "print(text[0])"
      ],
      "metadata": {
        "id": "vE51z7efOKyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "outputs = model.generate(**(generate_inputs[0].to(\"cuda\")), max_new_tokens=64*10)\n",
        "\n",
        "text = processor.batch_decode(\n",
        "    outputs,\n",
        "    skip_special_tokens=False,\n",
        "    clean_up_tokenization_spaces=False\n",
        ")\n",
        "print(text[0])"
      ],
      "metadata": {
        "id": "i-uPkui0iAro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[0])"
      ],
      "metadata": {
        "id": "XG4JVRRaO3TK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bugTXtJ4rwu-"
      },
      "outputs": [],
      "source": [
        "prompt_completion_ids = model.generate(\n",
        "    **(single_generate_inputs.to(\"cuda\")),\n",
        "    generation_config=generation_config,\n",
        "    disable_compile=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clog( f\"prompt_completion_ids={prompt_completion_ids.shape}\")\n",
        "# Compute prompt length and extract completion ids\n",
        "prompt_ids, prompt_mask = (\n",
        "    generate_inputs[0][\"input_ids\"],\n",
        "    generate_inputs[0][\"attention_mask\"],\n",
        ")\n",
        "prompt_length = prompt_ids.size(1)\n",
        "completion_ids = prompt_completion_ids[:, prompt_length:]\n",
        "\n",
        "prompt_length = prompt_ids.size(1)\n",
        "completion_ids = prompt_completion_ids[:, prompt_length:]\n",
        "completions_text = processor.batch_decode(\n",
        "    completion_ids, skip_special_tokens=True\n",
        ")\n",
        "print(completions_text[0])"
      ],
      "metadata": {
        "id": "2U_gN-yqMakA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzskq2T-X-bu"
      },
      "outputs": [],
      "source": [
        "clog( f\"prompt_completion_ids={prompt_completion_ids.shape}\")\n",
        "# Compute prompt length and extract completion ids\n",
        "prompt_ids, prompt_mask = (\n",
        "    generate_inputs[0][\"input_ids\"],\n",
        "    generate_inputs[0][\"attention_mask\"],\n",
        ")\n",
        "prompt_length = prompt_ids.size(1)\n",
        "completion_ids = prompt_completion_ids[:, prompt_length:]\n",
        "\n",
        "prompt_length = prompt_ids.size(1)\n",
        "completion_ids = prompt_completion_ids[:, prompt_length:]\n",
        "completions_text = processor.batch_decode(\n",
        "    completion_ids, skip_special_tokens=True\n",
        ")\n",
        "print(completions_text[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yim7b5fdr8-5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxaBy9ndbBqK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gk_eHE_UvGkE"
      },
      "outputs": [],
      "source": [
        "## case 1 (not working)\n",
        "\n",
        "p_ct = processor.apply_chat_template(\n",
        "    prompts,\n",
        "\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        "    #return_dict=True,\n",
        "    #return_tensors=\"pt\",\n",
        ")\n",
        "print(\"p_ct \",p_ct)\n",
        "inputs = processing_class(\n",
        "  text=p_ct,\n",
        "  audios=audios,\n",
        "  return_tensors=\"pt\",\n",
        "  padding=True,\n",
        "  padding_side=\"left\",\n",
        "  max_length=max_prompt_length,\n",
        "  truncation=True,\n",
        "  add_special_tokens=False,\n",
        "\n",
        "  **kwargs,\n",
        ")\n",
        "inputs = inputs.to(model.device, dtype=torch.bfloat16)\n",
        "input_len = inputs[\"input_ids\"].shape[-1]\n",
        "\n",
        "generation = model.generate(**inputs, max_new_tokens=500, do_sample=False)\n",
        "\n",
        "generation = generation[0][input_len:]\n",
        "\n",
        "decoded = processor.decode(generation, skip_special_tokens=True)\n",
        "\n",
        "decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5znFCnZgwwn2"
      },
      "outputs": [],
      "source": [
        "## case 2 (Working)\n",
        "\n",
        "inputs =  processor.apply_chat_template(\n",
        "    prompts,\n",
        "    add_generation_prompt=True,\n",
        "    tokenize=True,\n",
        "    return_dict=True,\n",
        "    return_tensors=\"pt\",\n",
        ")\n",
        "\n",
        "inputs = inputs.to(model.device, dtype=torch.bfloat16)\n",
        "input_len = inputs[\"input_ids\"].shape[-1]\n",
        "\n",
        "generation = model.generate(**inputs, max_new_tokens=500, do_sample=False)\n",
        "\n",
        "generation = generation[0][input_len:]\n",
        "\n",
        "decoded = processor.decode(generation, skip_special_tokens=True)\n",
        "\n",
        "decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxn54sRDuys_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oFg6s4Aa2mv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKfjCIcOu3t_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBXsu9vMvcfK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f0adb71d94aa48aaa86c0248da3365d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d36be7ebacdc4b338cb187d7daf6dc86",
              "IPY_MODEL_d49a9e1580cf47ebae51c84b4abee4e1",
              "IPY_MODEL_bdaa85b8c3c94def957dbee1182366c0"
            ],
            "layout": "IPY_MODEL_1606607d00994d598e214c850cfcbb45"
          }
        },
        "d36be7ebacdc4b338cb187d7daf6dc86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e123d133751747999d2aae91f9b62b93",
            "placeholder": "​",
            "style": "IPY_MODEL_657d76bca1994b9ca25c6637e2e60cdc",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "d49a9e1580cf47ebae51c84b4abee4e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c0cd1b7423c45ea99914ec00b0f2219",
            "max": 357,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ad6c3865290477b880e5a76fee9ddb9",
            "value": 357
          }
        },
        "bdaa85b8c3c94def957dbee1182366c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fc68dabf531483ebfa3b22c94080e39",
            "placeholder": "​",
            "style": "IPY_MODEL_e6f7c7d74aa4461186665dd887aebf43",
            "value": " 357/357 [00:00&lt;00:00, 39.4kB/s]"
          }
        },
        "1606607d00994d598e214c850cfcbb45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e123d133751747999d2aae91f9b62b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "657d76bca1994b9ca25c6637e2e60cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c0cd1b7423c45ea99914ec00b0f2219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ad6c3865290477b880e5a76fee9ddb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fc68dabf531483ebfa3b22c94080e39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6f7c7d74aa4461186665dd887aebf43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9890e851b44e484598295c9973638509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6c9419c8f704780b337655fcb530a29",
              "IPY_MODEL_cb16c9b1a781417abf4da87281304a3a",
              "IPY_MODEL_1da3dd9ad2d54fff863f9a3976243881"
            ],
            "layout": "IPY_MODEL_0f4d49ef7d484827abe7993423bafe91"
          }
        },
        "c6c9419c8f704780b337655fcb530a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5cb6e4380e0448195f43bd25128cb6d",
            "placeholder": "​",
            "style": "IPY_MODEL_bc44a5312efe4418b6ec62e1b44e629a",
            "value": "tekken.json: 100%"
          }
        },
        "cb16c9b1a781417abf4da87281304a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2affea4532ba4e299178a42e50c0ad5f",
            "max": 14894206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c30e86b98290471eafe3206c97ff855d",
            "value": 14894206
          }
        },
        "1da3dd9ad2d54fff863f9a3976243881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13a1cf86ddd5414aa08df81597d8d367",
            "placeholder": "​",
            "style": "IPY_MODEL_5701f559ace24569a7f54336d56f35fc",
            "value": " 14.9M/14.9M [00:00&lt;00:00, 7.74MB/s]"
          }
        },
        "0f4d49ef7d484827abe7993423bafe91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5cb6e4380e0448195f43bd25128cb6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc44a5312efe4418b6ec62e1b44e629a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2affea4532ba4e299178a42e50c0ad5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c30e86b98290471eafe3206c97ff855d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13a1cf86ddd5414aa08df81597d8d367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5701f559ace24569a7f54336d56f35fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5efe798fc92e4580981ba658489ea76c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d79fe35ea08a4c27aafe1dbe047da724",
              "IPY_MODEL_5a3d8dcac17544fc843454261922feca",
              "IPY_MODEL_adaa3660a07d4d78bafa98c3bdda0273"
            ],
            "layout": "IPY_MODEL_c686265744fd42a0afa0129c20d3c266"
          }
        },
        "d79fe35ea08a4c27aafe1dbe047da724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74b8649a73f8477790489d7c6fdffca2",
            "placeholder": "​",
            "style": "IPY_MODEL_0bc881ca1f8140958e0463c601e3756c",
            "value": "config.json: "
          }
        },
        "5a3d8dcac17544fc843454261922feca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2b0f5306a9b4d53a3e52be361c770b8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a2c7f0008ee47cb8b561c10697a74c1",
            "value": 1
          }
        },
        "adaa3660a07d4d78bafa98c3bdda0273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4ed064312604937815674772a5aedbf",
            "placeholder": "​",
            "style": "IPY_MODEL_b8f80dd62877436ea8689a65c56c3333",
            "value": " 1.36k/? [00:00&lt;00:00, 166kB/s]"
          }
        },
        "c686265744fd42a0afa0129c20d3c266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74b8649a73f8477790489d7c6fdffca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bc881ca1f8140958e0463c601e3756c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2b0f5306a9b4d53a3e52be361c770b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9a2c7f0008ee47cb8b561c10697a74c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4ed064312604937815674772a5aedbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8f80dd62877436ea8689a65c56c3333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e307d42209c4d239c848abd2acd810d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ba7cafca23c43c3a07412941e77bc75",
              "IPY_MODEL_f47424574dca4befa5b12de19607d7ab",
              "IPY_MODEL_adaa34a49d1a4ab1a229afcca981bf0c"
            ],
            "layout": "IPY_MODEL_79f9e9f7a2d74184b0d518246b9e4cca"
          }
        },
        "8ba7cafca23c43c3a07412941e77bc75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8a6cb448f33424db778b53c7bdc307b",
            "placeholder": "​",
            "style": "IPY_MODEL_85fd2b98cb324eb38e664725beb6e547",
            "value": "model.safetensors.index.json: "
          }
        },
        "f47424574dca4befa5b12de19607d7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87cf614d786441b0bdd1ee06a5dfa9f6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_644f54ec983c4ed1a1b32bc2470dbcce",
            "value": 1
          }
        },
        "adaa34a49d1a4ab1a229afcca981bf0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e403ce499854d7db175dd1ab6a25167",
            "placeholder": "​",
            "style": "IPY_MODEL_2eeb4e3807ef45d19bf4c12315c8d788",
            "value": " 68.1k/? [00:00&lt;00:00, 7.01MB/s]"
          }
        },
        "79f9e9f7a2d74184b0d518246b9e4cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8a6cb448f33424db778b53c7bdc307b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85fd2b98cb324eb38e664725beb6e547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87cf614d786441b0bdd1ee06a5dfa9f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "644f54ec983c4ed1a1b32bc2470dbcce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e403ce499854d7db175dd1ab6a25167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eeb4e3807ef45d19bf4c12315c8d788": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fe5a565869b48a5a30a40eeeee791f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0717b171ed8049739b2c77868250b05d",
              "IPY_MODEL_c7659b613faf4cd0b883df440321ad96",
              "IPY_MODEL_6d7737d5b6eb4876bbc5b1bb34da8736"
            ],
            "layout": "IPY_MODEL_e830c701986d45b986cac4b7a1d5cd21"
          }
        },
        "0717b171ed8049739b2c77868250b05d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca62a3bcedc64d688fdab69b7d5fadfc",
            "placeholder": "​",
            "style": "IPY_MODEL_bff6bf1b667141459b026efcc697f3cc",
            "value": "Fetching 2 files: 100%"
          }
        },
        "c7659b613faf4cd0b883df440321ad96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cddce9bd659846ccb24f1dc9c7b79116",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c64ddd6b209040d2b5fc322b5f667fe3",
            "value": 2
          }
        },
        "6d7737d5b6eb4876bbc5b1bb34da8736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a366cc6ee4694985b8aba1124805a6c1",
            "placeholder": "​",
            "style": "IPY_MODEL_9a77c02c18da480395e090c2f04b60ad",
            "value": " 2/2 [00:50&lt;00:00, 20.78s/it]"
          }
        },
        "e830c701986d45b986cac4b7a1d5cd21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca62a3bcedc64d688fdab69b7d5fadfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bff6bf1b667141459b026efcc697f3cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cddce9bd659846ccb24f1dc9c7b79116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c64ddd6b209040d2b5fc322b5f667fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a366cc6ee4694985b8aba1124805a6c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a77c02c18da480395e090c2f04b60ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2868392b4b14e70a1492b919b88c91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84d826db822b4234803770e703b19af2",
              "IPY_MODEL_bb86c2aec64244f597a70271f46a712f",
              "IPY_MODEL_b6b53d6b67254d2ebfbce463e0936678"
            ],
            "layout": "IPY_MODEL_1373e095a275455e98972c6381b0d390"
          }
        },
        "84d826db822b4234803770e703b19af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eb93e6485e342b6a7ab16acaa4ed580",
            "placeholder": "​",
            "style": "IPY_MODEL_86c38bc3296141fe8db6e8b068e162a4",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "bb86c2aec64244f597a70271f46a712f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baded0342ef24741a32ba4bff83fb4b5",
            "max": 4977385976,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42e30bf75a8043e99e832dc33c2ea464",
            "value": 4977385976
          }
        },
        "b6b53d6b67254d2ebfbce463e0936678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29004459c9c547ce8d747ed85c361209",
            "placeholder": "​",
            "style": "IPY_MODEL_e47dfe51a39d4a079ccf2d7525c23e8e",
            "value": " 4.98G/4.98G [00:49&lt;00:00, 124MB/s]"
          }
        },
        "1373e095a275455e98972c6381b0d390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eb93e6485e342b6a7ab16acaa4ed580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c38bc3296141fe8db6e8b068e162a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baded0342ef24741a32ba4bff83fb4b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42e30bf75a8043e99e832dc33c2ea464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29004459c9c547ce8d747ed85c361209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e47dfe51a39d4a079ccf2d7525c23e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b255d9239ceb4bef8f6040d84b9b3e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_563cb8bcf79844499624b5bdc2fee012",
              "IPY_MODEL_f46a8ff3b9204b79b49eba9e7322c621",
              "IPY_MODEL_0377e1e5f545456c89a02ced46674bfa"
            ],
            "layout": "IPY_MODEL_1e5e8aa7d1d344e1bbf60387a85d8466"
          }
        },
        "563cb8bcf79844499624b5bdc2fee012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_530f7356a726455992fc264ac8e72896",
            "placeholder": "​",
            "style": "IPY_MODEL_0708e27dfaf14f6fb9c20000fbd85993",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "f46a8ff3b9204b79b49eba9e7322c621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5270abdd471a440c9a036400f67c4c5e",
            "max": 4379088336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de979f434af54ef1a1784e78994ecd40",
            "value": 4379088336
          }
        },
        "0377e1e5f545456c89a02ced46674bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f5747cbbe604108a2b16c999be2bb58",
            "placeholder": "​",
            "style": "IPY_MODEL_f8c20c61885e4aa6b36c736214cc675f",
            "value": " 4.38G/4.38G [00:49&lt;00:00, 233MB/s]"
          }
        },
        "1e5e8aa7d1d344e1bbf60387a85d8466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "530f7356a726455992fc264ac8e72896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0708e27dfaf14f6fb9c20000fbd85993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5270abdd471a440c9a036400f67c4c5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de979f434af54ef1a1784e78994ecd40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f5747cbbe604108a2b16c999be2bb58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8c20c61885e4aa6b36c736214cc675f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2096cd8cc2b48ebbefa01c02fbfb4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bfc8e51f1a645fbb312285342851dc5",
              "IPY_MODEL_55717cbcb872419698c85d1c064540ea",
              "IPY_MODEL_e4d222d6ea65461f9ac3c8743ecf9920"
            ],
            "layout": "IPY_MODEL_45c4456923044dd8ba18266955ce9e4b"
          }
        },
        "2bfc8e51f1a645fbb312285342851dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a18cdde4dd414d43af509053ed11538c",
            "placeholder": "​",
            "style": "IPY_MODEL_f13d4de977184c20a496fe3691bccd46",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "55717cbcb872419698c85d1c064540ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a82e607fd19b42b185cc11141bf35ea1",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abeaf616db5146529e4494e5874d6d4c",
            "value": 2
          }
        },
        "e4d222d6ea65461f9ac3c8743ecf9920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56123aa499b2426d8043954bfff22da9",
            "placeholder": "​",
            "style": "IPY_MODEL_0461ff6e696a4c2cae152e152ec66299",
            "value": " 2/2 [00:02&lt;00:00,  1.41s/it]"
          }
        },
        "45c4456923044dd8ba18266955ce9e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a18cdde4dd414d43af509053ed11538c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f13d4de977184c20a496fe3691bccd46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a82e607fd19b42b185cc11141bf35ea1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abeaf616db5146529e4494e5874d6d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56123aa499b2426d8043954bfff22da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0461ff6e696a4c2cae152e152ec66299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1129f1e5ed3a435581c18ae97c5fdd09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13ccd7ae082c432b9c9ce5a5f049972d",
              "IPY_MODEL_e0e66f21fd9645faae8372fb59f9979c",
              "IPY_MODEL_12bc6224fe384e21bc4d2c034ef59b17"
            ],
            "layout": "IPY_MODEL_ddec1451cd1441328def6d496f1f363c"
          }
        },
        "13ccd7ae082c432b9c9ce5a5f049972d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dbe352f6bd140baa259fcb7039c1923",
            "placeholder": "​",
            "style": "IPY_MODEL_cd2ba848f6fa4846853bdcfd24737620",
            "value": "generation_config.json: 100%"
          }
        },
        "e0e66f21fd9645faae8372fb59f9979c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86d2d52dcca94bbbb06f51cecc2d6252",
            "max": 108,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d606fcf81524da8a17c1c03e52fc5e5",
            "value": 108
          }
        },
        "12bc6224fe384e21bc4d2c034ef59b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39b35b61d2dc4901b1ea4f5018a6a1db",
            "placeholder": "​",
            "style": "IPY_MODEL_a3483e25edb9437a9f0192f89e25d747",
            "value": " 108/108 [00:00&lt;00:00, 14.2kB/s]"
          }
        },
        "ddec1451cd1441328def6d496f1f363c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dbe352f6bd140baa259fcb7039c1923": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd2ba848f6fa4846853bdcfd24737620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86d2d52dcca94bbbb06f51cecc2d6252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d606fcf81524da8a17c1c03e52fc5e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39b35b61d2dc4901b1ea4f5018a6a1db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3483e25edb9437a9f0192f89e25d747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82c076099c844d26b3f131734db2e1cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06a51c8984fb4679974a63d0c8a8d141",
              "IPY_MODEL_9a03d411cb9547f3a14dc8a3b9a887e1",
              "IPY_MODEL_8af14d7c14f146ffb0c2fe8e76a142f9"
            ],
            "layout": "IPY_MODEL_696bf120d98a4f3fa47b877ead0f4dd7"
          }
        },
        "06a51c8984fb4679974a63d0c8a8d141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f49ec2b775bb4fb9a979ff8b9b8e80a0",
            "placeholder": "​",
            "style": "IPY_MODEL_70fa49fc3bcc4f219c1704a85de60015",
            "value": "Processing Files (3 / 3)      : 100%"
          }
        },
        "9a03d411cb9547f3a14dc8a3b9a887e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec54189f66fa4aa6a9ed9936ab86c503",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b01d5564f044c4593358aa66a6749bd",
            "value": 1
          }
        },
        "8af14d7c14f146ffb0c2fe8e76a142f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5ce303dccd347d5aca0176134a88cc2",
            "placeholder": "​",
            "style": "IPY_MODEL_bd1d24425d254bb9a87591a5b82f8303",
            "value": " 44.5MB / 44.5MB, 24.7MB/s  "
          }
        },
        "696bf120d98a4f3fa47b877ead0f4dd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f49ec2b775bb4fb9a979ff8b9b8e80a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70fa49fc3bcc4f219c1704a85de60015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec54189f66fa4aa6a9ed9936ab86c503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8b01d5564f044c4593358aa66a6749bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5ce303dccd347d5aca0176134a88cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd1d24425d254bb9a87591a5b82f8303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0054d1589004be3abe9ff041de4cf20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c18addc607a14abda767aaf0fb1b2a15",
              "IPY_MODEL_29a75476d22e42b293f2f68a7ce2cfe5",
              "IPY_MODEL_11afb20ccef446188dcb6deeaa489eed"
            ],
            "layout": "IPY_MODEL_cb5ba2ec76db45539bc6287e83e118b4"
          }
        },
        "c18addc607a14abda767aaf0fb1b2a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e27d827e54ad4e738dcd00d02b8b74b6",
            "placeholder": "​",
            "style": "IPY_MODEL_06ebc0afde74427d8c48059ab8c3c10d",
            "value": "New Data Upload               : 100%"
          }
        },
        "29a75476d22e42b293f2f68a7ce2cfe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bf922ae9346419a836097c4674c890c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4fccd58a33b4b4083dafb53b74115f1",
            "value": 1
          }
        },
        "11afb20ccef446188dcb6deeaa489eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d0929ba118c4b43b777fb8ff5b5047a",
            "placeholder": "​",
            "style": "IPY_MODEL_ed521adb81114ad2b718571873c91068",
            "value": "  416kB /  416kB,  347kB/s  "
          }
        },
        "cb5ba2ec76db45539bc6287e83e118b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e27d827e54ad4e738dcd00d02b8b74b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06ebc0afde74427d8c48059ab8c3c10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bf922ae9346419a836097c4674c890c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e4fccd58a33b4b4083dafb53b74115f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d0929ba118c4b43b777fb8ff5b5047a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed521adb81114ad2b718571873c91068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac82d77fb4a94b73b0805db452f05b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d45f0d8cb5d4e2fa23be4674e73efba",
              "IPY_MODEL_e70270e412e646b3a365671af9d8ecac",
              "IPY_MODEL_ad555aa3c1a64ef0930edbf9dae90b14"
            ],
            "layout": "IPY_MODEL_09a732e4bbf04299b7f4b63b441a9208"
          }
        },
        "8d45f0d8cb5d4e2fa23be4674e73efba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e75d68595d7740c7a6693ec1f545823a",
            "placeholder": "​",
            "style": "IPY_MODEL_a084dbcc785745cb978c5be1e22164df",
            "value": "  ...-Mini-3B-2507/tekken.json: 100%"
          }
        },
        "e70270e412e646b3a365671af9d8ecac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fd40a9fc6fb4d2781218838e5158f2f",
            "max": 14894206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1c6e8b059404bd7b9e437a24ae5009e",
            "value": 14894206
          }
        },
        "ad555aa3c1a64ef0930edbf9dae90b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_901319be1f454497adb0ef55315fb064",
            "placeholder": "​",
            "style": "IPY_MODEL_4eff85e822b64c1bb587466d42a0b61d",
            "value": " 14.9MB / 14.9MB            "
          }
        },
        "09a732e4bbf04299b7f4b63b441a9208": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e75d68595d7740c7a6693ec1f545823a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a084dbcc785745cb978c5be1e22164df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fd40a9fc6fb4d2781218838e5158f2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1c6e8b059404bd7b9e437a24ae5009e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "901319be1f454497adb0ef55315fb064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eff85e822b64c1bb587466d42a0b61d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f844135771b043318f205ba36febcff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5381d40b628f4699bcef5c117f4a899b",
              "IPY_MODEL_851096000b33496f8acbd434e8af1e4b",
              "IPY_MODEL_4e814df01f2d4e7cac77bf795f3427b6"
            ],
            "layout": "IPY_MODEL_9cfb2011b98741cb99d59a723db8b258"
          }
        },
        "5381d40b628f4699bcef5c117f4a899b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cd7223b6c744deaa7d920e1775bf7ae",
            "placeholder": "​",
            "style": "IPY_MODEL_b12933bcf4694a1f9632fd264bfb1691",
            "value": "  ...adapter_model.safetensors: 100%"
          }
        },
        "851096000b33496f8acbd434e8af1e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f915512e59c843b285ccc8d23afc96c4",
            "max": 29553256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f556854e4b1240739f91b7ecf3317185",
            "value": 29553256
          }
        },
        "4e814df01f2d4e7cac77bf795f3427b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0265ce82cd0744af816fd4a08e0c402c",
            "placeholder": "​",
            "style": "IPY_MODEL_57b5196c64324c70a51ad2098b2c3081",
            "value": " 29.6MB / 29.6MB            "
          }
        },
        "9cfb2011b98741cb99d59a723db8b258": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cd7223b6c744deaa7d920e1775bf7ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b12933bcf4694a1f9632fd264bfb1691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f915512e59c843b285ccc8d23afc96c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f556854e4b1240739f91b7ecf3317185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0265ce82cd0744af816fd4a08e0c402c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57b5196c64324c70a51ad2098b2c3081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2372d7a26f9f4f818e0b9f27caedd73c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b08d91ac08f40dd8bd0c6947830dbc8",
              "IPY_MODEL_06799b01fa5d44939cf8fb928cbf74d8",
              "IPY_MODEL_a3a4844289004bc8ba03105ae46c0e0f"
            ],
            "layout": "IPY_MODEL_41a677140b3e40a1888c01cb130a6f21"
          }
        },
        "1b08d91ac08f40dd8bd0c6947830dbc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84a8392ca05d416ba3a0167b7ebc0f1e",
            "placeholder": "​",
            "style": "IPY_MODEL_5270fa41350440d5abcd402414cbc2d9",
            "value": "  ...3B-2507/training_args.bin: 100%"
          }
        },
        "06799b01fa5d44939cf8fb928cbf74d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35c80f1eb3ea455f80c3ac77252edfc1",
            "max": 7249,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a46921da5564dfc85366d4be163c268",
            "value": 7249
          }
        },
        "a3a4844289004bc8ba03105ae46c0e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1f981d31b6e4dc8ba1eb229defb71f5",
            "placeholder": "​",
            "style": "IPY_MODEL_c89751bafb87438ea473380472e805d7",
            "value": " 7.25kB / 7.25kB            "
          }
        },
        "41a677140b3e40a1888c01cb130a6f21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84a8392ca05d416ba3a0167b7ebc0f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5270fa41350440d5abcd402414cbc2d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35c80f1eb3ea455f80c3ac77252edfc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a46921da5564dfc85366d4be163c268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1f981d31b6e4dc8ba1eb229defb71f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c89751bafb87438ea473380472e805d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5c1c5ae8eef462ba1ab4ce3c6f281bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2db255e47faa4a159d36170e2117fb5a",
              "IPY_MODEL_96f1f16df9544ab2b00c67af9268897d",
              "IPY_MODEL_f3af186f537a4784b4fb2816459a5878"
            ],
            "layout": "IPY_MODEL_f65315c670b84be49d5801c3fc601b3e"
          }
        },
        "2db255e47faa4a159d36170e2117fb5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d67f2f3e1334004b701e098e326c093",
            "placeholder": "​",
            "style": "IPY_MODEL_1e502b92f9b846c9a61b8f2f8dd04882",
            "value": "Processing Files (1 / 1)      : 100%"
          }
        },
        "96f1f16df9544ab2b00c67af9268897d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6bd979179304d67b0ea506c9636d53f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee62cd7249f14cad9c50bd7f19707790",
            "value": 1
          }
        },
        "f3af186f537a4784b4fb2816459a5878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a643c9495a214c3cadd105b47f028330",
            "placeholder": "​",
            "style": "IPY_MODEL_e33669c44d9547409d9af80a64fb0995",
            "value": " 14.9MB / 14.9MB, 10.6MB/s  "
          }
        },
        "f65315c670b84be49d5801c3fc601b3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d67f2f3e1334004b701e098e326c093": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e502b92f9b846c9a61b8f2f8dd04882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6bd979179304d67b0ea506c9636d53f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ee62cd7249f14cad9c50bd7f19707790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a643c9495a214c3cadd105b47f028330": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e33669c44d9547409d9af80a64fb0995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8ea0821eaa444f1868a66665f35b139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c760ee00e04454aa8de3179551bf02c",
              "IPY_MODEL_dddf7f3d877a45dfb0a095d9ebde3f6f",
              "IPY_MODEL_476dbc9b146341088f18efbcd60918d6"
            ],
            "layout": "IPY_MODEL_f9e9ecae22214b7d8fddc014ee5e9077"
          }
        },
        "2c760ee00e04454aa8de3179551bf02c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7de71471abfe41169142bcb45809f2a0",
            "placeholder": "​",
            "style": "IPY_MODEL_3137090f3fe148279a2cf88fc45fcc56",
            "value": "New Data Upload               : 100%"
          }
        },
        "dddf7f3d877a45dfb0a095d9ebde3f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca87287650a3449785f8a78b65d3f365",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ed0ebd734e0403ab1eaedfdc96acdfd",
            "value": 1
          }
        },
        "476dbc9b146341088f18efbcd60918d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4c7581555bd4ecbbc286317b066fc64",
            "placeholder": "​",
            "style": "IPY_MODEL_1b12ae0da2c94060bd759e055208ccf1",
            "value": " 1.16MB / 1.16MB,  828kB/s  "
          }
        },
        "f9e9ecae22214b7d8fddc014ee5e9077": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7de71471abfe41169142bcb45809f2a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3137090f3fe148279a2cf88fc45fcc56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca87287650a3449785f8a78b65d3f365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9ed0ebd734e0403ab1eaedfdc96acdfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4c7581555bd4ecbbc286317b066fc64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b12ae0da2c94060bd759e055208ccf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a2ce5cc11d84baab07a2b2920a821b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee01eed854284bc79c01095c9f639566",
              "IPY_MODEL_6cf08bfa102249519cff858c9174adc2",
              "IPY_MODEL_222b9bc718e642028ba8965f39e5bb66"
            ],
            "layout": "IPY_MODEL_4bc62fdf0b834ba1a53a3adb1f883778"
          }
        },
        "ee01eed854284bc79c01095c9f639566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f72634e4185146039767b9c467a52389",
            "placeholder": "​",
            "style": "IPY_MODEL_d5d9fc8eae004be7bd3949e780f0e94f",
            "value": "  /tmp/tmpclavfn63/tekken.json: 100%"
          }
        },
        "6cf08bfa102249519cff858c9174adc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dbf0534aaf244b4bd98ee399a7dbf2a",
            "max": 14894206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06cd2539e58546f9b5070376a8e26221",
            "value": 14894206
          }
        },
        "222b9bc718e642028ba8965f39e5bb66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78659ab790234d31ae8061a160ccb5c8",
            "placeholder": "​",
            "style": "IPY_MODEL_803f4c48788949acab6e0e432829b353",
            "value": " 14.9MB / 14.9MB            "
          }
        },
        "4bc62fdf0b834ba1a53a3adb1f883778": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f72634e4185146039767b9c467a52389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5d9fc8eae004be7bd3949e780f0e94f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dbf0534aaf244b4bd98ee399a7dbf2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06cd2539e58546f9b5070376a8e26221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78659ab790234d31ae8061a160ccb5c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "803f4c48788949acab6e0e432829b353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abadce50c81e40eda60df822303f8534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_248b6c541c6243f686861b2b62bea23d",
              "IPY_MODEL_4bfb9c0353f4489b8ddbdd45b52b61b9",
              "IPY_MODEL_66676831ccf44f13a669fad0803c508e"
            ],
            "layout": "IPY_MODEL_7f65fb1642144cb382830d0b95d7d362"
          }
        },
        "248b6c541c6243f686861b2b62bea23d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da00ffcae94247df9d919d49a96d0a12",
            "placeholder": "​",
            "style": "IPY_MODEL_111d79f268654472847f0d9044316c57",
            "value": "README.md: "
          }
        },
        "4bfb9c0353f4489b8ddbdd45b52b61b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68d2a66a47df4d6a818a268dfa4400c3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21b4afe189fc40abb1c8997a9a3f6c58",
            "value": 1
          }
        },
        "66676831ccf44f13a669fad0803c508e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d69977cde88543fcb3a2a69d844107b9",
            "placeholder": "​",
            "style": "IPY_MODEL_f30e95e458294fe49f53f113f725f217",
            "value": " 5.17k/? [00:00&lt;00:00, 515kB/s]"
          }
        },
        "7f65fb1642144cb382830d0b95d7d362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da00ffcae94247df9d919d49a96d0a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "111d79f268654472847f0d9044316c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68d2a66a47df4d6a818a268dfa4400c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "21b4afe189fc40abb1c8997a9a3f6c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d69977cde88543fcb3a2a69d844107b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f30e95e458294fe49f53f113f725f217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a40ff558992c4b0ea6aef13d4fdafda5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4a4bd3eb7f141c18813d868ddcf7b51",
              "IPY_MODEL_c7676629db1147b58b288fd797fdf4ab",
              "IPY_MODEL_5e106a5754d94831b2746f5264fb444e"
            ],
            "layout": "IPY_MODEL_c334f2a9824c41258e4e993e3aa46656"
          }
        },
        "d4a4bd3eb7f141c18813d868ddcf7b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37860c269add40d7ba70b133717f092a",
            "placeholder": "​",
            "style": "IPY_MODEL_ba927acc95c44fbca915ae762b0b0f2b",
            "value": "Processing Files (2 / 2)      : 100%"
          }
        },
        "c7676629db1147b58b288fd797fdf4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da24711c238440e098f058253531f41a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c0c69fc2be04419b7d863844d05a33d",
            "value": 1
          }
        },
        "5e106a5754d94831b2746f5264fb444e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09403815db554310aa2ffcfea05b5986",
            "placeholder": "​",
            "style": "IPY_MODEL_2077ae72f0084258a474a06274a9a653",
            "value": " 9.39GB / 9.39GB,  226MB/s  "
          }
        },
        "c334f2a9824c41258e4e993e3aa46656": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37860c269add40d7ba70b133717f092a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba927acc95c44fbca915ae762b0b0f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da24711c238440e098f058253531f41a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3c0c69fc2be04419b7d863844d05a33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09403815db554310aa2ffcfea05b5986": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2077ae72f0084258a474a06274a9a653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ee706a6e4084e2799e28fc157ba8b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e445d6097de847ffac154d0f8498f3f4",
              "IPY_MODEL_f8a51965fc4d4c97aa6d6ba87b420707",
              "IPY_MODEL_dd22a828590148d48e1e9120ef0b2e32"
            ],
            "layout": "IPY_MODEL_336ba06fc2284275aa02264c68f6579c"
          }
        },
        "e445d6097de847ffac154d0f8498f3f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cff95d7484a4a21ba878d36b40d30fa",
            "placeholder": "​",
            "style": "IPY_MODEL_ec9ff78b3d7f42e1a08d1a5e3d8c798e",
            "value": "New Data Upload               : 100%"
          }
        },
        "f8a51965fc4d4c97aa6d6ba87b420707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b827eab8ef3d41f390c93ad1fec2ad69",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61ace05b85b441c6b1dff84865b7fcf8",
            "value": 1
          }
        },
        "dd22a828590148d48e1e9120ef0b2e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_442f49e77dd24302a5206c732852d1fc",
            "placeholder": "​",
            "style": "IPY_MODEL_fed65c292894413797ec0bcef4f00755",
            "value": "  398MB /  398MB, 13.0MB/s  "
          }
        },
        "336ba06fc2284275aa02264c68f6579c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cff95d7484a4a21ba878d36b40d30fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec9ff78b3d7f42e1a08d1a5e3d8c798e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b827eab8ef3d41f390c93ad1fec2ad69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "61ace05b85b441c6b1dff84865b7fcf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "442f49e77dd24302a5206c732852d1fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fed65c292894413797ec0bcef4f00755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9176756727041a2875df69ec861d57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8688cfe1de5b4264a24a599ed588355a",
              "IPY_MODEL_1243b6eeed0f403f9d6df30a28136083",
              "IPY_MODEL_adc6fe8d692d46b384ad02050047b4c9"
            ],
            "layout": "IPY_MODEL_d4f9e61fbbfd4cfaab78c41129584d8e"
          }
        },
        "8688cfe1de5b4264a24a599ed588355a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_336debe4d0a644898a013767f7b52790",
            "placeholder": "​",
            "style": "IPY_MODEL_d922b4f2bf8d423b9e2b5842c957ad1b",
            "value": "  ...0001-of-00002.safetensors: 100%"
          }
        },
        "1243b6eeed0f403f9d6df30a28136083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8164ab8606384a4988910b07475e7248",
            "max": 4995385848,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36e9197d3b6b4f339134d740cdd0a5f2",
            "value": 4995385848
          }
        },
        "adc6fe8d692d46b384ad02050047b4c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9ef047383cf4b97a77b5a3c4a1cbb3b",
            "placeholder": "​",
            "style": "IPY_MODEL_cb0c4167976b452487a37af5729be8a1",
            "value": " 5.00GB / 5.00GB            "
          }
        },
        "d4f9e61fbbfd4cfaab78c41129584d8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "336debe4d0a644898a013767f7b52790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d922b4f2bf8d423b9e2b5842c957ad1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8164ab8606384a4988910b07475e7248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36e9197d3b6b4f339134d740cdd0a5f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9ef047383cf4b97a77b5a3c4a1cbb3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb0c4167976b452487a37af5729be8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75b7232e0607431bb6704d9156bfaf40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15aa92076c8a450a88d6382976848996",
              "IPY_MODEL_abe429e30ea646cda6438024013d307f",
              "IPY_MODEL_a57bd0940f534970a5af8324a872623f"
            ],
            "layout": "IPY_MODEL_795c8e94adcb48a392a6fbe096d5315f"
          }
        },
        "15aa92076c8a450a88d6382976848996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f73dbc6328244e08f21c13353a8771a",
            "placeholder": "​",
            "style": "IPY_MODEL_8fbe06cbdc444c919a368f6e22933e28",
            "value": "  ...0002-of-00002.safetensors: 100%"
          }
        },
        "abe429e30ea646cda6438024013d307f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3c3bd19827949ad9a20234e519da78a",
            "max": 4390641048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0353a8c2832d420f8b50146c8758ffc7",
            "value": 4390641048
          }
        },
        "a57bd0940f534970a5af8324a872623f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9eb793dc676492b8ba2b71f626e8234",
            "placeholder": "​",
            "style": "IPY_MODEL_aa04e123abc744dd9dd404870e1380f5",
            "value": " 4.39GB / 4.39GB            "
          }
        },
        "795c8e94adcb48a392a6fbe096d5315f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f73dbc6328244e08f21c13353a8771a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fbe06cbdc444c919a368f6e22933e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3c3bd19827949ad9a20234e519da78a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0353a8c2832d420f8b50146c8758ffc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9eb793dc676492b8ba2b71f626e8234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa04e123abc744dd9dd404870e1380f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}